{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u5h9YqKHMidH",
        "UJ2L8EDHQXwD",
        "3AEcTyxvQZ7j",
        "XlcTSlV-Dr06",
        "CDapVzfa01hG",
        "E4sfWc1E08FW",
        "wH4vWH3W0-TG",
        "S98tkr_g1B1i",
        "TUeJjyYA1D_X"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "u5h9YqKHMidH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HV40g3iL4X2I"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Suppress specific SHAP TensorFlow warnings\n",
        "warnings.filterwarnings(\"ignore\", message=\"Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode\")\n",
        "\n",
        "# Your code here..."
      ],
      "metadata": {
        "id": "aUb8hi4pGOvj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-C8NrPj68J4",
        "outputId": "e44caef1-4ada-4e6d-ada7-4045c891cb2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.4.1)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.5.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (24.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/AnotherSamWilson/fastshap.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hplMRhW7XdAv",
        "outputId": "da1747c2-f870-4898-9505-af2a1fda510a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AnotherSamWilson/fastshap.git\n",
            "  Cloning https://github.com/AnotherSamWilson/fastshap.git to /tmp/pip-req-build-egi51n2o\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AnotherSamWilson/fastshap.git /tmp/pip-req-build-egi51n2o\n",
            "  Resolved https://github.com/AnotherSamWilson/fastshap.git to commit 2a791a321909143da5606fb3cb092434d413850d\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fastshap==0.2.1) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastshap==0.2.1) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastshap==0.2.1) (1.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->fastshap==0.2.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastshap==0.2.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->fastshap==0.2.1) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastshap==0.2.1) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastshap==0.2.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastshap==0.2.1) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->fastshap==0.2.1) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "id": "ic7B9dVj5wSC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install modAL-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5QJlXPV7FQe",
        "outputId": "8cd5727e-4119-41d5-c24b-a9eaa1c4058a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: modAL-python in /usr/local/lib/python3.10/dist-packages (0.4.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from modAL-python) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python) (1.5.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.10/dist-packages (from modAL-python) (1.13.1)\n",
            "Requirement already satisfied: pandas>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from modAL-python) (2.2.2)\n",
            "Requirement already satisfied: skorch==0.9.0 in /usr/local/lib/python3.10/dist-packages (from modAL-python) (0.9.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python) (0.9.0)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.10/dist-packages (from skorch==0.9.0->modAL-python) (4.66.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.0->modAL-python) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->modAL-python) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.0->modAL-python) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from modAL.models import ActiveLearner\n",
        "from modAL.uncertainty import uncertainty_sampling\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "a3r2d58D8Zvq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install shap"
      ],
      "metadata": {
        "id": "-inClKYbEj98"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyZlxfinEgKo",
        "outputId": "f6d33db0-cd09-4d22-d38d-e89505af6525"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.9.0)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjv0WunKci8s",
        "outputId": "e7e3a7cf-9ccf-4eed-d2ca-fdd6d92829da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generic Active Learning Model"
      ],
      "metadata": {
        "id": "cv4R_g8_MloH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evidential-deep-learning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztMraK_ncFOf",
        "outputId": "bc42dad8-c47d-408a-9e3c-b41c40650b00"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evidential-deep-learning in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from evidential-deep-learning) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from evidential-deep-learning) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evidential-deep-learning) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evidential-deep-learning) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evidential-deep-learning) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evidential-deep-learning) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evidential-deep-learning) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evidential-deep-learning) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evidential-deep-learning) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->evidential-deep-learning) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->evidential-deep-learning) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evidential_deep_learning as edl\n",
        "\n",
        "def evidential_loss(true, pred):\n",
        "    alpha = tf.nn.relu(pred) + 1  # Convert evidence to Dirichlet parameters\n",
        "    return edl.losses.Dirichlet_SOS(true, alpha, t = None)\n",
        "\n",
        "def create_clf_evidential_model(nodes, n_features, n_classes):\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(n_features,)))\n",
        "  model.add(Dense(nodes, activation='relu'))\n",
        "  model.add(Dense(n_classes, activation='relu'))\n",
        "  model.compile(optimizer=Adam(), loss=evidential_loss)\n",
        "  return model"
      ],
      "metadata": {
        "id": "aqDsA83FIVQu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EvidentialRegressionLoss(true, pred):\n",
        "        return edl.losses.EvidentialRegression(true, pred, coeff=1e-2)\n",
        "\n",
        "def create_reg_model(nodes, n_features):\n",
        "    # Define the model with evidential output for regression\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(n_features,)))  # Use Input layer for 20 features\n",
        "    model.add(Dense(nodes, activation='relu', name = 'hidden_layer'))  # 64 units hidden layer\n",
        "    model.add(edl.layers.DenseNormalGamma(1))  # Output layer for binary classification with sigmoid activation\n",
        "    model.compile(optimizer=Adam(), loss=EvidentialRegressionLoss, metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "hlwLlMsNlClR"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "\n",
        "def create_clf_model(nodes, n_features):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(n_features,)))  # Use Input layer for 20 features\n",
        "    model.add(Dense(nodes, activation='relu', name = 'hidden_layer'))  # 64 units hidden layer\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Output layer for binary classification with sigmoid activation\n",
        "    model.compile(optimizer=Adam(), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "3d1fOaSR5u3q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_multi_clf_model(nodes, n_features, n_classes):\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(n_features,)))  # Use Input layer for 20 features\n",
        "    model.add(Dense(nodes, activation='relu', name = 'hidden_layer'))  # 64 units hidden layer\n",
        "    model.add(Dense(n_classes, activation='softmax'))  # Output layer for binary classification with sigmoid activation\n",
        "    model.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "WatVCcN9M4kc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create a function to initialize ActiveLearner using modAL\n",
        "def create_active_learner(X_train, y_train, keras_model, query_strategy):\n",
        "\n",
        "    # Initialize the ActiveLearner\n",
        "    learner = ActiveLearner(\n",
        "        estimator=keras_model,\n",
        "        X_training=X_train,\n",
        "        y_training=y_train,\n",
        "        query_strategy=query_strategy  # Use uncertainty sampling\n",
        "    )\n",
        "\n",
        "    return learner"
      ],
      "metadata": {
        "id": "NkztustQ4d7b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Step 3: Active learning loop with custom stopping criteria (Stabilizing Predictions) and n_queries support\n",
        "def active_learning_loop(learner, X_pool, y_pool, X_stop_set, y_stop, X_sample, y_sample, task = \"bin_clf\", n_queries=10, stability_threshold=0.01, max_iterations=100, beta = 0.9):\n",
        "    min_loss = float('inf')  # Initialize to a very large value (since we want to minimize the loss)\n",
        "    iterations = 0\n",
        "    streak = 0\n",
        "\n",
        "    while iterations < max_iterations and len(X_pool) >= n_queries:\n",
        "        if iterations % 10 == 0:\n",
        "          print(f\"Iteration {iterations + 1}: Current Loss = {min_loss:.4f}, Min Loss = {min_loss:.4f} with pool {len(X_pool)}\")\n",
        "\n",
        "\n",
        "        if learner.query_strategy == conflicting_evidence_strategy_clf:\n",
        "            query_idx, query_instance = learner.query(X_pool, n_instances=n_queries, task = task)\n",
        "\n",
        "            # Teach the model using the queried instances\n",
        "            learner.teach(X_pool[query_idx], y_pool[query_idx])\n",
        "\n",
        "            # Remove queried instances from the pool\n",
        "            X_pool = np.delete(X_pool, query_idx, axis=0)\n",
        "            y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "\n",
        "        elif learner.query_strategy == conflicting_evidence_strategy_reg:\n",
        "            query_idx, query_instance = learner.query(X_pool, n_instances=n_queries, task = task)\n",
        "\n",
        "            # Teach the model using the queried instances\n",
        "            learner.teach(X_pool[query_idx], y_pool[query_idx])\n",
        "\n",
        "            # Remove queried instances from the pool\n",
        "            X_pool = np.delete(X_pool, query_idx, axis=0)\n",
        "            y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "        else:\n",
        "            # Need to query with the full dataset which is in sample\n",
        "            query_idx, query_instance = learner.query(X_sample, n_instances=n_queries, task = task, beta = beta)\n",
        "\n",
        "            # Manual of the teach function\n",
        "            X_pool = query_instance\n",
        "            y_pool = y_sample[query_idx]\n",
        "            learner.X_training = X_pool\n",
        "            learner.y_training = y_pool\n",
        "            learner.estimator.fit(X_pool, y_pool)\n",
        "\n",
        "        if learner.query_strategy == conflicting_evidence_strategy_clf:\n",
        "\n",
        "            # Evaluate the learner's predictions (probabilities) on the stop set\n",
        "            if task == \"bin_clf\":\n",
        "              y_pred = learner.predict_proba(X_stop_set)\n",
        "              current_loss = evidential_loss(y_stop, y_pred)\n",
        "\n",
        "            elif task == \"multi_clf\":\n",
        "              y_pred = learner.predict_proba(X_stop_set)\n",
        "              current_loss = evidential_loss(y_stop, y_pred)\n",
        "\n",
        "        elif learner.query_strategy == conflicting_evidence_strategy_reg:\n",
        "              y_stop_pred = learner.estimator.model.predict(X_stop_set, verbose = 0)\n",
        "              y_stop_pred[:, 2] += 1\n",
        "              current_loss = EvidentialRegressionLoss(y_stop, y_stop_pred)\n",
        "\n",
        "        else:\n",
        "            if task == \"bin_clf\":\n",
        "              y_pred = learner.predict_proba(X_stop_set)\n",
        "              current_loss = log_loss(y_stop, y_pred)\n",
        "\n",
        "            elif task == \"multi_clf\":\n",
        "              y_pred = learner.predict_proba(X_stop_set)\n",
        "              current_loss = np.mean(sparse_categorical_crossentropy(y_stop, y_pred))\n",
        "\n",
        "            elif task == \"reg\":\n",
        "              y_pred = learner.predict(X_stop_set)\n",
        "              current_loss = mean_squared_error(y_stop, y_pred)\n",
        "\n",
        "            else:\n",
        "              raise ValueError(\"Invalid task specified. Must be 'bin_clf', 'multi_clf', or 'reg'.\")\n",
        "\n",
        "        #print(f\"Iteration {iterations + 1}: Current Loss = {current_loss:.4f}, Min Loss = {min_loss:.4f} with pool {len(X_pool)}\")\n",
        "\n",
        "        # Check if current loss is better (lower) than the minimum observed so far\n",
        "        if current_loss < min_loss:\n",
        "            min_loss = current_loss\n",
        "            streak = 0  # Reset the streak when the loss improves\n",
        "        elif streak == 3:  # Stop if the loss hasn't improved for 5 consecutive iterations\n",
        "            print(f\"Iteration {iterations + 1}: Current Loss = {current_loss:.4f}, Min Loss = {min_loss:.4f}\")\n",
        "            break\n",
        "        else:\n",
        "            streak += 1  # Increment the streak if there's no improvement\n",
        "\n",
        "        iterations += 1\n",
        "\n",
        "    print(f\"Active learning stopped after {iterations} iterations with loss {min_loss:.4f}.\")\n",
        "\n",
        "    return min_loss"
      ],
      "metadata": {
        "id": "k3EuRv1t5o0z"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import make_regression\n",
        "from scikeras.wrappers import KerasRegressor, KerasClassifier\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Step 4: Main function to use a stop set and custom stopping criterion\n",
        "def main(query_strategy, X = None, y = None, task = \"bin_clf\", nodes = 64, n_queries = 25, stability_threshold=0.01, n_folds=5, init_size = 0.05, beta = 0.9):\n",
        "    if query_strategy == sensitivity_strategy:\n",
        "      print(f\"\\nNew training with nodes {nodes} and beta {beta}\")\n",
        "    else:\n",
        "      print(f\"\\nNew training with nodes {nodes} and n_queries {n_queries}\")\n",
        "\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # Standardize the dataset\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Perform 5-fold cross-validation\n",
        "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # List to store trained models\n",
        "    models = []\n",
        "    losses = []\n",
        "\n",
        "    # Loop through each fold\n",
        "    for fold_idx, (train_idx, stop_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Processing Fold {fold_idx + 1}/{n_folds}...\")\n",
        "\n",
        "        # Create training and stop sets for this fold\n",
        "        X_train, X_stop_set = X[train_idx], X[stop_idx]\n",
        "        y_train, y_stop = y[train_idx], y[stop_idx]\n",
        "\n",
        "        sample_idx = np.random.choice(len(X_train),\n",
        "                                      size=int(init_size * len(X_train)),\n",
        "                                      replace=False)\n",
        "\n",
        "        ce_strat = query_strategy == conflicting_evidence_strategy_clf or query_strategy == conflicting_evidence_strategy_reg\n",
        "\n",
        "        if ce_strat:\n",
        "            X_sample = X_train[sample_idx]\n",
        "            y_sample = y_train[sample_idx]\n",
        "            X_train = np.delete(X_train, sample_idx, axis=0)\n",
        "            y_train = np.delete(y_train, sample_idx, axis=0)\n",
        "\n",
        "        elif query_strategy == sensitivity_strategy:\n",
        "            #Starts with the full set\n",
        "            X_sample = X_train\n",
        "            y_sample = y_train\n",
        "\n",
        "        # Define EarlyStopping callback\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "\n",
        "\n",
        "\n",
        "        if ce_strat :\n",
        "            if task == \"bin_clf\":\n",
        "                #Reshape ys\n",
        "                n_classes = len(np.unique(y))\n",
        "                y_sample = tf.keras.utils.to_categorical(y_sample, num_classes=n_classes)\n",
        "                y_train = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
        "                y_stop = tf.keras.utils.to_categorical(y_stop, num_classes=n_classes)\n",
        "\n",
        "                model = create_clf_evidential_model(nodes, n_features = X.shape[1], n_classes = n_classes)\n",
        "                keras_model = KerasClassifier(model=model, epochs=10, batch_size=32, verbose=0,\n",
        "                                              validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "            elif task == \"multi_clf\":\n",
        "                #Reshape ys\n",
        "                n_classes = len(np.unique(y))\n",
        "                y_sample = tf.keras.utils.to_categorical(y_sample, num_classes=n_classes)\n",
        "                y_train = tf.keras.utils.to_categorical(y_train, num_classes=n_classes)\n",
        "                y_stop = tf.keras.utils.to_categorical(y_stop, num_classes=n_classes)\n",
        "\n",
        "\n",
        "                model = create_clf_evidential_model(nodes, n_features = X.shape[1], n_classes = n_classes)\n",
        "                keras_model = KerasClassifier(model=model, epochs=10, batch_size=32, verbose=0,\n",
        "                                              validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "            elif task == \"reg\":\n",
        "                model = create_reg_model(nodes=nodes, n_features=X.shape[1])\n",
        "                keras_model = KerasRegressor(model=model, epochs=10, batch_size=32, verbose=0,\n",
        "                                            validation_split=0.2, callbacks=[early_stopping])\n",
        "            else:\n",
        "                raise ValueError(\"Invalid task specified. Must be 'bin_clf', 'multi_clf', or 'reg'.\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            if task == \"bin_clf\":\n",
        "                model = create_clf_model(nodes=nodes, n_features=X.shape[1])\n",
        "                keras_model = KerasClassifier(model=model, epochs=10, batch_size=32, verbose=0,\n",
        "                                              validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "            elif task == \"multi_clf\":\n",
        "                model = create_multi_clf_model(nodes=nodes, n_features=X.shape[1], n_classes = len(np.unique(y)))\n",
        "                keras_model = KerasClassifier(model=model, epochs=10, batch_size=32, verbose=0,\n",
        "                                              validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "            elif task == \"reg\":\n",
        "                model = create_reg_model(nodes=nodes, n_features=X.shape[1])\n",
        "                keras_model = KerasRegressor(model=model, epochs=10, batch_size=32, verbose=0,\n",
        "                                            validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "            else:\n",
        "                raise ValueError(\"Invalid task specified. Must be 'bin_clf', 'multi_clf', or 'reg'.\")\n",
        "\n",
        "\n",
        "        # Create the active learner with the provided query strategy\n",
        "        learner = create_active_learner(X_sample, y_sample, keras_model, query_strategy)\n",
        "\n",
        "        # Run the active learning loop with custom stop set criterion\n",
        "        min_loss = active_learning_loop(learner, X_train, y_train, X_stop_set, y_stop, X_sample, y_sample, task = task, n_queries=n_queries, stability_threshold=stability_threshold, beta = beta)\n",
        "\n",
        "        # Save the trained learner (model) for this fold\n",
        "        models.append(learner.estimator)\n",
        "        losses.append(min_loss)\n",
        "\n",
        "    avg_loss = np.mean(losses)\n",
        "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Return all trained models (one per fold)\n",
        "    return avg_loss"
      ],
      "metadata": {
        "id": "dSX57P1I5roe"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Query Strategy"
      ],
      "metadata": {
        "id": "uCV9d8KcMsfZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ALUS"
      ],
      "metadata": {
        "id": "UJ2L8EDHQXwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import fastshap\n",
        "import time\n",
        "\n",
        "def conflicting_evidence_strategy_clf(learner, X_pool, task = \"bin_clf\", n_instances=10, max = True):\n",
        "    classifier = learner.estimator.model_\n",
        "    preds = classifier.predict(X_pool, verbose = 0)\n",
        "    alpha = np.maximum(preds, 0) + 1  # Convert output to evidence\n",
        "\n",
        "    evidence_scores = []\n",
        "    orig_ind = []\n",
        "\n",
        "    # Get total evidence for when more than one evidence value\n",
        "    for i in range(len(alpha)):\n",
        "        sorted_evidence = np.sort(alpha[i])\n",
        "        evidence_score = sorted_evidence[-1] * sorted_evidence[-2]  # Multiply top two highest evidence values\n",
        "\n",
        "        if sorted_evidence[-2] > 1.0:\n",
        "          orig_ind.append(i)\n",
        "          evidence_scores.append(evidence_score)\n",
        "\n",
        "    # Sort the evidence scores\n",
        "    num_scores = len(evidence_scores)\n",
        "    #print(f\"Length of evidence scores is {num_scores}\")\n",
        "\n",
        "    if num_scores == 0:\n",
        "      evidence_scores = np.max(alpha, axis = 1)\n",
        "      inds = np.argsort(evidence_scores)[:n_instances]  # Sort in descending order of evidence scores\n",
        "      return inds, X_pool[inds]\n",
        "\n",
        "    evidence_scores = np.array(evidence_scores)\n",
        "\n",
        "    inds = []\n",
        "    if max == True:\n",
        "        sorted_indices = np.argsort(evidence_scores)[::-1]  # Sort in descending order of evidence scores\n",
        "        sorted_orig = np.array(orig_ind)[sorted_indices]\n",
        "        sorted_evidence_scores = evidence_scores[sorted_indices]\n",
        "\n",
        "        for i in range(min(n_instances, num_scores)):\n",
        "          inds.append(sorted_orig[i])\n",
        "          #print(sorted_evidence_scores[i])\n",
        "    else:\n",
        "        sorted_indices = np.argsort(evidence_scores)  # Sort in descending order of evidence scores\n",
        "        sorted_orig = np.array(orig_ind)[sorted_indices] #Orders references indicies\n",
        "        sorted_evidence_scores = evidence_scores[sorted_indices] #Gets the score\n",
        "\n",
        "        for i in range(num_scores - n_instances, num_scores):\n",
        "          inds.append(sorted_orig[i])\n",
        "          #print(sorted_evidence_scores[i])\n",
        "\n",
        "    inds = np.array(inds)\n",
        "    #print(f\"Inds are {inds}\")\n",
        "\n",
        "    # Return the indices and the corresponding instances\n",
        "    return inds, X_pool[inds]"
      ],
      "metadata": {
        "id": "SD04GdonEW2l"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conflicting_evidence_strategy_reg(learner, X_pool, task = \"reg\", n_instances=10, max = True):\n",
        "    regressor = learner.estimator.model_\n",
        "    preds = regressor.predict(X_pool, verbose = 0)\n",
        "\n",
        "    # Just using alpha because measure of uncertainty of variance which is where problems are\n",
        "    alpha = np.array(preds[:, 2])\n",
        "    sorted_indices = np.argsort(alpha)[:n_instances]\n",
        "\n",
        "    # Return the indices and the corresponding instances\n",
        "    return sorted_indices, X_pool[sorted_indices]"
      ],
      "metadata": {
        "id": "AJ3UFfiHn_Q-"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sensitivity"
      ],
      "metadata": {
        "id": "3AEcTyxvQZ7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Computing Sensitivity Matrix**\n",
        "$$\n",
        "S_{oz,ki}^{(p)} = (1 - o_k^{(p)}) o_k^{(p)} \\sum_{j=1}^{J} w_{kj} (1 - y_j^{(p)}) y_j^{(p)} v_{ji}\n",
        "$$\n",
        "\n",
        "- **Computing Output Sensitivity Vector**\n",
        "$$\n",
        "\\vec{S}_o^{(p)} = \\| S_{oz}^{(p)} \\|\n",
        "$$\n",
        "\n",
        "- **Computing Informativeness**\n",
        "$$\n",
        "\\Phi_{\\infty}^{(p)} = \\| \\vec{S}_o^{(p)} \\|_{\\infty} = \\max_k \\left\\{ |S_{o,k}^{(p)}| \\right\\}\n",
        "$$\n",
        "\n",
        "- **Computing Average Pattern Informativeness**\n",
        "$$\n",
        "\\overline{\\Phi}_\\infty = \\frac{1}{P_C} \\sum_{p=1}^{P_C} \\Phi_{\\infty}^{(p)}\n",
        "$$\n",
        "\n",
        "- **Applying Selection Operator**\n",
        "$$\n",
        "A(D_C, F(D_T; W)) = \\{ p \\in D_C \\ | \\ \\Phi_{\\infty}^{(p)} > \\psi(\\vec{\\Phi}_\\infty) \\}\n",
        "$$\n",
        "\n",
        "- **Threshold Function**\n",
        "$$\n",
        "\\psi(\\vec{\\Phi}_\\infty) = (1 - \\beta) \\overline{\\Phi}_\\infty\n",
        "$$\n"
      ],
      "metadata": {
        "id": "MUAIbnxLNcDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define a function that will return the hidden layer's output\n",
        "def get_hidden_layer_output(model, X_pool):\n",
        "\n",
        "    # Extract the hidden layer by name\n",
        "    input = model.get_layer('hidden_layer').input\n",
        "    hidden_layer = model.get_layer('hidden_layer').output\n",
        "\n",
        "    # Create a new model that outputs the hidden layer\n",
        "    intermediate_layer_model = Model(inputs=input, outputs=hidden_layer)\n",
        "\n",
        "    # Get the activations for the input X_pool\n",
        "    hidden_layer_activations = intermediate_layer_model.predict(X_pool, verbose = 0)\n",
        "\n",
        "    return hidden_layer_activations\n"
      ],
      "metadata": {
        "id": "b5VYm6ezQh-5"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to compute sensitivity matrix S(p)_oz\n",
        "def compute_sensitivity_matrix(X_pool, learner):\n",
        "    model = learner.estimator.model_\n",
        "\n",
        "    # Get weights between input-hidden and hidden-output layers\n",
        "    W_hidden_output = model.layers[-1].get_weights()[0]  # shape (hidden_units, output_units)\n",
        "    V_input_hidden = model.layers[0].get_weights()[0]    # shape (input_units, hidden_units)\n",
        "\n",
        "    # Get activations for the hidden layer and output layer\n",
        "    hidden_layer_activations = get_hidden_layer_output(model, X_pool)\n",
        "    output_layer_activations = model.predict(X_pool, verbose=0, batch_size=32)  # output layer predictions\n",
        "\n",
        "    # Getting shapes\n",
        "    input_shape = V_input_hidden.shape[0]\n",
        "    hidden_shape = W_hidden_output.shape[0]\n",
        "    output_shape = W_hidden_output.shape[1]\n",
        "\n",
        "    # Calculate sensitivity matrix S(p)_oz for each pattern\n",
        "    sensitivity_matrix = []\n",
        "    for idx, p in enumerate(X_pool):\n",
        "        o_p = output_layer_activations[idx]  # output activations for pattern p\n",
        "        y_p = hidden_layer_activations[idx]  # hidden layer activations for pattern p\n",
        "\n",
        "        # Equation (4) for sensitivity matrix computation\n",
        "        S_p_oz = np.zeros((input_shape, output_shape))  # shape (input_units, output_units)\n",
        "        for k in range(output_shape):  # output units\n",
        "            for i in range(input_shape):  # input units\n",
        "                # Summation over hidden units j\n",
        "                summation = sum(W_hidden_output[j, k] * y_p[j] * (1 - y_p[j]) * V_input_hidden[i, j] for j in range(W_hidden_output.shape[0]))\n",
        "                S_p_oz[i, k] = o_p[k] * (1 - o_p[k]) * summation\n",
        "        sensitivity_matrix.append(S_p_oz)\n",
        "\n",
        "    return np.array(sensitivity_matrix)"
      ],
      "metadata": {
        "id": "FXV1nytBQfQb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sensitivity-based query strategy\n",
        "def sensitivity_strategy(learner, X_pool, task = \"bin_clf\", beta=0.9, n_instances=None):\n",
        "    # Step 1: Initialize empty list to store informativeness values\n",
        "    informativeness_values = []\n",
        "\n",
        "    # Step 2: For each pattern in the pool (X_pool)\n",
        "    S_oz_all = compute_sensitivity_matrix(X_pool, learner) #Shape is input by output\n",
        "\n",
        "    for p in range(X_pool.shape[0]):\n",
        "        # Step 2.1: Compute output sensitivity vector S(p)_o\n",
        "        S_p_o = np.linalg.norm(S_oz_all[p], axis=0)\n",
        "\n",
        "        # Step 2.2: Compute informativeness for pattern p\n",
        "        Phi_p = np.max(np.abs(S_p_o))\n",
        "\n",
        "        # Step 2.3: Store informativeness value\n",
        "        informativeness_values.append(Phi_p)\n",
        "\n",
        "    # Step 3: Compute the average pattern informativeness over all patterns (Equation 12)\n",
        "    avg_informativeness = np.mean(informativeness_values)\n",
        "\n",
        "    # Step 4: Apply the selection threshold using beta (Equation 9)\n",
        "    threshold = (1 - beta) * avg_informativeness\n",
        "\n",
        "    # Step 5: Select the most informative patterns (informativeness > threshold)\n",
        "    selected_indices = [i for i, Phi_p in enumerate(informativeness_values) if Phi_p > threshold]\n",
        "\n",
        "    return selected_indices, X_pool[selected_indices]\n"
      ],
      "metadata": {
        "id": "QupukQCPMxXB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing"
      ],
      "metadata": {
        "id": "9q_BodiaMp_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Normal NN"
      ],
      "metadata": {
        "id": "Vaki6SGAP-7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Function to create a simple classification model with a single hidden layer\n",
        "def create_passive_clf_model(nodes, n_features, n_classes=2):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.InputLayer(input_shape=(n_features,)),\n",
        "        tf.keras.layers.Dense(nodes, activation='relu'),\n",
        "        tf.keras.layers.Dense(n_classes, activation='softmax')  # Use softmax for classification\n",
        "    ])\n",
        "    model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def create_passive_bin_clf(nodes, n_features):\n",
        "      model = tf.keras.Sequential([\n",
        "          tf.keras.layers.InputLayer(input_shape=(n_features,)),\n",
        "          tf.keras.layers.Dense(nodes, activation='relu'),\n",
        "          tf.keras.layers.Dense(1, activation='sigmoid')  # Use softmax for classification\n",
        "      ])\n",
        "      model.compile(optimizer = tf.keras.optimizers.SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "      return model\n",
        "\n",
        "# Function to perform K-fold cross-validation and return the average loss\n",
        "def train_passive_binary(X, y, nodes, task = \"binary\", n_folds=5):\n",
        "    # Standardize the dataset\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    # Initialize KFold cross-validation\n",
        "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    # Lists to store losses for each fold\n",
        "    losses = []\n",
        "    print(\"Getting here?\")\n",
        "\n",
        "    # Loop through each fold\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Processing Fold {fold_idx + 1}/{n_folds}...\")\n",
        "\n",
        "        # Split data into training and validation sets\n",
        "        X_train, X_val = X[train_idx], X[val_idx]\n",
        "        y_train, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        # Create the model\n",
        "        n_classes = len(np.unique(y))  # Number of unique classes\n",
        "\n",
        "        if task == \"bin_clf\":\n",
        "          model = create_passive_bin_clf(nodes=nodes, n_features=X.shape[1])\n",
        "        else:\n",
        "          model = create_passive_clf_model(nodes=nodes, n_features=X.shape[1], n_classes=n_classes)\n",
        "\n",
        "        # Early stopping callback\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=0)\n",
        "\n",
        "        # Train the model\n",
        "        history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val),\n",
        "                            callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "        # Evaluate on validation set and get loss\n",
        "        val_loss = model.evaluate(X_val, y_val, verbose=0)[0]\n",
        "        losses.append(val_loss)\n",
        "\n",
        "    # Calculate average loss across all folds\n",
        "    avg_loss = np.mean(losses)\n",
        "    print(f\"Average Loss across {n_folds} folds: {avg_loss:.4f}\")\n",
        "    return avg_loss\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a synthetic binary classification dataset\n",
        "    X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_classes=2, random_state=42)\n",
        "\n",
        "    # Perform 5-fold cross-validation with a single hidden layer of 64 nodes\n",
        "    #avg_loss = train_passive_binary(X, y, nodes=64, n_folds=5)\n"
      ],
      "metadata": {
        "id": "_flneq43QEY_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Practice"
      ],
      "metadata": {
        "id": "lSlpXJudYi6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#main(sensitivity_strategy)"
      ],
      "metadata": {
        "id": "b_v701yvVckA"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer, Real\n",
        "from functools import partial\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "# Generate regression data\n",
        "X, y = make_regression(n_samples=500, n_features=20, n_informative=15, noise=0.1, random_state=42)\n",
        "\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 20, name='nodes'),    # Number of nodes in the hidden layer\n",
        "    Integer(5, 50, name='n_queries')  # Number of queries in active learning\n",
        "]\n",
        "\n",
        "def objective(params):\n",
        "    nodes, n_queries = params  # Unpack the hyperparameters (nodes, n_queries)\n",
        "    query_strategy = conflicting_evidence_strategy_reg\n",
        "    return main(query_strategy, X = X, y = y, task = \"reg\", nodes=nodes, n_queries=n_queries, init_size = 0.1)\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")\n",
        "print(f\"Best value for beta: {result.x[1]}\")"
      ],
      "metadata": {
        "id": "dPdu6hXmLOSh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "49be35f1-9360-440d-cd4c-b725c7a54811"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New training with nodes 17 and n_queries 13\n",
            "Processing Fold 1/5...\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 360\n",
            "Iteration 11: Current Loss = 20.6345, Min Loss = 20.6345 with pool 230\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-8ff56a52c91d>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m result = gp_minimize(\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# Objective function to minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# Hyperparameter space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-92-8ff56a52c91d>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m  \u001b[0;31m# Unpack the hyperparameters (nodes, n_queries)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mquery_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconflicting_evidence_strategy_reg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"reg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-6f64d2b7ff79>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(query_strategy, X, y, task, nodes, n_queries, stability_threshold, n_folds, init_size, beta)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Run the active learning loop with custom stop set criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_learning_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_stop_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstability_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstability_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m# Save the trained learner (model) for this fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-528886f53535>\u001b[0m in \u001b[0;36mactive_learning_loop\u001b[0;34m(learner, X_pool, y_pool, X_stop_set, y_stop, X_sample, y_sample, task, n_queries, stability_threshold, max_iterations, beta)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Teach the model using the queried instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Remove queried instances from the pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, X, y, bootstrap, only_new, **fit_kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0monly_new\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_to_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             check_X_y(X, y, accept_sparse=True, ensure_2d=False, allow_nd=True, multi_output=True, dtype=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36m_fit_to_known\u001b[0;34m(self, bootstrap, **fit_kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mn_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         self._fit(\n\u001b[0m\u001b[1;32m    771\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         self._fit_keras_model(\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Create an iterator that yields batches for one epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         epoch_iterator = TFEpochIterator(\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             dataset = self._distribute_strategy.experimental_distribute_dataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrab_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             dataset = dataset.map(\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0mgrab_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2309\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2311\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     return _ParallelMapDataset(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    161\u001b[0m         num_parallel_calls, dtype=dtypes.int64, name=\"num_parallel_calls\")\n\u001b[1;32m    162\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     variant_tensor = gen_dataset_ops.parallel_map_dataset_v2(\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mparallel_map_dataset_v2\u001b[0;34m(input_dataset, other_arguments, num_parallel_calls, f, output_types, output_shapes, use_inter_op_parallelism, deterministic, preserve_cardinality, metadata, name)\u001b[0m\n\u001b[1;32m   5852\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5853\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5854\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   5855\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ParallelMapDatasetV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_arguments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5856\u001b[0m         \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiclass Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer\n",
        "from functools import partial\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=40, n_informative=30, n_redundant=10, n_classes=4, random_state=42)\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 200, name='nodes'),    # Number of nodes in the hidden layer\n",
        "    Integer(5, 50, name='n_queries')   # Number of queries in active learning\n",
        "]\n",
        "\n",
        "def objective(params):\n",
        "    query_strategy = conflicting_evidence_strategy_clf\n",
        "    nodes, n_queries = params  # Unpack the hyperparameters (nodes, n_queries)\n",
        "    return main(query_strategy, X = X, y = y, task = \"multi_clf\", nodes=nodes, n_queries=n_queries, init_size = 0.1)\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")\n",
        "print(f\"Best number of queries: {result.x[1]}\")\n"
      ],
      "metadata": {
        "id": "3uAlbxXCMsmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0506350-bfd1-4474-da5c-a27586f6538a"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New training with nodes 160 and n_queries 13\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9227, Min Loss = inf with pool 707\n",
            "Iteration 2: Current Loss = 0.9247, Min Loss = 0.9227 with pool 694\n",
            "Iteration 3: Current Loss = 0.9251, Min Loss = 0.9227 with pool 681\n",
            "Iteration 4: Current Loss = 0.9246, Min Loss = 0.9227 with pool 668\n",
            "Iteration 5: Current Loss = 0.9044, Min Loss = 0.9227 with pool 655\n",
            "Iteration 6: Current Loss = 0.9043, Min Loss = 0.9044 with pool 642\n",
            "Iteration 7: Current Loss = 0.9045, Min Loss = 0.9043 with pool 629\n",
            "Iteration 8: Current Loss = 0.8958, Min Loss = 0.9043 with pool 616\n",
            "Iteration 9: Current Loss = 0.8897, Min Loss = 0.8958 with pool 603\n",
            "Iteration 10: Current Loss = 0.8777, Min Loss = 0.8897 with pool 590\n",
            "Iteration 11: Current Loss = 0.8709, Min Loss = 0.8777 with pool 577\n",
            "Iteration 12: Current Loss = 0.8663, Min Loss = 0.8709 with pool 564\n",
            "Iteration 13: Current Loss = 0.8645, Min Loss = 0.8663 with pool 551\n",
            "Iteration 14: Current Loss = 0.8626, Min Loss = 0.8645 with pool 538\n",
            "Iteration 15: Current Loss = 0.8565, Min Loss = 0.8626 with pool 525\n",
            "Iteration 16: Current Loss = 0.8543, Min Loss = 0.8565 with pool 512\n",
            "Iteration 17: Current Loss = 0.8485, Min Loss = 0.8543 with pool 499\n",
            "Iteration 18: Current Loss = 0.8437, Min Loss = 0.8485 with pool 486\n",
            "Iteration 19: Current Loss = 0.8365, Min Loss = 0.8437 with pool 473\n",
            "Iteration 20: Current Loss = 0.8345, Min Loss = 0.8365 with pool 460\n",
            "Iteration 21: Current Loss = 0.8262, Min Loss = 0.8345 with pool 447\n",
            "Iteration 22: Current Loss = 0.8244, Min Loss = 0.8262 with pool 434\n",
            "Iteration 23: Current Loss = 0.8169, Min Loss = 0.8244 with pool 421\n",
            "Iteration 24: Current Loss = 0.8198, Min Loss = 0.8169 with pool 408\n",
            "Iteration 25: Current Loss = 0.8116, Min Loss = 0.8169 with pool 395\n",
            "Iteration 26: Current Loss = 0.8043, Min Loss = 0.8116 with pool 382\n",
            "Iteration 27: Current Loss = 0.8047, Min Loss = 0.8043 with pool 371\n",
            "Iteration 28: Current Loss = 0.7987, Min Loss = 0.8043 with pool 360\n",
            "Iteration 29: Current Loss = 0.7975, Min Loss = 0.7987 with pool 357\n",
            "Iteration 30: Current Loss = 0.7922, Min Loss = 0.7975 with pool 344\n",
            "Iteration 31: Current Loss = 0.7904, Min Loss = 0.7922 with pool 340\n",
            "Iteration 32: Current Loss = 0.7909, Min Loss = 0.7904 with pool 335\n",
            "Iteration 33: Current Loss = 0.7897, Min Loss = 0.7904 with pool 332\n",
            "Iteration 34: Current Loss = 0.7891, Min Loss = 0.7897 with pool 324\n",
            "Iteration 35: Current Loss = 0.7879, Min Loss = 0.7891 with pool 320\n",
            "Iteration 36: Current Loss = 0.7871, Min Loss = 0.7879 with pool 314\n",
            "Iteration 37: Current Loss = 0.7837, Min Loss = 0.7871 with pool 311\n",
            "Iteration 38: Current Loss = 0.7871, Min Loss = 0.7837 with pool 309\n",
            "Iteration 39: Current Loss = 0.7884, Min Loss = 0.7837 with pool 307\n",
            "Iteration 40: Current Loss = 0.7917, Min Loss = 0.7837 with pool 301\n",
            "Iteration 41: Current Loss = 0.7911, Min Loss = 0.7837 with pool 294\n",
            "Iteration 41: Current Loss = 0.7911, Min Loss = 0.7837\n",
            "Active learning stopped after 40 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9381, Min Loss = inf with pool 707\n",
            "Iteration 2: Current Loss = 0.9338, Min Loss = 0.9381 with pool 694\n",
            "Iteration 3: Current Loss = 0.9297, Min Loss = 0.9338 with pool 681\n",
            "Iteration 4: Current Loss = 0.9009, Min Loss = 0.9297 with pool 668\n",
            "Iteration 5: Current Loss = 0.9008, Min Loss = 0.9009 with pool 655\n",
            "Iteration 6: Current Loss = 0.8996, Min Loss = 0.9008 with pool 642\n",
            "Iteration 7: Current Loss = 0.9097, Min Loss = 0.8996 with pool 629\n",
            "Iteration 8: Current Loss = 0.9119, Min Loss = 0.8996 with pool 616\n",
            "Iteration 9: Current Loss = 0.9098, Min Loss = 0.8996 with pool 603\n",
            "Iteration 10: Current Loss = 0.9063, Min Loss = 0.8996 with pool 590\n",
            "Iteration 10: Current Loss = 0.9063, Min Loss = 0.8996\n",
            "Active learning stopped after 9 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9394, Min Loss = inf with pool 707\n",
            "Iteration 2: Current Loss = 0.9368, Min Loss = 0.9394 with pool 694\n",
            "Iteration 3: Current Loss = 0.9327, Min Loss = 0.9368 with pool 681\n",
            "Iteration 4: Current Loss = 0.9210, Min Loss = 0.9327 with pool 668\n",
            "Iteration 5: Current Loss = 0.8916, Min Loss = 0.9210 with pool 655\n",
            "Iteration 6: Current Loss = 0.8909, Min Loss = 0.8916 with pool 642\n",
            "Iteration 7: Current Loss = 0.8900, Min Loss = 0.8909 with pool 629\n",
            "Iteration 8: Current Loss = 0.8875, Min Loss = 0.8900 with pool 616\n",
            "Iteration 9: Current Loss = 0.8715, Min Loss = 0.8875 with pool 603\n",
            "Iteration 10: Current Loss = 0.8699, Min Loss = 0.8715 with pool 590\n",
            "Iteration 11: Current Loss = 0.8651, Min Loss = 0.8699 with pool 577\n",
            "Iteration 12: Current Loss = 0.8642, Min Loss = 0.8651 with pool 564\n",
            "Iteration 13: Current Loss = 0.8631, Min Loss = 0.8642 with pool 551\n",
            "Iteration 14: Current Loss = 0.8582, Min Loss = 0.8631 with pool 538\n",
            "Iteration 15: Current Loss = 0.8506, Min Loss = 0.8582 with pool 525\n",
            "Iteration 16: Current Loss = 0.8443, Min Loss = 0.8506 with pool 512\n",
            "Iteration 17: Current Loss = 0.8395, Min Loss = 0.8443 with pool 499\n",
            "Iteration 18: Current Loss = 0.8291, Min Loss = 0.8395 with pool 486\n",
            "Iteration 19: Current Loss = 0.8224, Min Loss = 0.8291 with pool 473\n",
            "Iteration 20: Current Loss = 0.8188, Min Loss = 0.8224 with pool 460\n",
            "Iteration 21: Current Loss = 0.8161, Min Loss = 0.8188 with pool 452\n",
            "Iteration 22: Current Loss = 0.8131, Min Loss = 0.8161 with pool 446\n",
            "Iteration 23: Current Loss = 0.8119, Min Loss = 0.8131 with pool 445\n",
            "Iteration 24: Current Loss = 0.8114, Min Loss = 0.8119 with pool 439\n",
            "Iteration 25: Current Loss = 0.8061, Min Loss = 0.8114 with pool 435\n",
            "Iteration 26: Current Loss = 0.8070, Min Loss = 0.8061 with pool 433\n",
            "Iteration 27: Current Loss = 0.8074, Min Loss = 0.8061 with pool 423\n",
            "Iteration 28: Current Loss = 0.8074, Min Loss = 0.8061 with pool 417\n",
            "Iteration 29: Current Loss = 0.8078, Min Loss = 0.8061 with pool 416\n",
            "Iteration 29: Current Loss = 0.8078, Min Loss = 0.8061\n",
            "Active learning stopped after 28 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7ebde56200d0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Current Loss = 0.9236, Min Loss = inf with pool 707\n",
            "Iteration 2: Current Loss = 0.9210, Min Loss = 0.9236 with pool 694\n",
            "Iteration 3: Current Loss = 0.9151, Min Loss = 0.9210 with pool 681\n",
            "Iteration 4: Current Loss = 0.8894, Min Loss = 0.9151 with pool 668\n",
            "Iteration 5: Current Loss = 0.8902, Min Loss = 0.8894 with pool 655\n",
            "Iteration 6: Current Loss = 0.8894, Min Loss = 0.8894 with pool 642\n",
            "Iteration 7: Current Loss = 0.8795, Min Loss = 0.8894 with pool 629\n",
            "Iteration 8: Current Loss = 0.8783, Min Loss = 0.8795 with pool 616\n",
            "Iteration 9: Current Loss = 0.8733, Min Loss = 0.8783 with pool 603\n",
            "Iteration 10: Current Loss = 0.8691, Min Loss = 0.8733 with pool 590\n",
            "Iteration 11: Current Loss = 0.8620, Min Loss = 0.8691 with pool 577\n",
            "Iteration 12: Current Loss = 0.8593, Min Loss = 0.8620 with pool 564\n",
            "Iteration 13: Current Loss = 0.8544, Min Loss = 0.8593 with pool 551\n",
            "Iteration 14: Current Loss = 0.8488, Min Loss = 0.8544 with pool 538\n",
            "Iteration 15: Current Loss = 0.8501, Min Loss = 0.8488 with pool 525\n",
            "Iteration 16: Current Loss = 0.8430, Min Loss = 0.8488 with pool 512\n",
            "Iteration 17: Current Loss = 0.8370, Min Loss = 0.8430 with pool 499\n",
            "Iteration 18: Current Loss = 0.8315, Min Loss = 0.8370 with pool 486\n",
            "Iteration 19: Current Loss = 0.8268, Min Loss = 0.8315 with pool 473\n",
            "Iteration 20: Current Loss = 0.8234, Min Loss = 0.8268 with pool 460\n",
            "Iteration 21: Current Loss = 0.8247, Min Loss = 0.8234 with pool 447\n",
            "Iteration 22: Current Loss = 0.8221, Min Loss = 0.8234 with pool 442\n",
            "Iteration 23: Current Loss = 0.8218, Min Loss = 0.8221 with pool 436\n",
            "Iteration 24: Current Loss = 0.8196, Min Loss = 0.8218 with pool 431\n",
            "Iteration 25: Current Loss = 0.8199, Min Loss = 0.8196 with pool 424\n",
            "Iteration 26: Current Loss = 0.8184, Min Loss = 0.8196 with pool 421\n",
            "Iteration 27: Current Loss = 0.8218, Min Loss = 0.8184 with pool 412\n",
            "Iteration 28: Current Loss = 0.8188, Min Loss = 0.8184 with pool 405\n",
            "Iteration 29: Current Loss = 0.8202, Min Loss = 0.8184 with pool 404\n",
            "Iteration 30: Current Loss = 0.8188, Min Loss = 0.8184 with pool 398\n",
            "Iteration 30: Current Loss = 0.8188, Min Loss = 0.8184\n",
            "Active learning stopped after 29 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9287, Min Loss = inf with pool 707\n",
            "Iteration 2: Current Loss = 0.9294, Min Loss = 0.9287 with pool 694\n",
            "Iteration 3: Current Loss = 0.9184, Min Loss = 0.9287 with pool 681\n",
            "Iteration 4: Current Loss = 0.9224, Min Loss = 0.9184 with pool 668\n",
            "Iteration 5: Current Loss = 0.9221, Min Loss = 0.9184 with pool 655\n",
            "Iteration 6: Current Loss = 0.9153, Min Loss = 0.9184 with pool 642\n",
            "Iteration 7: Current Loss = 0.9096, Min Loss = 0.9153 with pool 629\n",
            "Iteration 8: Current Loss = 0.9059, Min Loss = 0.9096 with pool 616\n",
            "Iteration 9: Current Loss = 0.9078, Min Loss = 0.9059 with pool 603\n",
            "Iteration 10: Current Loss = 0.9051, Min Loss = 0.9059 with pool 590\n",
            "Iteration 11: Current Loss = 0.9018, Min Loss = 0.9051 with pool 577\n",
            "Iteration 12: Current Loss = 0.8977, Min Loss = 0.9018 with pool 564\n",
            "Iteration 13: Current Loss = 0.8916, Min Loss = 0.8977 with pool 551\n",
            "Iteration 14: Current Loss = 0.8831, Min Loss = 0.8916 with pool 538\n",
            "Iteration 15: Current Loss = 0.8748, Min Loss = 0.8831 with pool 525\n",
            "Iteration 16: Current Loss = 0.8652, Min Loss = 0.8748 with pool 512\n",
            "Iteration 17: Current Loss = 0.8671, Min Loss = 0.8652 with pool 499\n",
            "Iteration 18: Current Loss = 0.8650, Min Loss = 0.8652 with pool 486\n",
            "Iteration 19: Current Loss = 0.8599, Min Loss = 0.8650 with pool 473\n",
            "Iteration 20: Current Loss = 0.8589, Min Loss = 0.8599 with pool 460\n",
            "Iteration 21: Current Loss = 0.8583, Min Loss = 0.8589 with pool 447\n",
            "Iteration 22: Current Loss = 0.8565, Min Loss = 0.8583 with pool 434\n",
            "Iteration 23: Current Loss = 0.8550, Min Loss = 0.8565 with pool 421\n",
            "Iteration 24: Current Loss = 0.8556, Min Loss = 0.8550 with pool 408\n",
            "Iteration 25: Current Loss = 0.8551, Min Loss = 0.8550 with pool 395\n",
            "Iteration 26: Current Loss = 0.8615, Min Loss = 0.8550 with pool 382\n",
            "Iteration 27: Current Loss = 0.8580, Min Loss = 0.8550 with pool 369\n",
            "Iteration 27: Current Loss = 0.8580, Min Loss = 0.8550\n",
            "Active learning stopped after 26 iterations.\n",
            "Average Loss: 0.8326\n",
            "\n",
            "New training with nodes 157 and n_queries 32\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9174, Min Loss = inf with pool 688\n",
            "Iteration 2: Current Loss = 0.8996, Min Loss = 0.9174 with pool 656\n",
            "Iteration 3: Current Loss = 0.8991, Min Loss = 0.8996 with pool 624\n",
            "Iteration 4: Current Loss = 0.8955, Min Loss = 0.8991 with pool 592\n",
            "Iteration 5: Current Loss = 0.8877, Min Loss = 0.8955 with pool 560\n",
            "Iteration 6: Current Loss = 0.8763, Min Loss = 0.8877 with pool 528\n",
            "Iteration 7: Current Loss = 0.8639, Min Loss = 0.8763 with pool 496\n",
            "Iteration 8: Current Loss = 0.8574, Min Loss = 0.8639 with pool 479\n",
            "Iteration 9: Current Loss = 0.8566, Min Loss = 0.8574 with pool 473\n",
            "Iteration 10: Current Loss = 0.8520, Min Loss = 0.8566 with pool 461\n",
            "Iteration 11: Current Loss = 0.8499, Min Loss = 0.8520 with pool 451\n",
            "Iteration 12: Current Loss = 0.8505, Min Loss = 0.8499 with pool 441\n",
            "Iteration 13: Current Loss = 0.8481, Min Loss = 0.8499 with pool 429\n",
            "Iteration 14: Current Loss = 0.8469, Min Loss = 0.8481 with pool 423\n",
            "Iteration 15: Current Loss = 0.8483, Min Loss = 0.8469 with pool 415\n",
            "Iteration 16: Current Loss = 0.8455, Min Loss = 0.8469 with pool 408\n",
            "Iteration 17: Current Loss = 0.8469, Min Loss = 0.8455 with pool 404\n",
            "Iteration 18: Current Loss = 0.8497, Min Loss = 0.8455 with pool 397\n",
            "Iteration 19: Current Loss = 0.8494, Min Loss = 0.8455 with pool 391\n",
            "Iteration 20: Current Loss = 0.8502, Min Loss = 0.8455 with pool 383\n",
            "Iteration 20: Current Loss = 0.8502, Min Loss = 0.8455\n",
            "Active learning stopped after 19 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9057, Min Loss = inf with pool 688\n",
            "Iteration 2: Current Loss = 0.9016, Min Loss = 0.9057 with pool 656\n",
            "Iteration 3: Current Loss = 0.8907, Min Loss = 0.9016 with pool 624\n",
            "Iteration 4: Current Loss = 0.8896, Min Loss = 0.8907 with pool 592\n",
            "Iteration 5: Current Loss = 0.8865, Min Loss = 0.8896 with pool 571\n",
            "Iteration 6: Current Loss = 0.8838, Min Loss = 0.8865 with pool 561\n",
            "Iteration 7: Current Loss = 0.8772, Min Loss = 0.8838 with pool 541\n",
            "Iteration 8: Current Loss = 0.8733, Min Loss = 0.8772 with pool 522\n",
            "Iteration 9: Current Loss = 0.8642, Min Loss = 0.8733 with pool 502\n",
            "Iteration 10: Current Loss = 0.8567, Min Loss = 0.8642 with pool 491\n",
            "Iteration 11: Current Loss = 0.8488, Min Loss = 0.8567 with pool 476\n",
            "Iteration 12: Current Loss = 0.8415, Min Loss = 0.8488 with pool 459\n",
            "Iteration 13: Current Loss = 0.8384, Min Loss = 0.8415 with pool 455\n",
            "Iteration 14: Current Loss = 0.8313, Min Loss = 0.8384 with pool 438\n",
            "Iteration 15: Current Loss = 0.8308, Min Loss = 0.8313 with pool 436\n",
            "Iteration 16: Current Loss = 0.8222, Min Loss = 0.8308 with pool 423\n",
            "Iteration 17: Current Loss = 0.8182, Min Loss = 0.8222 with pool 405\n",
            "Iteration 18: Current Loss = 0.8134, Min Loss = 0.8182 with pool 397\n",
            "Iteration 19: Current Loss = 0.8139, Min Loss = 0.8134 with pool 385\n",
            "Iteration 20: Current Loss = 0.7971, Min Loss = 0.8134 with pool 365\n",
            "Iteration 21: Current Loss = 0.7935, Min Loss = 0.7971 with pool 353\n",
            "Iteration 22: Current Loss = 0.7890, Min Loss = 0.7935 with pool 345\n",
            "Iteration 23: Current Loss = 0.7817, Min Loss = 0.7890 with pool 339\n",
            "Iteration 24: Current Loss = 0.7823, Min Loss = 0.7817 with pool 337\n",
            "Iteration 25: Current Loss = 0.7798, Min Loss = 0.7817 with pool 334\n",
            "Iteration 26: Current Loss = 0.7789, Min Loss = 0.7798 with pool 329\n",
            "Iteration 27: Current Loss = 0.7718, Min Loss = 0.7789 with pool 324\n",
            "Iteration 28: Current Loss = 0.7740, Min Loss = 0.7718 with pool 320\n",
            "Iteration 29: Current Loss = 0.7721, Min Loss = 0.7718 with pool 319\n",
            "Iteration 30: Current Loss = 0.7721, Min Loss = 0.7718 with pool 312\n",
            "Iteration 31: Current Loss = 0.7718, Min Loss = 0.7718 with pool 309\n",
            "Iteration 31: Current Loss = 0.7718, Min Loss = 0.7718\n",
            "Active learning stopped after 30 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9313, Min Loss = inf with pool 688\n",
            "Iteration 2: Current Loss = 0.8865, Min Loss = 0.9313 with pool 656\n",
            "Iteration 3: Current Loss = 0.8858, Min Loss = 0.8865 with pool 624\n",
            "Iteration 4: Current Loss = 0.8805, Min Loss = 0.8858 with pool 592\n",
            "Iteration 5: Current Loss = 0.8734, Min Loss = 0.8805 with pool 560\n",
            "Iteration 6: Current Loss = 0.8570, Min Loss = 0.8734 with pool 528\n",
            "Iteration 7: Current Loss = 0.8567, Min Loss = 0.8570 with pool 496\n",
            "Iteration 8: Current Loss = 0.8543, Min Loss = 0.8567 with pool 464\n",
            "Iteration 9: Current Loss = 0.8396, Min Loss = 0.8543 with pool 432\n",
            "Iteration 10: Current Loss = 0.8344, Min Loss = 0.8396 with pool 400\n",
            "Iteration 11: Current Loss = 0.8263, Min Loss = 0.8344 with pool 368\n",
            "Iteration 12: Current Loss = 0.8260, Min Loss = 0.8263 with pool 358\n",
            "Iteration 13: Current Loss = 0.8256, Min Loss = 0.8260 with pool 347\n",
            "Iteration 14: Current Loss = 0.8250, Min Loss = 0.8256 with pool 341\n",
            "Iteration 15: Current Loss = 0.8269, Min Loss = 0.8250 with pool 336\n",
            "Iteration 16: Current Loss = 0.8270, Min Loss = 0.8250 with pool 333\n",
            "Iteration 17: Current Loss = 0.8305, Min Loss = 0.8250 with pool 327\n",
            "Iteration 18: Current Loss = 0.8278, Min Loss = 0.8250 with pool 317\n",
            "Iteration 18: Current Loss = 0.8278, Min Loss = 0.8250\n",
            "Active learning stopped after 17 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.8994, Min Loss = inf with pool 688\n",
            "Iteration 2: Current Loss = 0.8964, Min Loss = 0.8994 with pool 656\n",
            "Iteration 3: Current Loss = 0.8617, Min Loss = 0.8964 with pool 624\n",
            "Iteration 4: Current Loss = 0.8449, Min Loss = 0.8617 with pool 592\n",
            "Iteration 5: Current Loss = 0.8440, Min Loss = 0.8449 with pool 560\n",
            "Iteration 6: Current Loss = 0.8390, Min Loss = 0.8440 with pool 528\n",
            "Iteration 7: Current Loss = 0.8330, Min Loss = 0.8390 with pool 496\n",
            "Iteration 8: Current Loss = 0.8305, Min Loss = 0.8330 with pool 479\n",
            "Iteration 9: Current Loss = 0.8284, Min Loss = 0.8305 with pool 469\n",
            "Iteration 10: Current Loss = 0.8263, Min Loss = 0.8284 with pool 455\n",
            "Iteration 11: Current Loss = 0.8225, Min Loss = 0.8263 with pool 448\n",
            "Iteration 12: Current Loss = 0.8182, Min Loss = 0.8225 with pool 445\n",
            "Iteration 13: Current Loss = 0.8159, Min Loss = 0.8182 with pool 443\n",
            "Iteration 14: Current Loss = 0.8157, Min Loss = 0.8159 with pool 440\n",
            "Iteration 15: Current Loss = 0.8120, Min Loss = 0.8157 with pool 436\n",
            "Iteration 16: Current Loss = 0.8139, Min Loss = 0.8120 with pool 433\n",
            "Iteration 17: Current Loss = 0.8136, Min Loss = 0.8120 with pool 428\n",
            "Iteration 18: Current Loss = 0.8131, Min Loss = 0.8120 with pool 424\n",
            "Iteration 19: Current Loss = 0.8108, Min Loss = 0.8120 with pool 392\n",
            "Iteration 20: Current Loss = 0.8089, Min Loss = 0.8108 with pool 388\n",
            "Iteration 21: Current Loss = 0.8037, Min Loss = 0.8089 with pool 381\n",
            "Iteration 22: Current Loss = 0.8083, Min Loss = 0.8037 with pool 376\n",
            "Iteration 23: Current Loss = 0.8095, Min Loss = 0.8037 with pool 371\n",
            "Iteration 24: Current Loss = 0.8117, Min Loss = 0.8037 with pool 370\n",
            "Iteration 25: Current Loss = 0.8117, Min Loss = 0.8037 with pool 366\n",
            "Iteration 25: Current Loss = 0.8117, Min Loss = 0.8037\n",
            "Active learning stopped after 24 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9473, Min Loss = inf with pool 688\n",
            "Iteration 2: Current Loss = 0.9358, Min Loss = 0.9473 with pool 656\n",
            "Iteration 3: Current Loss = 0.9148, Min Loss = 0.9358 with pool 624\n",
            "Iteration 4: Current Loss = 0.8818, Min Loss = 0.9148 with pool 592\n",
            "Iteration 5: Current Loss = 0.8797, Min Loss = 0.8818 with pool 560\n",
            "Iteration 6: Current Loss = 0.8747, Min Loss = 0.8797 with pool 528\n",
            "Iteration 7: Current Loss = 0.8675, Min Loss = 0.8747 with pool 496\n",
            "Iteration 8: Current Loss = 0.8569, Min Loss = 0.8675 with pool 464\n",
            "Iteration 9: Current Loss = 0.8507, Min Loss = 0.8569 with pool 432\n",
            "Iteration 10: Current Loss = 0.8475, Min Loss = 0.8507 with pool 401\n",
            "Iteration 11: Current Loss = 0.8473, Min Loss = 0.8475 with pool 388\n",
            "Iteration 12: Current Loss = 0.8471, Min Loss = 0.8473 with pool 380\n",
            "Iteration 13: Current Loss = 0.8427, Min Loss = 0.8471 with pool 371\n",
            "Iteration 14: Current Loss = 0.8387, Min Loss = 0.8427 with pool 365\n",
            "Iteration 15: Current Loss = 0.8399, Min Loss = 0.8387 with pool 362\n",
            "Iteration 16: Current Loss = 0.8362, Min Loss = 0.8387 with pool 355\n",
            "Iteration 17: Current Loss = 0.8353, Min Loss = 0.8362 with pool 343\n",
            "Iteration 18: Current Loss = 0.8319, Min Loss = 0.8353 with pool 337\n",
            "Iteration 19: Current Loss = 0.8270, Min Loss = 0.8319 with pool 334\n",
            "Iteration 20: Current Loss = 0.8269, Min Loss = 0.8270 with pool 328\n",
            "Iteration 21: Current Loss = 0.8276, Min Loss = 0.8269 with pool 322\n",
            "Iteration 22: Current Loss = 0.8232, Min Loss = 0.8269 with pool 318\n",
            "Iteration 23: Current Loss = 0.8252, Min Loss = 0.8232 with pool 312\n",
            "Iteration 24: Current Loss = 0.8240, Min Loss = 0.8232 with pool 310\n",
            "Iteration 25: Current Loss = 0.8197, Min Loss = 0.8232 with pool 302\n",
            "Iteration 26: Current Loss = 0.8223, Min Loss = 0.8197 with pool 300\n",
            "Iteration 27: Current Loss = 0.8232, Min Loss = 0.8197 with pool 299\n",
            "Iteration 28: Current Loss = 0.8226, Min Loss = 0.8197 with pool 298\n",
            "Iteration 29: Current Loss = 0.8241, Min Loss = 0.8197 with pool 296\n",
            "Iteration 29: Current Loss = 0.8241, Min Loss = 0.8197\n",
            "Active learning stopped after 28 iterations.\n",
            "Average Loss: 0.8131\n",
            "\n",
            "New training with nodes 92 and n_queries 9\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9631, Min Loss = inf with pool 711\n",
            "Iteration 2: Current Loss = 0.9594, Min Loss = 0.9631 with pool 702\n",
            "Iteration 3: Current Loss = 0.9568, Min Loss = 0.9594 with pool 693\n",
            "Iteration 4: Current Loss = 0.9533, Min Loss = 0.9568 with pool 684\n",
            "Iteration 5: Current Loss = 0.9475, Min Loss = 0.9533 with pool 675\n",
            "Iteration 6: Current Loss = 0.9417, Min Loss = 0.9475 with pool 666\n",
            "Iteration 7: Current Loss = 0.9355, Min Loss = 0.9417 with pool 657\n",
            "Iteration 8: Current Loss = 0.9262, Min Loss = 0.9355 with pool 648\n",
            "Iteration 9: Current Loss = 0.9256, Min Loss = 0.9262 with pool 639\n",
            "Iteration 10: Current Loss = 0.9244, Min Loss = 0.9256 with pool 630\n",
            "Iteration 11: Current Loss = 0.9191, Min Loss = 0.9244 with pool 621\n",
            "Iteration 12: Current Loss = 0.9136, Min Loss = 0.9191 with pool 612\n",
            "Iteration 13: Current Loss = 0.9064, Min Loss = 0.9136 with pool 603\n",
            "Iteration 14: Current Loss = 0.8864, Min Loss = 0.9064 with pool 594\n",
            "Iteration 15: Current Loss = 0.8870, Min Loss = 0.8864 with pool 585\n",
            "Iteration 16: Current Loss = 0.8812, Min Loss = 0.8864 with pool 576\n",
            "Iteration 17: Current Loss = 0.8789, Min Loss = 0.8812 with pool 567\n",
            "Iteration 18: Current Loss = 0.8782, Min Loss = 0.8789 with pool 558\n",
            "Iteration 19: Current Loss = 0.8798, Min Loss = 0.8782 with pool 549\n",
            "Iteration 20: Current Loss = 0.8781, Min Loss = 0.8782 with pool 540\n",
            "Iteration 21: Current Loss = 0.8776, Min Loss = 0.8781 with pool 531\n",
            "Iteration 22: Current Loss = 0.8758, Min Loss = 0.8776 with pool 522\n",
            "Iteration 23: Current Loss = 0.8745, Min Loss = 0.8758 with pool 513\n",
            "Iteration 24: Current Loss = 0.8706, Min Loss = 0.8745 with pool 504\n",
            "Iteration 25: Current Loss = 0.8711, Min Loss = 0.8706 with pool 495\n",
            "Iteration 26: Current Loss = 0.8691, Min Loss = 0.8706 with pool 486\n",
            "Iteration 27: Current Loss = 0.8719, Min Loss = 0.8691 with pool 477\n",
            "Iteration 28: Current Loss = 0.8693, Min Loss = 0.8691 with pool 468\n",
            "Iteration 29: Current Loss = 0.8665, Min Loss = 0.8691 with pool 459\n",
            "Iteration 30: Current Loss = 0.8653, Min Loss = 0.8665 with pool 450\n",
            "Iteration 31: Current Loss = 0.8631, Min Loss = 0.8653 with pool 441\n",
            "Iteration 32: Current Loss = 0.8652, Min Loss = 0.8631 with pool 432\n",
            "Iteration 33: Current Loss = 0.8642, Min Loss = 0.8631 with pool 423\n",
            "Iteration 34: Current Loss = 0.8628, Min Loss = 0.8631 with pool 420\n",
            "Iteration 35: Current Loss = 0.8635, Min Loss = 0.8628 with pool 411\n",
            "Iteration 36: Current Loss = 0.8634, Min Loss = 0.8628 with pool 405\n",
            "Iteration 37: Current Loss = 0.8679, Min Loss = 0.8628 with pool 402\n",
            "Iteration 38: Current Loss = 0.8714, Min Loss = 0.8628 with pool 399\n",
            "Iteration 38: Current Loss = 0.8714, Min Loss = 0.8628\n",
            "Active learning stopped after 37 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9532, Min Loss = inf with pool 711\n",
            "Iteration 2: Current Loss = 0.9528, Min Loss = 0.9532 with pool 702\n",
            "Iteration 3: Current Loss = 0.9513, Min Loss = 0.9528 with pool 693\n",
            "Iteration 4: Current Loss = 0.9488, Min Loss = 0.9513 with pool 684\n",
            "Iteration 5: Current Loss = 0.9427, Min Loss = 0.9488 with pool 675\n",
            "Iteration 6: Current Loss = 0.9191, Min Loss = 0.9427 with pool 666\n",
            "Iteration 7: Current Loss = 0.9217, Min Loss = 0.9191 with pool 657\n",
            "Iteration 8: Current Loss = 0.9240, Min Loss = 0.9191 with pool 648\n",
            "Iteration 9: Current Loss = 0.9236, Min Loss = 0.9191 with pool 639\n",
            "Iteration 10: Current Loss = 0.9211, Min Loss = 0.9191 with pool 630\n",
            "Iteration 10: Current Loss = 0.9211, Min Loss = 0.9191\n",
            "Active learning stopped after 9 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9389, Min Loss = inf with pool 711\n",
            "Iteration 2: Current Loss = 0.9384, Min Loss = 0.9389 with pool 702\n",
            "Iteration 3: Current Loss = 0.9274, Min Loss = 0.9384 with pool 693\n",
            "Iteration 4: Current Loss = 0.9234, Min Loss = 0.9274 with pool 684\n",
            "Iteration 5: Current Loss = 0.9229, Min Loss = 0.9234 with pool 675\n",
            "Iteration 6: Current Loss = 0.9211, Min Loss = 0.9229 with pool 666\n",
            "Iteration 7: Current Loss = 0.9179, Min Loss = 0.9211 with pool 657\n",
            "Iteration 8: Current Loss = 0.9142, Min Loss = 0.9179 with pool 648\n",
            "Iteration 9: Current Loss = 0.9091, Min Loss = 0.9142 with pool 639\n",
            "Iteration 10: Current Loss = 0.9014, Min Loss = 0.9091 with pool 630\n",
            "Iteration 11: Current Loss = 0.8931, Min Loss = 0.9014 with pool 621\n",
            "Iteration 12: Current Loss = 0.8720, Min Loss = 0.8931 with pool 612\n",
            "Iteration 13: Current Loss = 0.8707, Min Loss = 0.8720 with pool 603\n",
            "Iteration 14: Current Loss = 0.8684, Min Loss = 0.8707 with pool 594\n",
            "Iteration 15: Current Loss = 0.8649, Min Loss = 0.8684 with pool 585\n",
            "Iteration 16: Current Loss = 0.8598, Min Loss = 0.8649 with pool 576\n",
            "Iteration 17: Current Loss = 0.8582, Min Loss = 0.8598 with pool 567\n",
            "Iteration 18: Current Loss = 0.8562, Min Loss = 0.8582 with pool 558\n",
            "Iteration 19: Current Loss = 0.8544, Min Loss = 0.8562 with pool 549\n",
            "Iteration 20: Current Loss = 0.8499, Min Loss = 0.8544 with pool 540\n",
            "Iteration 21: Current Loss = 0.8469, Min Loss = 0.8499 with pool 531\n",
            "Iteration 22: Current Loss = 0.8435, Min Loss = 0.8469 with pool 522\n",
            "Iteration 23: Current Loss = 0.8309, Min Loss = 0.8435 with pool 513\n",
            "Iteration 24: Current Loss = 0.8312, Min Loss = 0.8309 with pool 504\n",
            "Iteration 25: Current Loss = 0.8283, Min Loss = 0.8309 with pool 495\n",
            "Iteration 26: Current Loss = 0.8290, Min Loss = 0.8283 with pool 486\n",
            "Iteration 27: Current Loss = 0.8271, Min Loss = 0.8283 with pool 477\n",
            "Iteration 28: Current Loss = 0.8266, Min Loss = 0.8271 with pool 468\n",
            "Iteration 29: Current Loss = 0.8278, Min Loss = 0.8266 with pool 459\n",
            "Iteration 30: Current Loss = 0.8273, Min Loss = 0.8266 with pool 450\n",
            "Iteration 31: Current Loss = 0.8269, Min Loss = 0.8266 with pool 441\n",
            "Iteration 32: Current Loss = 0.8247, Min Loss = 0.8266 with pool 433\n",
            "Iteration 33: Current Loss = 0.8233, Min Loss = 0.8247 with pool 428\n",
            "Iteration 34: Current Loss = 0.8209, Min Loss = 0.8233 with pool 425\n",
            "Iteration 35: Current Loss = 0.8217, Min Loss = 0.8209 with pool 419\n",
            "Iteration 36: Current Loss = 0.8200, Min Loss = 0.8209 with pool 411\n",
            "Iteration 37: Current Loss = 0.8171, Min Loss = 0.8200 with pool 409\n",
            "Iteration 38: Current Loss = 0.8187, Min Loss = 0.8171 with pool 406\n",
            "Iteration 39: Current Loss = 0.8153, Min Loss = 0.8171 with pool 403\n",
            "Iteration 40: Current Loss = 0.8147, Min Loss = 0.8153 with pool 394\n",
            "Iteration 41: Current Loss = 0.8112, Min Loss = 0.8147 with pool 385\n",
            "Iteration 42: Current Loss = 0.8132, Min Loss = 0.8112 with pool 379\n",
            "Iteration 43: Current Loss = 0.8130, Min Loss = 0.8112 with pool 373\n",
            "Iteration 44: Current Loss = 0.8134, Min Loss = 0.8112 with pool 364\n",
            "Iteration 45: Current Loss = 0.8116, Min Loss = 0.8112 with pool 355\n",
            "Iteration 45: Current Loss = 0.8116, Min Loss = 0.8112\n",
            "Active learning stopped after 44 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9359, Min Loss = inf with pool 711\n",
            "Iteration 2: Current Loss = 0.9356, Min Loss = 0.9359 with pool 702\n",
            "Iteration 3: Current Loss = 0.9353, Min Loss = 0.9356 with pool 693\n",
            "Iteration 4: Current Loss = 0.9332, Min Loss = 0.9353 with pool 684\n",
            "Iteration 5: Current Loss = 0.9280, Min Loss = 0.9332 with pool 675\n",
            "Iteration 6: Current Loss = 0.9051, Min Loss = 0.9280 with pool 666\n",
            "Iteration 7: Current Loss = 0.9029, Min Loss = 0.9051 with pool 657\n",
            "Iteration 8: Current Loss = 0.8994, Min Loss = 0.9029 with pool 648\n",
            "Iteration 9: Current Loss = 0.8943, Min Loss = 0.8994 with pool 639\n",
            "Iteration 10: Current Loss = 0.8706, Min Loss = 0.8943 with pool 630\n",
            "Iteration 11: Current Loss = 0.8704, Min Loss = 0.8706 with pool 621\n",
            "Iteration 12: Current Loss = 0.8591, Min Loss = 0.8704 with pool 612\n",
            "Iteration 13: Current Loss = 0.8584, Min Loss = 0.8591 with pool 603\n",
            "Iteration 14: Current Loss = 0.8545, Min Loss = 0.8584 with pool 594\n",
            "Iteration 15: Current Loss = 0.8507, Min Loss = 0.8545 with pool 585\n",
            "Iteration 16: Current Loss = 0.8466, Min Loss = 0.8507 with pool 576\n",
            "Iteration 17: Current Loss = 0.8445, Min Loss = 0.8466 with pool 567\n",
            "Iteration 18: Current Loss = 0.8420, Min Loss = 0.8445 with pool 558\n",
            "Iteration 19: Current Loss = 0.8415, Min Loss = 0.8420 with pool 549\n",
            "Iteration 20: Current Loss = 0.8364, Min Loss = 0.8415 with pool 540\n",
            "Iteration 21: Current Loss = 0.8315, Min Loss = 0.8364 with pool 531\n",
            "Iteration 22: Current Loss = 0.8273, Min Loss = 0.8315 with pool 522\n",
            "Iteration 23: Current Loss = 0.8232, Min Loss = 0.8273 with pool 513\n",
            "Iteration 24: Current Loss = 0.8214, Min Loss = 0.8232 with pool 504\n",
            "Iteration 25: Current Loss = 0.8186, Min Loss = 0.8214 with pool 495\n",
            "Iteration 26: Current Loss = 0.8164, Min Loss = 0.8186 with pool 486\n",
            "Iteration 27: Current Loss = 0.8124, Min Loss = 0.8164 with pool 477\n",
            "Iteration 28: Current Loss = 0.8103, Min Loss = 0.8124 with pool 468\n",
            "Iteration 29: Current Loss = 0.8064, Min Loss = 0.8103 with pool 459\n",
            "Iteration 30: Current Loss = 0.8028, Min Loss = 0.8064 with pool 450\n",
            "Iteration 31: Current Loss = 0.7926, Min Loss = 0.8028 with pool 441\n",
            "Iteration 32: Current Loss = 0.7913, Min Loss = 0.7926 with pool 432\n",
            "Iteration 33: Current Loss = 0.7904, Min Loss = 0.7913 with pool 423\n",
            "Iteration 34: Current Loss = 0.7901, Min Loss = 0.7904 with pool 414\n",
            "Iteration 35: Current Loss = 0.7844, Min Loss = 0.7901 with pool 405\n",
            "Iteration 36: Current Loss = 0.7709, Min Loss = 0.7844 with pool 398\n",
            "Iteration 37: Current Loss = 0.7720, Min Loss = 0.7709 with pool 389\n",
            "Iteration 38: Current Loss = 0.7699, Min Loss = 0.7709 with pool 386\n",
            "Iteration 39: Current Loss = 0.7694, Min Loss = 0.7699 with pool 379\n",
            "Iteration 40: Current Loss = 0.7715, Min Loss = 0.7694 with pool 374\n",
            "Iteration 41: Current Loss = 0.7714, Min Loss = 0.7694 with pool 372\n",
            "Iteration 42: Current Loss = 0.7708, Min Loss = 0.7694 with pool 369\n",
            "Iteration 43: Current Loss = 0.7721, Min Loss = 0.7694 with pool 366\n",
            "Iteration 43: Current Loss = 0.7721, Min Loss = 0.7694\n",
            "Active learning stopped after 42 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9850, Min Loss = inf with pool 711\n",
            "Iteration 2: Current Loss = 0.9854, Min Loss = 0.9850 with pool 702\n",
            "Iteration 3: Current Loss = 0.9846, Min Loss = 0.9850 with pool 693\n",
            "Iteration 4: Current Loss = 0.9792, Min Loss = 0.9846 with pool 684\n",
            "Iteration 5: Current Loss = 0.9696, Min Loss = 0.9792 with pool 675\n",
            "Iteration 6: Current Loss = 0.9586, Min Loss = 0.9696 with pool 666\n",
            "Iteration 7: Current Loss = 0.9321, Min Loss = 0.9586 with pool 657\n",
            "Iteration 8: Current Loss = 0.9322, Min Loss = 0.9321 with pool 648\n",
            "Iteration 9: Current Loss = 0.9320, Min Loss = 0.9321 with pool 639\n",
            "Iteration 10: Current Loss = 0.9302, Min Loss = 0.9320 with pool 630\n",
            "Iteration 11: Current Loss = 0.9289, Min Loss = 0.9302 with pool 621\n",
            "Iteration 12: Current Loss = 0.9270, Min Loss = 0.9289 with pool 612\n",
            "Iteration 13: Current Loss = 0.9239, Min Loss = 0.9270 with pool 603\n",
            "Iteration 14: Current Loss = 0.9189, Min Loss = 0.9239 with pool 594\n",
            "Iteration 15: Current Loss = 0.9146, Min Loss = 0.9189 with pool 585\n",
            "Iteration 16: Current Loss = 0.9083, Min Loss = 0.9146 with pool 576\n",
            "Iteration 17: Current Loss = 0.9028, Min Loss = 0.9083 with pool 567\n",
            "Iteration 18: Current Loss = 0.8986, Min Loss = 0.9028 with pool 558\n",
            "Iteration 19: Current Loss = 0.8928, Min Loss = 0.8986 with pool 549\n",
            "Iteration 20: Current Loss = 0.8897, Min Loss = 0.8928 with pool 540\n",
            "Iteration 21: Current Loss = 0.8859, Min Loss = 0.8897 with pool 531\n",
            "Iteration 22: Current Loss = 0.8837, Min Loss = 0.8859 with pool 522\n",
            "Iteration 23: Current Loss = 0.8801, Min Loss = 0.8837 with pool 513\n",
            "Iteration 24: Current Loss = 0.8783, Min Loss = 0.8801 with pool 504\n",
            "Iteration 25: Current Loss = 0.8771, Min Loss = 0.8783 with pool 495\n",
            "Iteration 26: Current Loss = 0.8786, Min Loss = 0.8771 with pool 486\n",
            "Iteration 27: Current Loss = 0.8754, Min Loss = 0.8771 with pool 477\n",
            "Iteration 28: Current Loss = 0.8788, Min Loss = 0.8754 with pool 468\n",
            "Iteration 29: Current Loss = 0.8784, Min Loss = 0.8754 with pool 459\n",
            "Iteration 30: Current Loss = 0.8816, Min Loss = 0.8754 with pool 450\n",
            "Iteration 31: Current Loss = 0.8815, Min Loss = 0.8754 with pool 441\n",
            "Iteration 31: Current Loss = 0.8815, Min Loss = 0.8754\n",
            "Active learning stopped after 30 iterations.\n",
            "Average Loss: 0.8476\n",
            "\n",
            "New training with nodes 95 and n_queries 20\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9079, Min Loss = inf with pool 700\n",
            "Iteration 2: Current Loss = 0.9043, Min Loss = 0.9079 with pool 680\n",
            "Iteration 3: Current Loss = 0.8951, Min Loss = 0.9043 with pool 660\n",
            "Iteration 4: Current Loss = 0.8947, Min Loss = 0.8951 with pool 640\n",
            "Iteration 5: Current Loss = 0.8924, Min Loss = 0.8947 with pool 620\n",
            "Iteration 6: Current Loss = 0.8885, Min Loss = 0.8924 with pool 600\n",
            "Iteration 7: Current Loss = 0.8828, Min Loss = 0.8885 with pool 580\n",
            "Iteration 8: Current Loss = 0.8775, Min Loss = 0.8828 with pool 560\n",
            "Iteration 9: Current Loss = 0.8726, Min Loss = 0.8775 with pool 540\n",
            "Iteration 10: Current Loss = 0.8698, Min Loss = 0.8726 with pool 527\n",
            "Iteration 11: Current Loss = 0.8661, Min Loss = 0.8698 with pool 513\n",
            "Iteration 12: Current Loss = 0.8626, Min Loss = 0.8661 with pool 498\n",
            "Iteration 13: Current Loss = 0.8588, Min Loss = 0.8626 with pool 487\n",
            "Iteration 14: Current Loss = 0.8572, Min Loss = 0.8588 with pool 482\n",
            "Iteration 15: Current Loss = 0.8550, Min Loss = 0.8572 with pool 477\n",
            "Iteration 16: Current Loss = 0.8486, Min Loss = 0.8550 with pool 468\n",
            "Iteration 17: Current Loss = 0.8461, Min Loss = 0.8486 with pool 455\n",
            "Iteration 18: Current Loss = 0.8476, Min Loss = 0.8461 with pool 452\n",
            "Iteration 19: Current Loss = 0.8464, Min Loss = 0.8461 with pool 439\n",
            "Iteration 20: Current Loss = 0.8461, Min Loss = 0.8461 with pool 437\n",
            "Iteration 21: Current Loss = 0.8463, Min Loss = 0.8461 with pool 430\n",
            "Iteration 21: Current Loss = 0.8463, Min Loss = 0.8461\n",
            "Active learning stopped after 20 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9302, Min Loss = inf with pool 700\n",
            "Iteration 2: Current Loss = 0.9034, Min Loss = 0.9302 with pool 680\n",
            "Iteration 3: Current Loss = 0.9021, Min Loss = 0.9034 with pool 660\n",
            "Iteration 4: Current Loss = 0.8992, Min Loss = 0.9021 with pool 640\n",
            "Iteration 5: Current Loss = 0.8917, Min Loss = 0.8992 with pool 620\n",
            "Iteration 6: Current Loss = 0.8833, Min Loss = 0.8917 with pool 600\n",
            "Iteration 7: Current Loss = 0.8772, Min Loss = 0.8833 with pool 580\n",
            "Iteration 8: Current Loss = 0.8746, Min Loss = 0.8772 with pool 575\n",
            "Iteration 9: Current Loss = 0.8731, Min Loss = 0.8746 with pool 565\n",
            "Iteration 10: Current Loss = 0.8716, Min Loss = 0.8731 with pool 561\n",
            "Iteration 11: Current Loss = 0.8698, Min Loss = 0.8716 with pool 552\n",
            "Iteration 12: Current Loss = 0.8707, Min Loss = 0.8698 with pool 547\n",
            "Iteration 13: Current Loss = 0.8690, Min Loss = 0.8698 with pool 539\n",
            "Iteration 14: Current Loss = 0.8670, Min Loss = 0.8690 with pool 537\n",
            "Iteration 15: Current Loss = 0.8663, Min Loss = 0.8670 with pool 527\n",
            "Iteration 16: Current Loss = 0.8648, Min Loss = 0.8663 with pool 521\n",
            "Iteration 17: Current Loss = 0.8643, Min Loss = 0.8648 with pool 512\n",
            "Iteration 18: Current Loss = 0.8623, Min Loss = 0.8643 with pool 502\n",
            "Iteration 19: Current Loss = 0.8607, Min Loss = 0.8623 with pool 496\n",
            "Iteration 20: Current Loss = 0.8592, Min Loss = 0.8607 with pool 493\n",
            "Iteration 21: Current Loss = 0.8584, Min Loss = 0.8592 with pool 486\n",
            "Iteration 22: Current Loss = 0.8574, Min Loss = 0.8584 with pool 482\n",
            "Iteration 23: Current Loss = 0.8570, Min Loss = 0.8574 with pool 481\n",
            "Iteration 24: Current Loss = 0.8570, Min Loss = 0.8570 with pool 478\n",
            "Iteration 25: Current Loss = 0.8559, Min Loss = 0.8570 with pool 469\n",
            "Iteration 26: Current Loss = 0.8562, Min Loss = 0.8559 with pool 467\n",
            "Iteration 27: Current Loss = 0.8442, Min Loss = 0.8559 with pool 455\n",
            "Iteration 28: Current Loss = 0.8436, Min Loss = 0.8442 with pool 450\n",
            "Iteration 29: Current Loss = 0.8426, Min Loss = 0.8436 with pool 443\n",
            "Iteration 30: Current Loss = 0.8414, Min Loss = 0.8426 with pool 441\n",
            "Iteration 31: Current Loss = 0.8419, Min Loss = 0.8414 with pool 436\n",
            "Iteration 32: Current Loss = 0.8441, Min Loss = 0.8414 with pool 433\n",
            "Iteration 33: Current Loss = 0.8457, Min Loss = 0.8414 with pool 430\n",
            "Iteration 34: Current Loss = 0.8426, Min Loss = 0.8414 with pool 421\n",
            "Iteration 34: Current Loss = 0.8426, Min Loss = 0.8414\n",
            "Active learning stopped after 33 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9159, Min Loss = inf with pool 700\n",
            "Iteration 2: Current Loss = 0.9145, Min Loss = 0.9159 with pool 680\n",
            "Iteration 3: Current Loss = 0.8840, Min Loss = 0.9145 with pool 660\n",
            "Iteration 4: Current Loss = 0.8832, Min Loss = 0.8840 with pool 640\n",
            "Iteration 5: Current Loss = 0.8799, Min Loss = 0.8832 with pool 620\n",
            "Iteration 6: Current Loss = 0.8762, Min Loss = 0.8799 with pool 600\n",
            "Iteration 7: Current Loss = 0.8690, Min Loss = 0.8762 with pool 580\n",
            "Iteration 8: Current Loss = 0.8634, Min Loss = 0.8690 with pool 560\n",
            "Iteration 9: Current Loss = 0.8581, Min Loss = 0.8634 with pool 540\n",
            "Iteration 10: Current Loss = 0.8537, Min Loss = 0.8581 with pool 532\n",
            "Iteration 11: Current Loss = 0.8515, Min Loss = 0.8537 with pool 529\n",
            "Iteration 12: Current Loss = 0.8506, Min Loss = 0.8515 with pool 526\n",
            "Iteration 13: Current Loss = 0.8498, Min Loss = 0.8506 with pool 523\n",
            "Iteration 14: Current Loss = 0.8487, Min Loss = 0.8498 with pool 514\n",
            "Iteration 15: Current Loss = 0.8488, Min Loss = 0.8487 with pool 510\n",
            "Iteration 16: Current Loss = 0.8456, Min Loss = 0.8487 with pool 502\n",
            "Iteration 17: Current Loss = 0.8424, Min Loss = 0.8456 with pool 493\n",
            "Iteration 18: Current Loss = 0.8395, Min Loss = 0.8424 with pool 484\n",
            "Iteration 19: Current Loss = 0.8367, Min Loss = 0.8395 with pool 473\n",
            "Iteration 20: Current Loss = 0.8374, Min Loss = 0.8367 with pool 466\n",
            "Iteration 21: Current Loss = 0.8343, Min Loss = 0.8367 with pool 463\n",
            "Iteration 22: Current Loss = 0.8335, Min Loss = 0.8343 with pool 454\n",
            "Iteration 23: Current Loss = 0.8357, Min Loss = 0.8335 with pool 452\n",
            "Iteration 24: Current Loss = 0.8321, Min Loss = 0.8335 with pool 445\n",
            "Iteration 25: Current Loss = 0.8319, Min Loss = 0.8321 with pool 441\n",
            "Iteration 26: Current Loss = 0.8301, Min Loss = 0.8319 with pool 439\n",
            "Iteration 27: Current Loss = 0.8296, Min Loss = 0.8301 with pool 433\n",
            "Iteration 28: Current Loss = 0.8288, Min Loss = 0.8296 with pool 431\n",
            "Iteration 29: Current Loss = 0.8281, Min Loss = 0.8288 with pool 425\n",
            "Iteration 30: Current Loss = 0.8274, Min Loss = 0.8281 with pool 405\n",
            "Iteration 31: Current Loss = 0.8271, Min Loss = 0.8274 with pool 400\n",
            "Iteration 32: Current Loss = 0.8260, Min Loss = 0.8271 with pool 399\n",
            "Iteration 33: Current Loss = 0.8287, Min Loss = 0.8260 with pool 398\n",
            "Iteration 34: Current Loss = 0.8250, Min Loss = 0.8260 with pool 396\n",
            "Iteration 35: Current Loss = 0.8249, Min Loss = 0.8250 with pool 385\n",
            "Iteration 36: Current Loss = 0.8254, Min Loss = 0.8249 with pool 365\n",
            "Iteration 37: Current Loss = 0.8237, Min Loss = 0.8249 with pool 364\n",
            "Iteration 38: Current Loss = 0.8245, Min Loss = 0.8237 with pool 362\n",
            "Iteration 39: Current Loss = 0.8228, Min Loss = 0.8237 with pool 342\n",
            "Iteration 40: Current Loss = 0.8250, Min Loss = 0.8228 with pool 341\n",
            "Iteration 41: Current Loss = 0.8261, Min Loss = 0.8228 with pool 321\n",
            "Iteration 42: Current Loss = 0.8286, Min Loss = 0.8228 with pool 319\n",
            "Iteration 43: Current Loss = 0.8278, Min Loss = 0.8228 with pool 299\n",
            "Iteration 43: Current Loss = 0.8278, Min Loss = 0.8228\n",
            "Active learning stopped after 42 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9411, Min Loss = inf with pool 700\n",
            "Iteration 2: Current Loss = 0.9350, Min Loss = 0.9411 with pool 680\n",
            "Iteration 3: Current Loss = 0.8969, Min Loss = 0.9350 with pool 660\n",
            "Iteration 4: Current Loss = 0.8974, Min Loss = 0.8969 with pool 640\n",
            "Iteration 5: Current Loss = 0.8949, Min Loss = 0.8969 with pool 620\n",
            "Iteration 6: Current Loss = 0.8904, Min Loss = 0.8949 with pool 600\n",
            "Iteration 7: Current Loss = 0.8849, Min Loss = 0.8904 with pool 580\n",
            "Iteration 8: Current Loss = 0.8809, Min Loss = 0.8849 with pool 560\n",
            "Iteration 9: Current Loss = 0.8785, Min Loss = 0.8809 with pool 551\n",
            "Iteration 10: Current Loss = 0.8761, Min Loss = 0.8785 with pool 543\n",
            "Iteration 11: Current Loss = 0.8718, Min Loss = 0.8761 with pool 534\n",
            "Iteration 12: Current Loss = 0.8690, Min Loss = 0.8718 with pool 529\n",
            "Iteration 13: Current Loss = 0.8661, Min Loss = 0.8690 with pool 509\n",
            "Iteration 14: Current Loss = 0.8631, Min Loss = 0.8661 with pool 501\n",
            "Iteration 15: Current Loss = 0.8615, Min Loss = 0.8631 with pool 496\n",
            "Iteration 16: Current Loss = 0.8578, Min Loss = 0.8615 with pool 494\n",
            "Iteration 17: Current Loss = 0.8562, Min Loss = 0.8578 with pool 490\n",
            "Iteration 18: Current Loss = 0.8544, Min Loss = 0.8562 with pool 488\n",
            "Iteration 19: Current Loss = 0.8538, Min Loss = 0.8544 with pool 484\n",
            "Iteration 20: Current Loss = 0.8524, Min Loss = 0.8538 with pool 479\n",
            "Iteration 21: Current Loss = 0.8528, Min Loss = 0.8524 with pool 477\n",
            "Iteration 22: Current Loss = 0.8517, Min Loss = 0.8524 with pool 469\n",
            "Iteration 23: Current Loss = 0.8491, Min Loss = 0.8517 with pool 459\n",
            "Iteration 24: Current Loss = 0.8481, Min Loss = 0.8491 with pool 454\n",
            "Iteration 25: Current Loss = 0.8468, Min Loss = 0.8481 with pool 444\n",
            "Iteration 26: Current Loss = 0.8466, Min Loss = 0.8468 with pool 436\n",
            "Iteration 27: Current Loss = 0.8452, Min Loss = 0.8466 with pool 432\n",
            "Iteration 28: Current Loss = 0.8442, Min Loss = 0.8452 with pool 429\n",
            "Iteration 29: Current Loss = 0.8446, Min Loss = 0.8442 with pool 421\n",
            "Iteration 30: Current Loss = 0.8426, Min Loss = 0.8442 with pool 417\n",
            "Iteration 31: Current Loss = 0.8441, Min Loss = 0.8426 with pool 414\n",
            "Iteration 32: Current Loss = 0.8424, Min Loss = 0.8426 with pool 412\n",
            "Iteration 33: Current Loss = 0.8421, Min Loss = 0.8424 with pool 405\n",
            "Iteration 34: Current Loss = 0.8420, Min Loss = 0.8421 with pool 404\n",
            "Iteration 35: Current Loss = 0.8421, Min Loss = 0.8420 with pool 401\n",
            "Iteration 36: Current Loss = 0.8428, Min Loss = 0.8420 with pool 400\n",
            "Iteration 37: Current Loss = 0.8409, Min Loss = 0.8420 with pool 396\n",
            "Iteration 38: Current Loss = 0.8468, Min Loss = 0.8409 with pool 395\n",
            "Iteration 39: Current Loss = 0.8389, Min Loss = 0.8409 with pool 386\n",
            "Iteration 40: Current Loss = 0.8452, Min Loss = 0.8389 with pool 384\n",
            "Iteration 41: Current Loss = 0.8447, Min Loss = 0.8389 with pool 383\n",
            "Iteration 42: Current Loss = 0.8474, Min Loss = 0.8389 with pool 382\n",
            "Iteration 43: Current Loss = 0.8470, Min Loss = 0.8389 with pool 380\n",
            "Iteration 43: Current Loss = 0.8470, Min Loss = 0.8389\n",
            "Active learning stopped after 42 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9629, Min Loss = inf with pool 700\n",
            "Iteration 2: Current Loss = 0.9564, Min Loss = 0.9629 with pool 680\n",
            "Iteration 3: Current Loss = 0.9463, Min Loss = 0.9564 with pool 660\n",
            "Iteration 4: Current Loss = 0.9352, Min Loss = 0.9463 with pool 640\n",
            "Iteration 5: Current Loss = 0.9230, Min Loss = 0.9352 with pool 620\n",
            "Iteration 6: Current Loss = 0.9148, Min Loss = 0.9230 with pool 601\n",
            "Iteration 7: Current Loss = 0.9101, Min Loss = 0.9148 with pool 597\n",
            "Iteration 8: Current Loss = 0.9084, Min Loss = 0.9101 with pool 594\n",
            "Iteration 9: Current Loss = 0.9096, Min Loss = 0.9084 with pool 585\n",
            "Iteration 10: Current Loss = 0.9085, Min Loss = 0.9084 with pool 574\n",
            "Iteration 11: Current Loss = 0.9087, Min Loss = 0.9084 with pool 566\n",
            "Iteration 12: Current Loss = 0.9073, Min Loss = 0.9084 with pool 559\n",
            "Iteration 13: Current Loss = 0.9071, Min Loss = 0.9073 with pool 550\n",
            "Iteration 14: Current Loss = 0.9070, Min Loss = 0.9071 with pool 544\n",
            "Iteration 15: Current Loss = 0.9053, Min Loss = 0.9070 with pool 535\n",
            "Iteration 16: Current Loss = 0.9041, Min Loss = 0.9053 with pool 524\n",
            "Iteration 17: Current Loss = 0.9032, Min Loss = 0.9041 with pool 515\n",
            "Iteration 18: Current Loss = 0.9015, Min Loss = 0.9032 with pool 505\n",
            "Iteration 19: Current Loss = 0.9010, Min Loss = 0.9015 with pool 491\n",
            "Iteration 20: Current Loss = 0.8965, Min Loss = 0.9010 with pool 474\n",
            "Iteration 21: Current Loss = 0.8911, Min Loss = 0.8965 with pool 460\n",
            "Iteration 22: Current Loss = 0.8911, Min Loss = 0.8911 with pool 452\n",
            "Iteration 23: Current Loss = 0.8863, Min Loss = 0.8911 with pool 437\n",
            "Iteration 24: Current Loss = 0.8774, Min Loss = 0.8863 with pool 429\n",
            "Iteration 25: Current Loss = 0.8784, Min Loss = 0.8774 with pool 409\n",
            "Iteration 26: Current Loss = 0.8729, Min Loss = 0.8774 with pool 394\n",
            "Iteration 27: Current Loss = 0.8714, Min Loss = 0.8729 with pool 383\n",
            "Iteration 28: Current Loss = 0.8728, Min Loss = 0.8714 with pool 366\n",
            "Iteration 29: Current Loss = 0.8704, Min Loss = 0.8714 with pool 354\n",
            "Iteration 30: Current Loss = 0.8709, Min Loss = 0.8704 with pool 351\n",
            "Iteration 31: Current Loss = 0.8696, Min Loss = 0.8704 with pool 349\n",
            "Iteration 32: Current Loss = 0.8651, Min Loss = 0.8696 with pool 345\n",
            "Iteration 33: Current Loss = 0.8648, Min Loss = 0.8651 with pool 342\n",
            "Iteration 34: Current Loss = 0.8621, Min Loss = 0.8648 with pool 339\n",
            "Iteration 35: Current Loss = 0.8605, Min Loss = 0.8621 with pool 336\n",
            "Iteration 36: Current Loss = 0.8624, Min Loss = 0.8605 with pool 334\n",
            "Iteration 37: Current Loss = 0.8571, Min Loss = 0.8605 with pool 328\n",
            "Iteration 38: Current Loss = 0.8600, Min Loss = 0.8571 with pool 325\n",
            "Iteration 39: Current Loss = 0.8597, Min Loss = 0.8571 with pool 322\n",
            "Iteration 40: Current Loss = 0.8580, Min Loss = 0.8571 with pool 318\n",
            "Iteration 41: Current Loss = 0.8591, Min Loss = 0.8571 with pool 316\n",
            "Iteration 41: Current Loss = 0.8591, Min Loss = 0.8571\n",
            "Active learning stopped after 40 iterations.\n",
            "Average Loss: 0.8413\n",
            "\n",
            "New training with nodes 33 and n_queries 34\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0104, Min Loss = inf with pool 686\n",
            "Iteration 2: Current Loss = 0.9964, Min Loss = 1.0104 with pool 652\n",
            "Iteration 3: Current Loss = 0.9135, Min Loss = 0.9964 with pool 618\n",
            "Iteration 4: Current Loss = 0.8943, Min Loss = 0.9135 with pool 584\n",
            "Iteration 5: Current Loss = 0.8929, Min Loss = 0.8943 with pool 562\n",
            "Iteration 6: Current Loss = 0.8912, Min Loss = 0.8929 with pool 560\n",
            "Iteration 7: Current Loss = 0.8897, Min Loss = 0.8912 with pool 559\n",
            "Iteration 8: Current Loss = 0.8887, Min Loss = 0.8897 with pool 557\n",
            "Iteration 9: Current Loss = 0.8883, Min Loss = 0.8887 with pool 552\n",
            "Iteration 10: Current Loss = 0.8883, Min Loss = 0.8883 with pool 550\n",
            "Iteration 11: Current Loss = 0.8875, Min Loss = 0.8883 with pool 549\n",
            "Iteration 12: Current Loss = 0.8870, Min Loss = 0.8875 with pool 544\n",
            "Iteration 13: Current Loss = 0.8867, Min Loss = 0.8870 with pool 541\n",
            "Iteration 14: Current Loss = 0.8871, Min Loss = 0.8867 with pool 540\n",
            "Iteration 15: Current Loss = 0.8869, Min Loss = 0.8867 with pool 538\n",
            "Iteration 16: Current Loss = 0.8877, Min Loss = 0.8867 with pool 533\n",
            "Iteration 17: Current Loss = 0.8878, Min Loss = 0.8867 with pool 529\n",
            "Iteration 17: Current Loss = 0.8878, Min Loss = 0.8867\n",
            "Active learning stopped after 16 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9793, Min Loss = inf with pool 686\n",
            "Iteration 2: Current Loss = 0.9668, Min Loss = 0.9793 with pool 652\n",
            "Iteration 3: Current Loss = 0.9518, Min Loss = 0.9668 with pool 618\n",
            "Iteration 4: Current Loss = 0.8944, Min Loss = 0.9518 with pool 584\n",
            "Iteration 5: Current Loss = 0.8765, Min Loss = 0.8944 with pool 550\n",
            "Iteration 6: Current Loss = 0.8754, Min Loss = 0.8765 with pool 516\n",
            "Iteration 7: Current Loss = 0.8745, Min Loss = 0.8754 with pool 507\n",
            "Iteration 8: Current Loss = 0.8735, Min Loss = 0.8745 with pool 504\n",
            "Iteration 9: Current Loss = 0.8724, Min Loss = 0.8735 with pool 502\n",
            "Iteration 10: Current Loss = 0.8713, Min Loss = 0.8724 with pool 499\n",
            "Iteration 11: Current Loss = 0.8705, Min Loss = 0.8713 with pool 498\n",
            "Iteration 12: Current Loss = 0.8692, Min Loss = 0.8705 with pool 496\n",
            "Iteration 13: Current Loss = 0.8687, Min Loss = 0.8692 with pool 494\n",
            "Iteration 14: Current Loss = 0.8684, Min Loss = 0.8687 with pool 487\n",
            "Iteration 15: Current Loss = 0.8679, Min Loss = 0.8684 with pool 482\n",
            "Iteration 16: Current Loss = 0.8680, Min Loss = 0.8679 with pool 479\n",
            "Iteration 17: Current Loss = 0.8679, Min Loss = 0.8679 with pool 475\n",
            "Iteration 18: Current Loss = 0.8687, Min Loss = 0.8679 with pool 474\n",
            "Iteration 19: Current Loss = 0.8684, Min Loss = 0.8679 with pool 468\n",
            "Iteration 19: Current Loss = 0.8684, Min Loss = 0.8679\n",
            "Active learning stopped after 18 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0753, Min Loss = inf with pool 686\n",
            "Iteration 2: Current Loss = 1.0566, Min Loss = 1.0753 with pool 652\n",
            "Iteration 3: Current Loss = 0.9304, Min Loss = 1.0566 with pool 618\n",
            "Iteration 4: Current Loss = 0.9276, Min Loss = 0.9304 with pool 592\n",
            "Iteration 5: Current Loss = 0.9267, Min Loss = 0.9276 with pool 591\n",
            "Iteration 6: Current Loss = 0.9260, Min Loss = 0.9267 with pool 588\n",
            "Iteration 7: Current Loss = 0.9258, Min Loss = 0.9260 with pool 586\n",
            "Iteration 8: Current Loss = 0.9249, Min Loss = 0.9258 with pool 585\n",
            "Iteration 9: Current Loss = 0.9242, Min Loss = 0.9249 with pool 584\n",
            "Iteration 10: Current Loss = 0.9233, Min Loss = 0.9242 with pool 583\n",
            "Iteration 11: Current Loss = 0.9230, Min Loss = 0.9233 with pool 582\n",
            "Iteration 12: Current Loss = 0.9231, Min Loss = 0.9230 with pool 581\n",
            "Iteration 13: Current Loss = 0.9231, Min Loss = 0.9230 with pool 579\n",
            "Iteration 14: Current Loss = 0.9231, Min Loss = 0.9230 with pool 576\n",
            "Iteration 15: Current Loss = 0.9232, Min Loss = 0.9230 with pool 574\n",
            "Iteration 15: Current Loss = 0.9232, Min Loss = 0.9230\n",
            "Active learning stopped after 14 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0407, Min Loss = inf with pool 686\n",
            "Iteration 2: Current Loss = 1.0196, Min Loss = 1.0407 with pool 652\n",
            "Iteration 3: Current Loss = 0.9952, Min Loss = 1.0196 with pool 618\n",
            "Iteration 4: Current Loss = 0.9686, Min Loss = 0.9952 with pool 584\n",
            "Iteration 5: Current Loss = 0.8831, Min Loss = 0.9686 with pool 550\n",
            "Iteration 6: Current Loss = 0.8833, Min Loss = 0.8831 with pool 535\n",
            "Iteration 7: Current Loss = 0.8830, Min Loss = 0.8831 with pool 534\n",
            "Iteration 8: Current Loss = 0.8832, Min Loss = 0.8830 with pool 531\n",
            "Iteration 9: Current Loss = 0.8833, Min Loss = 0.8830 with pool 527\n",
            "Iteration 10: Current Loss = 0.8833, Min Loss = 0.8830 with pool 526\n",
            "Iteration 11: Current Loss = 0.8834, Min Loss = 0.8830 with pool 523\n",
            "Iteration 11: Current Loss = 0.8834, Min Loss = 0.8830\n",
            "Active learning stopped after 10 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.1169, Min Loss = inf with pool 686\n",
            "Iteration 2: Current Loss = 1.0939, Min Loss = 1.1169 with pool 652\n",
            "Iteration 3: Current Loss = 1.0648, Min Loss = 1.0939 with pool 618\n",
            "Iteration 4: Current Loss = 0.9131, Min Loss = 1.0648 with pool 584\n",
            "Iteration 5: Current Loss = 0.8915, Min Loss = 0.9131 with pool 550\n",
            "Iteration 6: Current Loss = 0.8893, Min Loss = 0.8915 with pool 516\n",
            "Iteration 7: Current Loss = 0.8880, Min Loss = 0.8893 with pool 508\n",
            "Iteration 8: Current Loss = 0.8861, Min Loss = 0.8880 with pool 505\n",
            "Iteration 9: Current Loss = 0.8855, Min Loss = 0.8861 with pool 503\n",
            "Iteration 10: Current Loss = 0.8844, Min Loss = 0.8855 with pool 498\n",
            "Iteration 11: Current Loss = 0.8841, Min Loss = 0.8844 with pool 494\n",
            "Iteration 12: Current Loss = 0.8839, Min Loss = 0.8841 with pool 491\n",
            "Iteration 13: Current Loss = 0.8829, Min Loss = 0.8839 with pool 457\n",
            "Iteration 14: Current Loss = 0.8803, Min Loss = 0.8829 with pool 454\n",
            "Iteration 15: Current Loss = 0.8790, Min Loss = 0.8803 with pool 420\n",
            "Iteration 16: Current Loss = 0.8779, Min Loss = 0.8790 with pool 418\n",
            "Iteration 17: Current Loss = 0.8767, Min Loss = 0.8779 with pool 414\n",
            "Iteration 18: Current Loss = 0.8760, Min Loss = 0.8767 with pool 412\n",
            "Iteration 19: Current Loss = 0.8750, Min Loss = 0.8760 with pool 409\n",
            "Iteration 20: Current Loss = 0.8741, Min Loss = 0.8750 with pool 408\n",
            "Iteration 21: Current Loss = 0.8740, Min Loss = 0.8741 with pool 403\n",
            "Iteration 22: Current Loss = 0.8743, Min Loss = 0.8740 with pool 397\n",
            "Iteration 23: Current Loss = 0.8737, Min Loss = 0.8740 with pool 395\n",
            "Iteration 24: Current Loss = 0.8732, Min Loss = 0.8737 with pool 390\n",
            "Iteration 25: Current Loss = 0.8751, Min Loss = 0.8732 with pool 387\n",
            "Iteration 26: Current Loss = 0.8754, Min Loss = 0.8732 with pool 384\n",
            "Iteration 27: Current Loss = 0.8768, Min Loss = 0.8732 with pool 350\n",
            "Iteration 28: Current Loss = 0.8772, Min Loss = 0.8732 with pool 347\n",
            "Iteration 28: Current Loss = 0.8772, Min Loss = 0.8732\n",
            "Active learning stopped after 27 iterations.\n",
            "Average Loss: 0.8867\n",
            "\n",
            "New training with nodes 16 and n_queries 37\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0939, Min Loss = inf with pool 683\n",
            "Iteration 2: Current Loss = 1.0783, Min Loss = 1.0939 with pool 646\n",
            "Iteration 3: Current Loss = 1.0594, Min Loss = 1.0783 with pool 609\n",
            "Iteration 4: Current Loss = 1.0378, Min Loss = 1.0594 with pool 572\n",
            "Iteration 5: Current Loss = 1.0151, Min Loss = 1.0378 with pool 535\n",
            "Iteration 6: Current Loss = 0.9926, Min Loss = 1.0151 with pool 498\n",
            "Iteration 7: Current Loss = 0.8995, Min Loss = 0.9926 with pool 461\n",
            "Iteration 8: Current Loss = 0.8791, Min Loss = 0.8995 with pool 424\n",
            "Iteration 9: Current Loss = 0.8690, Min Loss = 0.8791 with pool 410\n",
            "Iteration 10: Current Loss = 0.8632, Min Loss = 0.8690 with pool 398\n",
            "Iteration 11: Current Loss = 0.8623, Min Loss = 0.8632 with pool 395\n",
            "Iteration 12: Current Loss = 0.8621, Min Loss = 0.8623 with pool 394\n",
            "Iteration 13: Current Loss = 0.8618, Min Loss = 0.8621 with pool 393\n",
            "Iteration 14: Current Loss = 0.8616, Min Loss = 0.8618 with pool 356\n",
            "Iteration 15: Current Loss = 0.8603, Min Loss = 0.8616 with pool 319\n",
            "Iteration 16: Current Loss = 0.8589, Min Loss = 0.8603 with pool 318\n",
            "Iteration 17: Current Loss = 0.8585, Min Loss = 0.8589 with pool 281\n",
            "Iteration 18: Current Loss = 0.8583, Min Loss = 0.8585 with pool 279\n",
            "Iteration 19: Current Loss = 0.8584, Min Loss = 0.8583 with pool 278\n",
            "Iteration 20: Current Loss = 0.8570, Min Loss = 0.8583 with pool 275\n",
            "Iteration 21: Current Loss = 0.8567, Min Loss = 0.8570 with pool 274\n",
            "Iteration 22: Current Loss = 0.8568, Min Loss = 0.8567 with pool 272\n",
            "Iteration 23: Current Loss = 0.8556, Min Loss = 0.8567 with pool 270\n",
            "Iteration 24: Current Loss = 0.8554, Min Loss = 0.8556 with pool 269\n",
            "Iteration 25: Current Loss = 0.8539, Min Loss = 0.8554 with pool 232\n",
            "Iteration 26: Current Loss = 0.8544, Min Loss = 0.8539 with pool 231\n",
            "Iteration 27: Current Loss = 0.8538, Min Loss = 0.8539 with pool 230\n",
            "Iteration 28: Current Loss = 0.8532, Min Loss = 0.8538 with pool 228\n",
            "Iteration 29: Current Loss = 0.8532, Min Loss = 0.8532 with pool 226\n",
            "Iteration 30: Current Loss = 0.8530, Min Loss = 0.8532 with pool 225\n",
            "Iteration 31: Current Loss = 0.8520, Min Loss = 0.8530 with pool 223\n",
            "Iteration 32: Current Loss = 0.8507, Min Loss = 0.8520 with pool 186\n",
            "Iteration 33: Current Loss = 0.8506, Min Loss = 0.8507 with pool 183\n",
            "Iteration 34: Current Loss = 0.8500, Min Loss = 0.8506 with pool 182\n",
            "Iteration 35: Current Loss = 0.8489, Min Loss = 0.8500 with pool 181\n",
            "Iteration 36: Current Loss = 0.8470, Min Loss = 0.8489 with pool 144\n",
            "Iteration 37: Current Loss = 0.8450, Min Loss = 0.8470 with pool 107\n",
            "Iteration 38: Current Loss = 0.8430, Min Loss = 0.8450 with pool 70\n",
            "Iteration 39: Current Loss = 0.8395, Min Loss = 0.8430 with pool 69\n",
            "Iteration 40: Current Loss = 0.8383, Min Loss = 0.8395 with pool 68\n",
            "Iteration 41: Current Loss = 0.8368, Min Loss = 0.8383 with pool 31\n",
            "Active learning stopped after 41 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0943, Min Loss = inf with pool 683\n",
            "Iteration 2: Current Loss = 1.0785, Min Loss = 1.0943 with pool 646\n",
            "Iteration 3: Current Loss = 1.0582, Min Loss = 1.0785 with pool 609\n",
            "Iteration 4: Current Loss = 1.0355, Min Loss = 1.0582 with pool 572\n",
            "Iteration 5: Current Loss = 0.9201, Min Loss = 1.0355 with pool 535\n",
            "Iteration 6: Current Loss = 0.9166, Min Loss = 0.9201 with pool 500\n",
            "Iteration 7: Current Loss = 0.9142, Min Loss = 0.9166 with pool 498\n",
            "Iteration 8: Current Loss = 0.9123, Min Loss = 0.9142 with pool 497\n",
            "Iteration 9: Current Loss = 0.9101, Min Loss = 0.9123 with pool 460\n",
            "Iteration 10: Current Loss = 0.8963, Min Loss = 0.9101 with pool 423\n",
            "Iteration 11: Current Loss = 0.8895, Min Loss = 0.8963 with pool 419\n",
            "Iteration 12: Current Loss = 0.8891, Min Loss = 0.8895 with pool 412\n",
            "Iteration 13: Current Loss = 0.8884, Min Loss = 0.8891 with pool 410\n",
            "Iteration 14: Current Loss = 0.8879, Min Loss = 0.8884 with pool 409\n",
            "Iteration 15: Current Loss = 0.8872, Min Loss = 0.8879 with pool 372\n",
            "Iteration 16: Current Loss = 0.8862, Min Loss = 0.8872 with pool 335\n",
            "Iteration 17: Current Loss = 0.8850, Min Loss = 0.8862 with pool 298\n",
            "Iteration 18: Current Loss = 0.8825, Min Loss = 0.8850 with pool 261\n",
            "Iteration 19: Current Loss = 0.8807, Min Loss = 0.8825 with pool 224\n",
            "Iteration 20: Current Loss = 0.8791, Min Loss = 0.8807 with pool 187\n",
            "Iteration 21: Current Loss = 0.8769, Min Loss = 0.8791 with pool 184\n",
            "Iteration 22: Current Loss = 0.8749, Min Loss = 0.8769 with pool 181\n",
            "Iteration 23: Current Loss = 0.8732, Min Loss = 0.8749 with pool 144\n",
            "Iteration 24: Current Loss = 0.8717, Min Loss = 0.8732 with pool 107\n",
            "Iteration 25: Current Loss = 0.8697, Min Loss = 0.8717 with pool 106\n",
            "Iteration 26: Current Loss = 0.8681, Min Loss = 0.8697 with pool 69\n",
            "Iteration 27: Current Loss = 0.8666, Min Loss = 0.8681 with pool 68\n",
            "Iteration 28: Current Loss = 0.8644, Min Loss = 0.8666 with pool 67\n",
            "Iteration 29: Current Loss = 0.8623, Min Loss = 0.8644 with pool 30\n",
            "Active learning stopped after 29 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0068, Min Loss = inf with pool 683\n",
            "Iteration 2: Current Loss = 0.9969, Min Loss = 1.0068 with pool 646\n",
            "Iteration 3: Current Loss = 0.9841, Min Loss = 0.9969 with pool 609\n",
            "Iteration 4: Current Loss = 0.9034, Min Loss = 0.9841 with pool 572\n",
            "Iteration 5: Current Loss = 0.8818, Min Loss = 0.9034 with pool 535\n",
            "Iteration 6: Current Loss = 0.8806, Min Loss = 0.8818 with pool 500\n",
            "Iteration 7: Current Loss = 0.8790, Min Loss = 0.8806 with pool 499\n",
            "Iteration 8: Current Loss = 0.8775, Min Loss = 0.8790 with pool 495\n",
            "Iteration 9: Current Loss = 0.8756, Min Loss = 0.8775 with pool 492\n",
            "Iteration 10: Current Loss = 0.8741, Min Loss = 0.8756 with pool 491\n",
            "Iteration 11: Current Loss = 0.8725, Min Loss = 0.8741 with pool 489\n",
            "Iteration 12: Current Loss = 0.8709, Min Loss = 0.8725 with pool 487\n",
            "Iteration 13: Current Loss = 0.8693, Min Loss = 0.8709 with pool 482\n",
            "Iteration 14: Current Loss = 0.8678, Min Loss = 0.8693 with pool 480\n",
            "Iteration 15: Current Loss = 0.8661, Min Loss = 0.8678 with pool 477\n",
            "Iteration 16: Current Loss = 0.8646, Min Loss = 0.8661 with pool 475\n",
            "Iteration 17: Current Loss = 0.8640, Min Loss = 0.8646 with pool 473\n",
            "Iteration 18: Current Loss = 0.8620, Min Loss = 0.8640 with pool 470\n",
            "Iteration 19: Current Loss = 0.8605, Min Loss = 0.8620 with pool 466\n",
            "Iteration 20: Current Loss = 0.8589, Min Loss = 0.8605 with pool 463\n",
            "Iteration 21: Current Loss = 0.8572, Min Loss = 0.8589 with pool 460\n",
            "Iteration 22: Current Loss = 0.8556, Min Loss = 0.8572 with pool 423\n",
            "Iteration 23: Current Loss = 0.8543, Min Loss = 0.8556 with pool 421\n",
            "Iteration 24: Current Loss = 0.8528, Min Loss = 0.8543 with pool 419\n",
            "Iteration 25: Current Loss = 0.8523, Min Loss = 0.8528 with pool 417\n",
            "Iteration 26: Current Loss = 0.8515, Min Loss = 0.8523 with pool 415\n",
            "Iteration 27: Current Loss = 0.8506, Min Loss = 0.8515 with pool 414\n",
            "Iteration 28: Current Loss = 0.8497, Min Loss = 0.8506 with pool 412\n",
            "Iteration 29: Current Loss = 0.8484, Min Loss = 0.8497 with pool 409\n",
            "Iteration 30: Current Loss = 0.8472, Min Loss = 0.8484 with pool 407\n",
            "Iteration 31: Current Loss = 0.8467, Min Loss = 0.8472 with pool 405\n",
            "Iteration 32: Current Loss = 0.8458, Min Loss = 0.8467 with pool 403\n",
            "Iteration 33: Current Loss = 0.8456, Min Loss = 0.8458 with pool 400\n",
            "Iteration 34: Current Loss = 0.8460, Min Loss = 0.8456 with pool 398\n",
            "Iteration 35: Current Loss = 0.8452, Min Loss = 0.8456 with pool 395\n",
            "Iteration 36: Current Loss = 0.8437, Min Loss = 0.8452 with pool 390\n",
            "Iteration 37: Current Loss = 0.8431, Min Loss = 0.8437 with pool 388\n",
            "Iteration 38: Current Loss = 0.8422, Min Loss = 0.8431 with pool 387\n",
            "Iteration 39: Current Loss = 0.8414, Min Loss = 0.8422 with pool 381\n",
            "Iteration 40: Current Loss = 0.8412, Min Loss = 0.8414 with pool 379\n",
            "Iteration 41: Current Loss = 0.8398, Min Loss = 0.8412 with pool 378\n",
            "Iteration 42: Current Loss = 0.8405, Min Loss = 0.8398 with pool 376\n",
            "Iteration 43: Current Loss = 0.8397, Min Loss = 0.8398 with pool 374\n",
            "Iteration 44: Current Loss = 0.8388, Min Loss = 0.8397 with pool 373\n",
            "Iteration 45: Current Loss = 0.8383, Min Loss = 0.8388 with pool 372\n",
            "Iteration 46: Current Loss = 0.8370, Min Loss = 0.8383 with pool 335\n",
            "Iteration 47: Current Loss = 0.8366, Min Loss = 0.8370 with pool 334\n",
            "Iteration 48: Current Loss = 0.8365, Min Loss = 0.8366 with pool 333\n",
            "Iteration 49: Current Loss = 0.8363, Min Loss = 0.8365 with pool 330\n",
            "Iteration 50: Current Loss = 0.8355, Min Loss = 0.8363 with pool 329\n",
            "Iteration 51: Current Loss = 0.8358, Min Loss = 0.8355 with pool 328\n",
            "Iteration 52: Current Loss = 0.8334, Min Loss = 0.8355 with pool 291\n",
            "Iteration 53: Current Loss = 0.8317, Min Loss = 0.8334 with pool 254\n",
            "Iteration 54: Current Loss = 0.8288, Min Loss = 0.8317 with pool 253\n",
            "Iteration 55: Current Loss = 0.8260, Min Loss = 0.8288 with pool 252\n",
            "Iteration 56: Current Loss = 0.8248, Min Loss = 0.8260 with pool 215\n",
            "Iteration 57: Current Loss = 0.8225, Min Loss = 0.8248 with pool 214\n",
            "Iteration 58: Current Loss = 0.8203, Min Loss = 0.8225 with pool 213\n",
            "Iteration 59: Current Loss = 0.8200, Min Loss = 0.8203 with pool 211\n",
            "Iteration 60: Current Loss = 0.8187, Min Loss = 0.8200 with pool 210\n",
            "Iteration 61: Current Loss = 0.8167, Min Loss = 0.8187 with pool 209\n",
            "Iteration 62: Current Loss = 0.8158, Min Loss = 0.8167 with pool 172\n",
            "Iteration 63: Current Loss = 0.8156, Min Loss = 0.8158 with pool 171\n",
            "Iteration 64: Current Loss = 0.8143, Min Loss = 0.8156 with pool 134\n",
            "Iteration 65: Current Loss = 0.8121, Min Loss = 0.8143 with pool 97\n",
            "Iteration 66: Current Loss = 0.8115, Min Loss = 0.8121 with pool 60\n",
            "Iteration 67: Current Loss = 0.8038, Min Loss = 0.8115 with pool 23\n",
            "Active learning stopped after 67 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0445, Min Loss = inf with pool 683\n",
            "Iteration 2: Current Loss = 1.0299, Min Loss = 1.0445 with pool 646\n",
            "Iteration 3: Current Loss = 1.0113, Min Loss = 1.0299 with pool 609\n",
            "Iteration 4: Current Loss = 0.9918, Min Loss = 1.0113 with pool 572\n",
            "Iteration 5: Current Loss = 0.9735, Min Loss = 0.9918 with pool 535\n",
            "Iteration 6: Current Loss = 0.9571, Min Loss = 0.9735 with pool 498\n",
            "Iteration 7: Current Loss = 0.9430, Min Loss = 0.9571 with pool 461\n",
            "Iteration 8: Current Loss = 0.8888, Min Loss = 0.9430 with pool 424\n",
            "Iteration 9: Current Loss = 0.8730, Min Loss = 0.8888 with pool 405\n",
            "Iteration 10: Current Loss = 0.8716, Min Loss = 0.8730 with pool 390\n",
            "Iteration 11: Current Loss = 0.8708, Min Loss = 0.8716 with pool 388\n",
            "Iteration 12: Current Loss = 0.8690, Min Loss = 0.8708 with pool 385\n",
            "Iteration 13: Current Loss = 0.8680, Min Loss = 0.8690 with pool 382\n",
            "Iteration 14: Current Loss = 0.8663, Min Loss = 0.8680 with pool 379\n",
            "Iteration 15: Current Loss = 0.8648, Min Loss = 0.8663 with pool 372\n",
            "Iteration 16: Current Loss = 0.8631, Min Loss = 0.8648 with pool 369\n",
            "Iteration 17: Current Loss = 0.8464, Min Loss = 0.8631 with pool 365\n",
            "Iteration 18: Current Loss = 0.8309, Min Loss = 0.8464 with pool 346\n",
            "Iteration 19: Current Loss = 0.8296, Min Loss = 0.8309 with pool 321\n",
            "Iteration 20: Current Loss = 0.8275, Min Loss = 0.8296 with pool 320\n",
            "Iteration 21: Current Loss = 0.8259, Min Loss = 0.8275 with pool 317\n",
            "Iteration 22: Current Loss = 0.8252, Min Loss = 0.8259 with pool 316\n",
            "Iteration 23: Current Loss = 0.8236, Min Loss = 0.8252 with pool 312\n",
            "Iteration 24: Current Loss = 0.8231, Min Loss = 0.8236 with pool 311\n",
            "Iteration 25: Current Loss = 0.8213, Min Loss = 0.8231 with pool 309\n",
            "Iteration 26: Current Loss = 0.8191, Min Loss = 0.8213 with pool 308\n",
            "Iteration 27: Current Loss = 0.8188, Min Loss = 0.8191 with pool 271\n",
            "Iteration 28: Current Loss = 0.8177, Min Loss = 0.8188 with pool 269\n",
            "Iteration 29: Current Loss = 0.8172, Min Loss = 0.8177 with pool 267\n",
            "Iteration 30: Current Loss = 0.8159, Min Loss = 0.8172 with pool 230\n",
            "Iteration 31: Current Loss = 0.8126, Min Loss = 0.8159 with pool 229\n",
            "Iteration 32: Current Loss = 0.8105, Min Loss = 0.8126 with pool 228\n",
            "Iteration 33: Current Loss = 0.8091, Min Loss = 0.8105 with pool 226\n",
            "Iteration 34: Current Loss = 0.8057, Min Loss = 0.8091 with pool 189\n",
            "Iteration 35: Current Loss = 0.8052, Min Loss = 0.8057 with pool 188\n",
            "Iteration 36: Current Loss = 0.8034, Min Loss = 0.8052 with pool 186\n",
            "Iteration 37: Current Loss = 0.8035, Min Loss = 0.8034 with pool 184\n",
            "Iteration 38: Current Loss = 0.8014, Min Loss = 0.8034 with pool 183\n",
            "Iteration 39: Current Loss = 0.8003, Min Loss = 0.8014 with pool 181\n",
            "Iteration 40: Current Loss = 0.7992, Min Loss = 0.8003 with pool 144\n",
            "Iteration 41: Current Loss = 0.7986, Min Loss = 0.7992 with pool 142\n",
            "Iteration 42: Current Loss = 0.7986, Min Loss = 0.7986 with pool 141\n",
            "Iteration 43: Current Loss = 0.7974, Min Loss = 0.7986 with pool 139\n",
            "Iteration 44: Current Loss = 0.7968, Min Loss = 0.7974 with pool 138\n",
            "Iteration 45: Current Loss = 0.7945, Min Loss = 0.7968 with pool 101\n",
            "Iteration 46: Current Loss = 0.7950, Min Loss = 0.7945 with pool 99\n",
            "Iteration 47: Current Loss = 0.7951, Min Loss = 0.7945 with pool 62\n",
            "Iteration 48: Current Loss = 0.7947, Min Loss = 0.7945 with pool 25\n",
            "Active learning stopped after 48 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.2589, Min Loss = inf with pool 683\n",
            "Iteration 2: Current Loss = 1.2394, Min Loss = 1.2589 with pool 646\n",
            "Iteration 3: Current Loss = 1.2148, Min Loss = 1.2394 with pool 609\n",
            "Iteration 4: Current Loss = 1.1870, Min Loss = 1.2148 with pool 572\n",
            "Iteration 5: Current Loss = 0.9646, Min Loss = 1.1870 with pool 535\n",
            "Iteration 6: Current Loss = 0.9061, Min Loss = 0.9646 with pool 498\n",
            "Iteration 7: Current Loss = 0.8884, Min Loss = 0.9061 with pool 461\n",
            "Iteration 8: Current Loss = 0.8866, Min Loss = 0.8884 with pool 424\n",
            "Iteration 9: Current Loss = 0.8849, Min Loss = 0.8866 with pool 387\n",
            "Iteration 10: Current Loss = 0.8825, Min Loss = 0.8849 with pool 350\n",
            "Iteration 11: Current Loss = 0.8799, Min Loss = 0.8825 with pool 331\n",
            "Iteration 12: Current Loss = 0.8783, Min Loss = 0.8799 with pool 328\n",
            "Iteration 13: Current Loss = 0.8768, Min Loss = 0.8783 with pool 326\n",
            "Iteration 14: Current Loss = 0.8757, Min Loss = 0.8768 with pool 324\n",
            "Iteration 15: Current Loss = 0.8749, Min Loss = 0.8757 with pool 323\n",
            "Iteration 16: Current Loss = 0.8736, Min Loss = 0.8749 with pool 321\n",
            "Iteration 17: Current Loss = 0.8729, Min Loss = 0.8736 with pool 318\n",
            "Iteration 18: Current Loss = 0.8715, Min Loss = 0.8729 with pool 316\n",
            "Iteration 19: Current Loss = 0.8707, Min Loss = 0.8715 with pool 312\n",
            "Iteration 20: Current Loss = 0.8692, Min Loss = 0.8707 with pool 310\n",
            "Iteration 21: Current Loss = 0.8685, Min Loss = 0.8692 with pool 308\n",
            "Iteration 22: Current Loss = 0.8677, Min Loss = 0.8685 with pool 300\n",
            "Iteration 23: Current Loss = 0.8668, Min Loss = 0.8677 with pool 298\n",
            "Iteration 24: Current Loss = 0.8663, Min Loss = 0.8668 with pool 297\n",
            "Iteration 25: Current Loss = 0.8651, Min Loss = 0.8663 with pool 295\n",
            "Iteration 26: Current Loss = 0.8641, Min Loss = 0.8651 with pool 294\n",
            "Iteration 27: Current Loss = 0.8634, Min Loss = 0.8641 with pool 293\n",
            "Iteration 28: Current Loss = 0.8603, Min Loss = 0.8634 with pool 291\n",
            "Iteration 29: Current Loss = 0.8608, Min Loss = 0.8603 with pool 278\n",
            "Iteration 30: Current Loss = 0.8593, Min Loss = 0.8603 with pool 277\n",
            "Iteration 31: Current Loss = 0.8610, Min Loss = 0.8593 with pool 271\n",
            "Iteration 32: Current Loss = 0.8620, Min Loss = 0.8593 with pool 270\n",
            "Iteration 33: Current Loss = 0.8628, Min Loss = 0.8593 with pool 265\n",
            "Iteration 34: Current Loss = 0.8628, Min Loss = 0.8593 with pool 264\n",
            "Iteration 34: Current Loss = 0.8628, Min Loss = 0.8593\n",
            "Active learning stopped after 33 iterations.\n",
            "Average Loss: 0.8314\n",
            "\n",
            "New training with nodes 188 and n_queries 5\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9100, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9101, Min Loss = 0.9100 with pool 710\n",
            "Iteration 3: Current Loss = 0.9106, Min Loss = 0.9100 with pool 705\n",
            "Iteration 4: Current Loss = 0.9110, Min Loss = 0.9100 with pool 700\n",
            "Iteration 5: Current Loss = 0.9112, Min Loss = 0.9100 with pool 695\n",
            "Iteration 5: Current Loss = 0.9112, Min Loss = 0.9100\n",
            "Active learning stopped after 4 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9352, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9355, Min Loss = 0.9352 with pool 710\n",
            "Iteration 3: Current Loss = 0.9361, Min Loss = 0.9352 with pool 705\n",
            "Iteration 4: Current Loss = 0.9343, Min Loss = 0.9352 with pool 700\n",
            "Iteration 5: Current Loss = 0.9343, Min Loss = 0.9343 with pool 695\n",
            "Iteration 6: Current Loss = 0.9341, Min Loss = 0.9343 with pool 690\n",
            "Iteration 7: Current Loss = 0.9322, Min Loss = 0.9341 with pool 685\n",
            "Iteration 8: Current Loss = 0.9288, Min Loss = 0.9322 with pool 680\n",
            "Iteration 9: Current Loss = 0.9222, Min Loss = 0.9288 with pool 675\n",
            "Iteration 10: Current Loss = 0.9160, Min Loss = 0.9222 with pool 670\n",
            "Iteration 11: Current Loss = 0.9104, Min Loss = 0.9160 with pool 665\n",
            "Iteration 12: Current Loss = 0.9073, Min Loss = 0.9104 with pool 660\n",
            "Iteration 13: Current Loss = 0.9025, Min Loss = 0.9073 with pool 655\n",
            "Iteration 14: Current Loss = 0.8974, Min Loss = 0.9025 with pool 650\n",
            "Iteration 15: Current Loss = 0.8936, Min Loss = 0.8974 with pool 645\n",
            "Iteration 16: Current Loss = 0.8922, Min Loss = 0.8936 with pool 640\n",
            "Iteration 17: Current Loss = 0.8896, Min Loss = 0.8922 with pool 635\n",
            "Iteration 18: Current Loss = 0.8884, Min Loss = 0.8896 with pool 630\n",
            "Iteration 19: Current Loss = 0.8856, Min Loss = 0.8884 with pool 625\n",
            "Iteration 20: Current Loss = 0.8804, Min Loss = 0.8856 with pool 620\n",
            "Iteration 21: Current Loss = 0.8763, Min Loss = 0.8804 with pool 615\n",
            "Iteration 22: Current Loss = 0.8760, Min Loss = 0.8763 with pool 610\n",
            "Iteration 23: Current Loss = 0.8711, Min Loss = 0.8760 with pool 605\n",
            "Iteration 24: Current Loss = 0.8669, Min Loss = 0.8711 with pool 600\n",
            "Iteration 25: Current Loss = 0.8596, Min Loss = 0.8669 with pool 595\n",
            "Iteration 26: Current Loss = 0.8579, Min Loss = 0.8596 with pool 590\n",
            "Iteration 27: Current Loss = 0.8612, Min Loss = 0.8579 with pool 585\n",
            "Iteration 28: Current Loss = 0.8611, Min Loss = 0.8579 with pool 580\n",
            "Iteration 29: Current Loss = 0.8641, Min Loss = 0.8579 with pool 575\n",
            "Iteration 30: Current Loss = 0.8673, Min Loss = 0.8579 with pool 570\n",
            "Iteration 30: Current Loss = 0.8673, Min Loss = 0.8579\n",
            "Active learning stopped after 29 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9050, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9066, Min Loss = 0.9050 with pool 710\n",
            "Iteration 3: Current Loss = 0.9060, Min Loss = 0.9050 with pool 705\n",
            "Iteration 4: Current Loss = 0.9046, Min Loss = 0.9050 with pool 700\n",
            "Iteration 5: Current Loss = 0.9041, Min Loss = 0.9046 with pool 695\n",
            "Iteration 6: Current Loss = 0.9017, Min Loss = 0.9041 with pool 690\n",
            "Iteration 7: Current Loss = 0.8986, Min Loss = 0.9017 with pool 685\n",
            "Iteration 8: Current Loss = 0.8949, Min Loss = 0.8986 with pool 680\n",
            "Iteration 9: Current Loss = 0.8907, Min Loss = 0.8949 with pool 675\n",
            "Iteration 10: Current Loss = 0.8893, Min Loss = 0.8907 with pool 670\n",
            "Iteration 11: Current Loss = 0.8843, Min Loss = 0.8893 with pool 665\n",
            "Iteration 12: Current Loss = 0.8869, Min Loss = 0.8843 with pool 660\n",
            "Iteration 13: Current Loss = 0.8892, Min Loss = 0.8843 with pool 655\n",
            "Iteration 14: Current Loss = 0.8917, Min Loss = 0.8843 with pool 650\n",
            "Iteration 15: Current Loss = 0.8942, Min Loss = 0.8843 with pool 645\n",
            "Iteration 15: Current Loss = 0.8942, Min Loss = 0.8843\n",
            "Active learning stopped after 14 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9231, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9267, Min Loss = 0.9231 with pool 710\n",
            "Iteration 3: Current Loss = 0.9291, Min Loss = 0.9231 with pool 705\n",
            "Iteration 4: Current Loss = 0.9293, Min Loss = 0.9231 with pool 700\n",
            "Iteration 5: Current Loss = 0.9259, Min Loss = 0.9231 with pool 695\n",
            "Iteration 5: Current Loss = 0.9259, Min Loss = 0.9231\n",
            "Active learning stopped after 4 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9521, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9634, Min Loss = 0.9521 with pool 710\n",
            "Iteration 3: Current Loss = 0.9720, Min Loss = 0.9521 with pool 705\n",
            "Iteration 4: Current Loss = 0.9746, Min Loss = 0.9521 with pool 700\n",
            "Iteration 5: Current Loss = 0.9737, Min Loss = 0.9521 with pool 695\n",
            "Iteration 5: Current Loss = 0.9737, Min Loss = 0.9521\n",
            "Active learning stopped after 4 iterations.\n",
            "Average Loss: 0.9055\n",
            "\n",
            "New training with nodes 198 and n_queries 33\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9422, Min Loss = inf with pool 687\n",
            "Iteration 2: Current Loss = 0.9038, Min Loss = 0.9422 with pool 654\n",
            "Iteration 3: Current Loss = 0.8990, Min Loss = 0.9038 with pool 621\n",
            "Iteration 4: Current Loss = 0.8635, Min Loss = 0.8990 with pool 588\n",
            "Iteration 5: Current Loss = 0.8484, Min Loss = 0.8635 with pool 555\n",
            "Iteration 6: Current Loss = 0.8448, Min Loss = 0.8484 with pool 522\n",
            "Iteration 7: Current Loss = 0.8393, Min Loss = 0.8448 with pool 489\n",
            "Iteration 8: Current Loss = 0.8304, Min Loss = 0.8393 with pool 456\n",
            "Iteration 9: Current Loss = 0.8229, Min Loss = 0.8304 with pool 423\n",
            "Iteration 10: Current Loss = 0.8114, Min Loss = 0.8229 with pool 390\n",
            "Iteration 11: Current Loss = 0.8074, Min Loss = 0.8114 with pool 357\n",
            "Iteration 12: Current Loss = 0.7995, Min Loss = 0.8074 with pool 331\n",
            "Iteration 13: Current Loss = 0.7909, Min Loss = 0.7995 with pool 312\n",
            "Iteration 14: Current Loss = 0.7812, Min Loss = 0.7909 with pool 305\n",
            "Iteration 15: Current Loss = 0.7763, Min Loss = 0.7812 with pool 296\n",
            "Iteration 16: Current Loss = 0.7707, Min Loss = 0.7763 with pool 290\n",
            "Iteration 17: Current Loss = 0.7650, Min Loss = 0.7707 with pool 283\n",
            "Iteration 18: Current Loss = 0.7611, Min Loss = 0.7650 with pool 275\n",
            "Iteration 19: Current Loss = 0.7591, Min Loss = 0.7611 with pool 268\n",
            "Iteration 20: Current Loss = 0.7602, Min Loss = 0.7591 with pool 254\n",
            "Iteration 21: Current Loss = 0.7578, Min Loss = 0.7591 with pool 243\n",
            "Iteration 22: Current Loss = 0.7547, Min Loss = 0.7578 with pool 237\n",
            "Iteration 23: Current Loss = 0.7590, Min Loss = 0.7547 with pool 230\n",
            "Iteration 24: Current Loss = 0.7459, Min Loss = 0.7547 with pool 223\n",
            "Iteration 25: Current Loss = 0.7507, Min Loss = 0.7459 with pool 221\n",
            "Iteration 26: Current Loss = 0.7464, Min Loss = 0.7459 with pool 217\n",
            "Iteration 27: Current Loss = 0.7506, Min Loss = 0.7459 with pool 211\n",
            "Iteration 28: Current Loss = 0.7485, Min Loss = 0.7459 with pool 207\n",
            "Iteration 28: Current Loss = 0.7485, Min Loss = 0.7459\n",
            "Active learning stopped after 27 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9485, Min Loss = inf with pool 687\n",
            "Iteration 2: Current Loss = 0.9335, Min Loss = 0.9485 with pool 654\n",
            "Iteration 3: Current Loss = 0.9331, Min Loss = 0.9335 with pool 621\n",
            "Iteration 4: Current Loss = 0.9026, Min Loss = 0.9331 with pool 588\n",
            "Iteration 5: Current Loss = 0.9044, Min Loss = 0.9026 with pool 555\n",
            "Iteration 6: Current Loss = 0.8979, Min Loss = 0.9026 with pool 522\n",
            "Iteration 7: Current Loss = 0.8819, Min Loss = 0.8979 with pool 489\n",
            "Iteration 8: Current Loss = 0.8685, Min Loss = 0.8819 with pool 456\n",
            "Iteration 9: Current Loss = 0.8482, Min Loss = 0.8685 with pool 423\n",
            "Iteration 10: Current Loss = 0.8080, Min Loss = 0.8482 with pool 390\n",
            "Iteration 11: Current Loss = 0.8048, Min Loss = 0.8080 with pool 357\n",
            "Iteration 12: Current Loss = 0.8027, Min Loss = 0.8048 with pool 324\n",
            "Iteration 13: Current Loss = 0.7650, Min Loss = 0.8027 with pool 306\n",
            "Iteration 14: Current Loss = 0.7635, Min Loss = 0.7650 with pool 273\n",
            "Iteration 15: Current Loss = 0.7623, Min Loss = 0.7635 with pool 242\n",
            "Iteration 16: Current Loss = 0.7566, Min Loss = 0.7623 with pool 234\n",
            "Iteration 17: Current Loss = 0.7455, Min Loss = 0.7566 with pool 221\n",
            "Iteration 18: Current Loss = 0.7486, Min Loss = 0.7455 with pool 220\n",
            "Iteration 19: Current Loss = 0.7421, Min Loss = 0.7455 with pool 215\n",
            "Iteration 20: Current Loss = 0.7443, Min Loss = 0.7421 with pool 214\n",
            "Iteration 21: Current Loss = 0.7362, Min Loss = 0.7421 with pool 181\n",
            "Iteration 22: Current Loss = 0.7301, Min Loss = 0.7362 with pool 179\n",
            "Iteration 23: Current Loss = 0.7365, Min Loss = 0.7301 with pool 173\n",
            "Iteration 24: Current Loss = 0.7304, Min Loss = 0.7301 with pool 169\n",
            "Iteration 25: Current Loss = 0.7286, Min Loss = 0.7301 with pool 168\n",
            "Iteration 26: Current Loss = 0.7289, Min Loss = 0.7286 with pool 167\n",
            "Iteration 27: Current Loss = 0.7281, Min Loss = 0.7286 with pool 163\n",
            "Iteration 28: Current Loss = 0.7268, Min Loss = 0.7281 with pool 157\n",
            "Iteration 29: Current Loss = 0.7225, Min Loss = 0.7268 with pool 152\n",
            "Iteration 30: Current Loss = 0.7216, Min Loss = 0.7225 with pool 147\n",
            "Iteration 31: Current Loss = 0.7209, Min Loss = 0.7216 with pool 143\n",
            "Iteration 32: Current Loss = 0.7244, Min Loss = 0.7209 with pool 138\n",
            "Iteration 33: Current Loss = 0.7201, Min Loss = 0.7209 with pool 134\n",
            "Iteration 34: Current Loss = 0.7249, Min Loss = 0.7201 with pool 101\n",
            "Iteration 35: Current Loss = 0.7158, Min Loss = 0.7201 with pool 99\n",
            "Iteration 36: Current Loss = 0.7148, Min Loss = 0.7158 with pool 66\n",
            "Iteration 37: Current Loss = 0.7174, Min Loss = 0.7148 with pool 33\n",
            "Iteration 38: Current Loss = 0.7029, Min Loss = 0.7148 with pool 32\n",
            "Active learning stopped after 38 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9241, Min Loss = inf with pool 687\n",
            "Iteration 2: Current Loss = 0.8815, Min Loss = 0.9241 with pool 654\n",
            "Iteration 3: Current Loss = 0.8815, Min Loss = 0.8815 with pool 621\n",
            "Iteration 4: Current Loss = 0.8785, Min Loss = 0.8815 with pool 588\n",
            "Iteration 5: Current Loss = 0.8702, Min Loss = 0.8785 with pool 555\n",
            "Iteration 6: Current Loss = 0.8443, Min Loss = 0.8702 with pool 522\n",
            "Iteration 7: Current Loss = 0.8410, Min Loss = 0.8443 with pool 489\n",
            "Iteration 8: Current Loss = 0.8384, Min Loss = 0.8410 with pool 456\n",
            "Iteration 9: Current Loss = 0.8360, Min Loss = 0.8384 with pool 423\n",
            "Iteration 10: Current Loss = 0.8350, Min Loss = 0.8360 with pool 403\n",
            "Iteration 11: Current Loss = 0.8348, Min Loss = 0.8350 with pool 397\n",
            "Iteration 12: Current Loss = 0.8313, Min Loss = 0.8348 with pool 386\n",
            "Iteration 13: Current Loss = 0.8276, Min Loss = 0.8313 with pool 375\n",
            "Iteration 14: Current Loss = 0.8304, Min Loss = 0.8276 with pool 372\n",
            "Iteration 15: Current Loss = 0.8300, Min Loss = 0.8276 with pool 359\n",
            "Iteration 16: Current Loss = 0.8274, Min Loss = 0.8276 with pool 353\n",
            "Iteration 17: Current Loss = 0.8330, Min Loss = 0.8274 with pool 351\n",
            "Iteration 18: Current Loss = 0.8317, Min Loss = 0.8274 with pool 343\n",
            "Iteration 19: Current Loss = 0.8291, Min Loss = 0.8274 with pool 336\n",
            "Iteration 20: Current Loss = 0.8304, Min Loss = 0.8274 with pool 331\n",
            "Iteration 20: Current Loss = 0.8304, Min Loss = 0.8274\n",
            "Active learning stopped after 19 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9025, Min Loss = inf with pool 687\n",
            "Iteration 2: Current Loss = 0.9035, Min Loss = 0.9025 with pool 654\n",
            "Iteration 3: Current Loss = 0.8764, Min Loss = 0.9025 with pool 621\n",
            "Iteration 4: Current Loss = 0.8692, Min Loss = 0.8764 with pool 588\n",
            "Iteration 5: Current Loss = 0.8705, Min Loss = 0.8692 with pool 555\n",
            "Iteration 6: Current Loss = 0.8630, Min Loss = 0.8692 with pool 522\n",
            "Iteration 7: Current Loss = 0.8569, Min Loss = 0.8630 with pool 489\n",
            "Iteration 8: Current Loss = 0.8479, Min Loss = 0.8569 with pool 456\n",
            "Iteration 9: Current Loss = 0.8407, Min Loss = 0.8479 with pool 427\n",
            "Iteration 10: Current Loss = 0.8343, Min Loss = 0.8407 with pool 415\n",
            "Iteration 11: Current Loss = 0.8289, Min Loss = 0.8343 with pool 405\n",
            "Iteration 12: Current Loss = 0.8263, Min Loss = 0.8289 with pool 394\n",
            "Iteration 13: Current Loss = 0.8223, Min Loss = 0.8263 with pool 384\n",
            "Iteration 14: Current Loss = 0.8231, Min Loss = 0.8223 with pool 382\n",
            "Iteration 15: Current Loss = 0.8167, Min Loss = 0.8223 with pool 371\n",
            "Iteration 16: Current Loss = 0.8147, Min Loss = 0.8167 with pool 366\n",
            "Iteration 17: Current Loss = 0.8101, Min Loss = 0.8147 with pool 360\n",
            "Iteration 18: Current Loss = 0.8074, Min Loss = 0.8101 with pool 352\n",
            "Iteration 19: Current Loss = 0.8050, Min Loss = 0.8074 with pool 344\n",
            "Iteration 20: Current Loss = 0.8039, Min Loss = 0.8050 with pool 336\n",
            "Iteration 21: Current Loss = 0.8006, Min Loss = 0.8039 with pool 329\n",
            "Iteration 22: Current Loss = 0.7988, Min Loss = 0.8006 with pool 324\n",
            "Iteration 23: Current Loss = 0.7929, Min Loss = 0.7988 with pool 315\n",
            "Iteration 24: Current Loss = 0.7934, Min Loss = 0.7929 with pool 310\n",
            "Iteration 25: Current Loss = 0.7919, Min Loss = 0.7929 with pool 305\n",
            "Iteration 26: Current Loss = 0.7912, Min Loss = 0.7919 with pool 303\n",
            "Iteration 27: Current Loss = 0.7883, Min Loss = 0.7912 with pool 298\n",
            "Iteration 28: Current Loss = 0.7907, Min Loss = 0.7883 with pool 294\n",
            "Iteration 29: Current Loss = 0.7877, Min Loss = 0.7883 with pool 290\n",
            "Iteration 30: Current Loss = 0.7852, Min Loss = 0.7877 with pool 286\n",
            "Iteration 31: Current Loss = 0.7826, Min Loss = 0.7852 with pool 282\n",
            "Iteration 32: Current Loss = 0.7790, Min Loss = 0.7826 with pool 276\n",
            "Iteration 33: Current Loss = 0.7783, Min Loss = 0.7790 with pool 273\n",
            "Iteration 34: Current Loss = 0.7752, Min Loss = 0.7783 with pool 270\n",
            "Iteration 35: Current Loss = 0.7780, Min Loss = 0.7752 with pool 265\n",
            "Iteration 36: Current Loss = 0.7693, Min Loss = 0.7752 with pool 260\n",
            "Iteration 37: Current Loss = 0.7734, Min Loss = 0.7693 with pool 255\n",
            "Iteration 38: Current Loss = 0.7692, Min Loss = 0.7693 with pool 253\n",
            "Iteration 39: Current Loss = 0.7702, Min Loss = 0.7692 with pool 251\n",
            "Iteration 40: Current Loss = 0.7685, Min Loss = 0.7692 with pool 250\n",
            "Iteration 41: Current Loss = 0.7709, Min Loss = 0.7685 with pool 247\n",
            "Iteration 42: Current Loss = 0.7634, Min Loss = 0.7685 with pool 241\n",
            "Iteration 43: Current Loss = 0.7678, Min Loss = 0.7634 with pool 235\n",
            "Iteration 44: Current Loss = 0.7645, Min Loss = 0.7634 with pool 228\n",
            "Iteration 45: Current Loss = 0.7629, Min Loss = 0.7634 with pool 225\n",
            "Iteration 46: Current Loss = 0.7565, Min Loss = 0.7629 with pool 222\n",
            "Iteration 47: Current Loss = 0.7574, Min Loss = 0.7565 with pool 218\n",
            "Iteration 48: Current Loss = 0.7570, Min Loss = 0.7565 with pool 217\n",
            "Iteration 49: Current Loss = 0.7511, Min Loss = 0.7565 with pool 184\n",
            "Iteration 50: Current Loss = 0.7428, Min Loss = 0.7511 with pool 181\n",
            "Iteration 51: Current Loss = 0.7359, Min Loss = 0.7428 with pool 178\n",
            "Iteration 52: Current Loss = 0.7452, Min Loss = 0.7359 with pool 176\n",
            "Iteration 53: Current Loss = 0.7440, Min Loss = 0.7359 with pool 172\n",
            "Iteration 54: Current Loss = 0.7396, Min Loss = 0.7359 with pool 169\n",
            "Iteration 55: Current Loss = 0.7459, Min Loss = 0.7359 with pool 167\n",
            "Iteration 55: Current Loss = 0.7459, Min Loss = 0.7359\n",
            "Active learning stopped after 54 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9361, Min Loss = inf with pool 687\n",
            "Iteration 2: Current Loss = 0.9297, Min Loss = 0.9361 with pool 654\n",
            "Iteration 3: Current Loss = 0.8852, Min Loss = 0.9297 with pool 621\n",
            "Iteration 4: Current Loss = 0.8881, Min Loss = 0.8852 with pool 588\n",
            "Iteration 5: Current Loss = 0.8871, Min Loss = 0.8852 with pool 561\n",
            "Iteration 6: Current Loss = 0.8866, Min Loss = 0.8852 with pool 552\n",
            "Iteration 7: Current Loss = 0.8873, Min Loss = 0.8852 with pool 546\n",
            "Iteration 7: Current Loss = 0.8873, Min Loss = 0.8852\n",
            "Active learning stopped after 6 iterations.\n",
            "Average Loss: 0.7795\n",
            "\n",
            "New training with nodes 124 and n_queries 5\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9772, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9738, Min Loss = 0.9772 with pool 710\n",
            "Iteration 3: Current Loss = 0.9729, Min Loss = 0.9738 with pool 705\n",
            "Iteration 4: Current Loss = 0.9736, Min Loss = 0.9729 with pool 700\n",
            "Iteration 5: Current Loss = 0.9737, Min Loss = 0.9729 with pool 695\n",
            "Iteration 6: Current Loss = 0.9685, Min Loss = 0.9729 with pool 690\n",
            "Iteration 7: Current Loss = 0.9616, Min Loss = 0.9685 with pool 685\n",
            "Iteration 8: Current Loss = 0.9518, Min Loss = 0.9616 with pool 680\n",
            "Iteration 9: Current Loss = 0.9401, Min Loss = 0.9518 with pool 675\n",
            "Iteration 10: Current Loss = 0.9281, Min Loss = 0.9401 with pool 670\n",
            "Iteration 11: Current Loss = 0.9190, Min Loss = 0.9281 with pool 665\n",
            "Iteration 12: Current Loss = 0.9122, Min Loss = 0.9190 with pool 660\n",
            "Iteration 13: Current Loss = 0.9055, Min Loss = 0.9122 with pool 655\n",
            "Iteration 14: Current Loss = 0.8994, Min Loss = 0.9055 with pool 650\n",
            "Iteration 15: Current Loss = 0.8940, Min Loss = 0.8994 with pool 645\n",
            "Iteration 16: Current Loss = 0.8901, Min Loss = 0.8940 with pool 640\n",
            "Iteration 17: Current Loss = 0.8888, Min Loss = 0.8901 with pool 635\n",
            "Iteration 18: Current Loss = 0.8878, Min Loss = 0.8888 with pool 630\n",
            "Iteration 19: Current Loss = 0.8877, Min Loss = 0.8878 with pool 625\n",
            "Iteration 20: Current Loss = 0.8882, Min Loss = 0.8877 with pool 620\n",
            "Iteration 21: Current Loss = 0.8896, Min Loss = 0.8877 with pool 615\n",
            "Iteration 22: Current Loss = 0.8893, Min Loss = 0.8877 with pool 610\n",
            "Iteration 23: Current Loss = 0.8882, Min Loss = 0.8877 with pool 605\n",
            "Iteration 23: Current Loss = 0.8882, Min Loss = 0.8877\n",
            "Active learning stopped after 22 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9064, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9063, Min Loss = 0.9064 with pool 710\n",
            "Iteration 3: Current Loss = 0.9064, Min Loss = 0.9063 with pool 705\n",
            "Iteration 4: Current Loss = 0.9060, Min Loss = 0.9063 with pool 700\n",
            "Iteration 5: Current Loss = 0.9054, Min Loss = 0.9060 with pool 695\n",
            "Iteration 6: Current Loss = 0.9046, Min Loss = 0.9054 with pool 690\n",
            "Iteration 7: Current Loss = 0.9006, Min Loss = 0.9046 with pool 685\n",
            "Iteration 8: Current Loss = 0.9005, Min Loss = 0.9006 with pool 680\n",
            "Iteration 9: Current Loss = 0.8993, Min Loss = 0.9005 with pool 675\n",
            "Iteration 10: Current Loss = 0.8971, Min Loss = 0.8993 with pool 670\n",
            "Iteration 11: Current Loss = 0.8954, Min Loss = 0.8971 with pool 665\n",
            "Iteration 12: Current Loss = 0.8915, Min Loss = 0.8954 with pool 660\n",
            "Iteration 13: Current Loss = 0.8864, Min Loss = 0.8915 with pool 655\n",
            "Iteration 14: Current Loss = 0.8781, Min Loss = 0.8864 with pool 650\n",
            "Iteration 15: Current Loss = 0.8767, Min Loss = 0.8781 with pool 645\n",
            "Iteration 16: Current Loss = 0.8708, Min Loss = 0.8767 with pool 640\n",
            "Iteration 17: Current Loss = 0.8704, Min Loss = 0.8708 with pool 635\n",
            "Iteration 18: Current Loss = 0.8694, Min Loss = 0.8704 with pool 630\n",
            "Iteration 19: Current Loss = 0.8699, Min Loss = 0.8694 with pool 625\n",
            "Iteration 20: Current Loss = 0.8716, Min Loss = 0.8694 with pool 620\n",
            "Iteration 21: Current Loss = 0.8726, Min Loss = 0.8694 with pool 615\n",
            "Iteration 22: Current Loss = 0.8741, Min Loss = 0.8694 with pool 610\n",
            "Iteration 22: Current Loss = 0.8741, Min Loss = 0.8694\n",
            "Active learning stopped after 21 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9060, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9069, Min Loss = 0.9060 with pool 710\n",
            "Iteration 3: Current Loss = 0.9089, Min Loss = 0.9060 with pool 705\n",
            "Iteration 4: Current Loss = 0.9089, Min Loss = 0.9060 with pool 700\n",
            "Iteration 5: Current Loss = 0.9072, Min Loss = 0.9060 with pool 695\n",
            "Iteration 5: Current Loss = 0.9072, Min Loss = 0.9060\n",
            "Active learning stopped after 4 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9060, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9055, Min Loss = 0.9060 with pool 710\n",
            "Iteration 3: Current Loss = 0.9041, Min Loss = 0.9055 with pool 705\n",
            "Iteration 4: Current Loss = 0.9012, Min Loss = 0.9041 with pool 700\n",
            "Iteration 5: Current Loss = 0.8974, Min Loss = 0.9012 with pool 695\n",
            "Iteration 6: Current Loss = 0.8839, Min Loss = 0.8974 with pool 690\n",
            "Iteration 7: Current Loss = 0.8840, Min Loss = 0.8839 with pool 685\n",
            "Iteration 8: Current Loss = 0.8850, Min Loss = 0.8839 with pool 680\n",
            "Iteration 9: Current Loss = 0.8855, Min Loss = 0.8839 with pool 675\n",
            "Iteration 10: Current Loss = 0.8907, Min Loss = 0.8839 with pool 670\n",
            "Iteration 10: Current Loss = 0.8907, Min Loss = 0.8839\n",
            "Active learning stopped after 9 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9418, Min Loss = inf with pool 715\n",
            "Iteration 2: Current Loss = 0.9392, Min Loss = 0.9418 with pool 710\n",
            "Iteration 3: Current Loss = 0.9372, Min Loss = 0.9392 with pool 705\n",
            "Iteration 4: Current Loss = 0.9358, Min Loss = 0.9372 with pool 700\n",
            "Iteration 5: Current Loss = 0.9344, Min Loss = 0.9358 with pool 695\n",
            "Iteration 6: Current Loss = 0.9329, Min Loss = 0.9344 with pool 690\n",
            "Iteration 7: Current Loss = 0.9313, Min Loss = 0.9329 with pool 685\n",
            "Iteration 8: Current Loss = 0.9297, Min Loss = 0.9313 with pool 680\n",
            "Iteration 9: Current Loss = 0.9265, Min Loss = 0.9297 with pool 675\n",
            "Iteration 10: Current Loss = 0.9216, Min Loss = 0.9265 with pool 670\n",
            "Iteration 11: Current Loss = 0.9085, Min Loss = 0.9216 with pool 665\n",
            "Iteration 12: Current Loss = 0.9077, Min Loss = 0.9085 with pool 660\n",
            "Iteration 13: Current Loss = 0.9068, Min Loss = 0.9077 with pool 655\n",
            "Iteration 14: Current Loss = 0.9049, Min Loss = 0.9068 with pool 650\n",
            "Iteration 15: Current Loss = 0.9027, Min Loss = 0.9049 with pool 645\n",
            "Iteration 16: Current Loss = 0.9012, Min Loss = 0.9027 with pool 640\n",
            "Iteration 17: Current Loss = 0.8999, Min Loss = 0.9012 with pool 635\n",
            "Iteration 18: Current Loss = 0.8990, Min Loss = 0.8999 with pool 630\n",
            "Iteration 19: Current Loss = 0.8976, Min Loss = 0.8990 with pool 625\n",
            "Iteration 20: Current Loss = 0.8948, Min Loss = 0.8976 with pool 620\n",
            "Iteration 21: Current Loss = 0.8916, Min Loss = 0.8948 with pool 615\n",
            "Iteration 22: Current Loss = 0.8874, Min Loss = 0.8916 with pool 610\n",
            "Iteration 23: Current Loss = 0.8840, Min Loss = 0.8874 with pool 605\n",
            "Iteration 24: Current Loss = 0.8805, Min Loss = 0.8840 with pool 600\n",
            "Iteration 25: Current Loss = 0.8771, Min Loss = 0.8805 with pool 595\n",
            "Iteration 26: Current Loss = 0.8755, Min Loss = 0.8771 with pool 590\n",
            "Iteration 27: Current Loss = 0.8717, Min Loss = 0.8755 with pool 585\n",
            "Iteration 28: Current Loss = 0.8692, Min Loss = 0.8717 with pool 580\n",
            "Iteration 29: Current Loss = 0.8663, Min Loss = 0.8692 with pool 575\n",
            "Iteration 30: Current Loss = 0.8652, Min Loss = 0.8663 with pool 570\n",
            "Iteration 31: Current Loss = 0.8645, Min Loss = 0.8652 with pool 565\n",
            "Iteration 32: Current Loss = 0.8650, Min Loss = 0.8645 with pool 560\n",
            "Iteration 33: Current Loss = 0.8645, Min Loss = 0.8645 with pool 555\n",
            "Iteration 34: Current Loss = 0.8635, Min Loss = 0.8645 with pool 550\n",
            "Iteration 35: Current Loss = 0.8625, Min Loss = 0.8635 with pool 545\n",
            "Iteration 36: Current Loss = 0.8608, Min Loss = 0.8625 with pool 540\n",
            "Iteration 37: Current Loss = 0.8630, Min Loss = 0.8608 with pool 535\n",
            "Iteration 38: Current Loss = 0.8637, Min Loss = 0.8608 with pool 530\n",
            "Iteration 39: Current Loss = 0.8664, Min Loss = 0.8608 with pool 525\n",
            "Iteration 40: Current Loss = 0.8635, Min Loss = 0.8608 with pool 520\n",
            "Iteration 40: Current Loss = 0.8635, Min Loss = 0.8608\n",
            "Active learning stopped after 39 iterations.\n",
            "Average Loss: 0.8816\n",
            "\n",
            "New training with nodes 9 and n_queries 29\n",
            "Processing Fold 1/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0814, Min Loss = inf with pool 691\n",
            "Iteration 2: Current Loss = 1.0704, Min Loss = 1.0814 with pool 662\n",
            "Iteration 3: Current Loss = 1.0553, Min Loss = 1.0704 with pool 633\n",
            "Iteration 4: Current Loss = 1.0407, Min Loss = 1.0553 with pool 604\n",
            "Iteration 5: Current Loss = 1.0252, Min Loss = 1.0407 with pool 575\n",
            "Iteration 6: Current Loss = 0.9300, Min Loss = 1.0252 with pool 546\n",
            "Iteration 7: Current Loss = 0.9082, Min Loss = 0.9300 with pool 531\n",
            "Iteration 8: Current Loss = 0.9014, Min Loss = 0.9082 with pool 502\n",
            "Iteration 9: Current Loss = 0.9007, Min Loss = 0.9014 with pool 473\n",
            "Iteration 10: Current Loss = 0.9005, Min Loss = 0.9007 with pool 468\n",
            "Iteration 11: Current Loss = 0.9002, Min Loss = 0.9005 with pool 467\n",
            "Iteration 12: Current Loss = 0.8999, Min Loss = 0.9002 with pool 466\n",
            "Iteration 13: Current Loss = 0.8998, Min Loss = 0.8999 with pool 465\n",
            "Iteration 14: Current Loss = 0.8996, Min Loss = 0.8998 with pool 464\n",
            "Iteration 15: Current Loss = 0.8997, Min Loss = 0.8996 with pool 435\n",
            "Iteration 16: Current Loss = 0.8996, Min Loss = 0.8996 with pool 434\n",
            "Iteration 17: Current Loss = 0.8993, Min Loss = 0.8996 with pool 405\n",
            "Iteration 18: Current Loss = 0.8991, Min Loss = 0.8993 with pool 404\n",
            "Iteration 19: Current Loss = 0.8991, Min Loss = 0.8991 with pool 375\n",
            "Iteration 20: Current Loss = 0.8986, Min Loss = 0.8991 with pool 346\n",
            "Iteration 21: Current Loss = 0.8982, Min Loss = 0.8986 with pool 317\n",
            "Iteration 22: Current Loss = 0.8972, Min Loss = 0.8982 with pool 288\n",
            "Iteration 23: Current Loss = 0.8964, Min Loss = 0.8972 with pool 259\n",
            "Iteration 24: Current Loss = 0.8955, Min Loss = 0.8964 with pool 258\n",
            "Iteration 25: Current Loss = 0.8953, Min Loss = 0.8955 with pool 257\n",
            "Iteration 26: Current Loss = 0.8951, Min Loss = 0.8953 with pool 228\n",
            "Iteration 27: Current Loss = 0.8947, Min Loss = 0.8951 with pool 227\n",
            "Iteration 28: Current Loss = 0.8945, Min Loss = 0.8947 with pool 198\n",
            "Iteration 29: Current Loss = 0.8943, Min Loss = 0.8945 with pool 169\n",
            "Iteration 30: Current Loss = 0.8940, Min Loss = 0.8943 with pool 140\n",
            "Iteration 31: Current Loss = 0.8936, Min Loss = 0.8940 with pool 111\n",
            "Iteration 32: Current Loss = 0.8932, Min Loss = 0.8936 with pool 82\n",
            "Iteration 33: Current Loss = 0.8928, Min Loss = 0.8932 with pool 53\n",
            "Iteration 34: Current Loss = 0.8927, Min Loss = 0.8928 with pool 24\n",
            "Active learning stopped after 34 iterations.\n",
            "Processing Fold 2/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.1589, Min Loss = inf with pool 691\n",
            "Iteration 2: Current Loss = 1.1461, Min Loss = 1.1589 with pool 662\n",
            "Iteration 3: Current Loss = 1.1283, Min Loss = 1.1461 with pool 633\n",
            "Iteration 4: Current Loss = 1.1107, Min Loss = 1.1283 with pool 604\n",
            "Iteration 5: Current Loss = 1.0901, Min Loss = 1.1107 with pool 575\n",
            "Iteration 6: Current Loss = 0.9407, Min Loss = 1.0901 with pool 546\n",
            "Iteration 7: Current Loss = 0.9008, Min Loss = 0.9407 with pool 517\n",
            "Iteration 8: Current Loss = 0.8988, Min Loss = 0.9008 with pool 488\n",
            "Iteration 9: Current Loss = 0.8975, Min Loss = 0.8988 with pool 459\n",
            "Iteration 10: Current Loss = 0.8877, Min Loss = 0.8975 with pool 440\n",
            "Iteration 11: Current Loss = 0.8869, Min Loss = 0.8877 with pool 417\n",
            "Iteration 12: Current Loss = 0.8862, Min Loss = 0.8869 with pool 388\n",
            "Iteration 13: Current Loss = 0.8738, Min Loss = 0.8862 with pool 385\n",
            "Iteration 14: Current Loss = 0.8635, Min Loss = 0.8738 with pool 370\n",
            "Iteration 15: Current Loss = 0.8620, Min Loss = 0.8635 with pool 351\n",
            "Iteration 16: Current Loss = 0.8612, Min Loss = 0.8620 with pool 349\n",
            "Iteration 17: Current Loss = 0.8567, Min Loss = 0.8612 with pool 346\n",
            "Iteration 18: Current Loss = 0.8552, Min Loss = 0.8567 with pool 341\n",
            "Iteration 19: Current Loss = 0.8528, Min Loss = 0.8552 with pool 336\n",
            "Iteration 20: Current Loss = 0.8507, Min Loss = 0.8528 with pool 334\n",
            "Iteration 21: Current Loss = 0.8494, Min Loss = 0.8507 with pool 331\n",
            "Iteration 22: Current Loss = 0.8485, Min Loss = 0.8494 with pool 329\n",
            "Iteration 23: Current Loss = 0.8472, Min Loss = 0.8485 with pool 327\n",
            "Iteration 24: Current Loss = 0.8456, Min Loss = 0.8472 with pool 322\n",
            "Iteration 25: Current Loss = 0.8445, Min Loss = 0.8456 with pool 321\n",
            "Iteration 26: Current Loss = 0.8436, Min Loss = 0.8445 with pool 320\n",
            "Iteration 27: Current Loss = 0.8428, Min Loss = 0.8436 with pool 319\n",
            "Iteration 28: Current Loss = 0.8419, Min Loss = 0.8428 with pool 316\n",
            "Iteration 29: Current Loss = 0.8410, Min Loss = 0.8419 with pool 315\n",
            "Iteration 30: Current Loss = 0.8407, Min Loss = 0.8410 with pool 311\n",
            "Iteration 31: Current Loss = 0.8386, Min Loss = 0.8407 with pool 309\n",
            "Iteration 32: Current Loss = 0.8386, Min Loss = 0.8386 with pool 308\n",
            "Iteration 33: Current Loss = 0.8377, Min Loss = 0.8386 with pool 302\n",
            "Iteration 34: Current Loss = 0.8372, Min Loss = 0.8377 with pool 301\n",
            "Iteration 35: Current Loss = 0.8364, Min Loss = 0.8372 with pool 299\n",
            "Iteration 36: Current Loss = 0.8354, Min Loss = 0.8364 with pool 298\n",
            "Iteration 37: Current Loss = 0.8336, Min Loss = 0.8354 with pool 269\n",
            "Iteration 38: Current Loss = 0.8320, Min Loss = 0.8336 with pool 266\n",
            "Iteration 39: Current Loss = 0.8314, Min Loss = 0.8320 with pool 265\n",
            "Iteration 40: Current Loss = 0.8302, Min Loss = 0.8314 with pool 236\n",
            "Iteration 41: Current Loss = 0.8304, Min Loss = 0.8302 with pool 234\n",
            "Iteration 42: Current Loss = 0.8303, Min Loss = 0.8302 with pool 232\n",
            "Iteration 43: Current Loss = 0.8322, Min Loss = 0.8302 with pool 203\n",
            "Iteration 44: Current Loss = 0.8306, Min Loss = 0.8302 with pool 202\n",
            "Iteration 44: Current Loss = 0.8306, Min Loss = 0.8302\n",
            "Active learning stopped after 43 iterations.\n",
            "Processing Fold 3/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.1824, Min Loss = inf with pool 691\n",
            "Iteration 2: Current Loss = 1.1692, Min Loss = 1.1824 with pool 662\n",
            "Iteration 3: Current Loss = 1.1524, Min Loss = 1.1692 with pool 633\n",
            "Iteration 4: Current Loss = 1.1348, Min Loss = 1.1524 with pool 604\n",
            "Iteration 5: Current Loss = 1.1151, Min Loss = 1.1348 with pool 575\n",
            "Iteration 6: Current Loss = 1.0937, Min Loss = 1.1151 with pool 546\n",
            "Iteration 7: Current Loss = 0.9644, Min Loss = 1.0937 with pool 517\n",
            "Iteration 8: Current Loss = 0.9251, Min Loss = 0.9644 with pool 488\n",
            "Iteration 9: Current Loss = 0.9160, Min Loss = 0.9251 with pool 480\n",
            "Iteration 10: Current Loss = 0.9153, Min Loss = 0.9160 with pool 471\n",
            "Iteration 11: Current Loss = 0.9145, Min Loss = 0.9153 with pool 442\n",
            "Iteration 12: Current Loss = 0.9138, Min Loss = 0.9145 with pool 413\n",
            "Iteration 13: Current Loss = 0.9131, Min Loss = 0.9138 with pool 412\n",
            "Iteration 14: Current Loss = 0.9125, Min Loss = 0.9131 with pool 411\n",
            "Iteration 15: Current Loss = 0.9119, Min Loss = 0.9125 with pool 382\n",
            "Iteration 16: Current Loss = 0.9115, Min Loss = 0.9119 with pool 353\n",
            "Iteration 17: Current Loss = 0.9105, Min Loss = 0.9115 with pool 324\n",
            "Iteration 18: Current Loss = 0.9101, Min Loss = 0.9105 with pool 323\n",
            "Iteration 19: Current Loss = 0.9098, Min Loss = 0.9101 with pool 322\n",
            "Iteration 20: Current Loss = 0.9096, Min Loss = 0.9098 with pool 319\n",
            "Iteration 21: Current Loss = 0.9093, Min Loss = 0.9096 with pool 317\n",
            "Iteration 22: Current Loss = 0.9092, Min Loss = 0.9093 with pool 316\n",
            "Iteration 23: Current Loss = 0.9086, Min Loss = 0.9092 with pool 287\n",
            "Iteration 24: Current Loss = 0.9079, Min Loss = 0.9086 with pool 258\n",
            "Iteration 25: Current Loss = 0.9073, Min Loss = 0.9079 with pool 229\n",
            "Iteration 26: Current Loss = 0.9068, Min Loss = 0.9073 with pool 228\n",
            "Iteration 27: Current Loss = 0.9063, Min Loss = 0.9068 with pool 227\n",
            "Iteration 28: Current Loss = 0.9061, Min Loss = 0.9063 with pool 198\n",
            "Iteration 29: Current Loss = 0.9076, Min Loss = 0.9061 with pool 169\n",
            "Iteration 30: Current Loss = 0.9071, Min Loss = 0.9061 with pool 167\n",
            "Iteration 31: Current Loss = 0.9064, Min Loss = 0.9061 with pool 138\n",
            "Iteration 32: Current Loss = 0.9060, Min Loss = 0.9061 with pool 137\n",
            "Iteration 33: Current Loss = 0.9061, Min Loss = 0.9060 with pool 136\n",
            "Iteration 34: Current Loss = 0.9055, Min Loss = 0.9060 with pool 135\n",
            "Iteration 35: Current Loss = 0.9051, Min Loss = 0.9055 with pool 134\n",
            "Iteration 36: Current Loss = 0.9053, Min Loss = 0.9051 with pool 105\n",
            "Iteration 37: Current Loss = 0.9051, Min Loss = 0.9051 with pool 76\n",
            "Iteration 38: Current Loss = 0.9036, Min Loss = 0.9051 with pool 47\n",
            "Iteration 39: Current Loss = 0.8974, Min Loss = 0.9036 with pool 18\n",
            "Active learning stopped after 39 iterations.\n",
            "Processing Fold 4/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 1.0002, Min Loss = inf with pool 691\n",
            "Iteration 2: Current Loss = 0.9942, Min Loss = 1.0002 with pool 662\n",
            "Iteration 3: Current Loss = 0.9406, Min Loss = 0.9942 with pool 633\n",
            "Iteration 4: Current Loss = 0.9148, Min Loss = 0.9406 with pool 604\n",
            "Iteration 5: Current Loss = 0.9131, Min Loss = 0.9148 with pool 588\n",
            "Iteration 6: Current Loss = 0.9115, Min Loss = 0.9131 with pool 559\n",
            "Iteration 7: Current Loss = 0.9094, Min Loss = 0.9115 with pool 558\n",
            "Iteration 8: Current Loss = 0.9077, Min Loss = 0.9094 with pool 529\n",
            "Iteration 9: Current Loss = 0.9058, Min Loss = 0.9077 with pool 500\n",
            "Iteration 10: Current Loss = 0.9042, Min Loss = 0.9058 with pool 471\n",
            "Iteration 11: Current Loss = 0.9028, Min Loss = 0.9042 with pool 469\n",
            "Iteration 12: Current Loss = 0.9022, Min Loss = 0.9028 with pool 440\n",
            "Iteration 13: Current Loss = 0.9014, Min Loss = 0.9022 with pool 439\n",
            "Iteration 14: Current Loss = 0.9003, Min Loss = 0.9014 with pool 437\n",
            "Iteration 15: Current Loss = 0.8988, Min Loss = 0.9003 with pool 436\n",
            "Iteration 16: Current Loss = 0.8979, Min Loss = 0.8988 with pool 435\n",
            "Iteration 17: Current Loss = 0.8971, Min Loss = 0.8979 with pool 406\n",
            "Iteration 18: Current Loss = 0.8971, Min Loss = 0.8971 with pool 405\n",
            "Iteration 19: Current Loss = 0.8966, Min Loss = 0.8971 with pool 376\n",
            "Iteration 20: Current Loss = 0.8960, Min Loss = 0.8966 with pool 375\n",
            "Iteration 21: Current Loss = 0.8954, Min Loss = 0.8960 with pool 373\n",
            "Iteration 22: Current Loss = 0.8942, Min Loss = 0.8954 with pool 344\n",
            "Iteration 23: Current Loss = 0.8938, Min Loss = 0.8942 with pool 341\n",
            "Iteration 24: Current Loss = 0.8934, Min Loss = 0.8938 with pool 340\n",
            "Iteration 25: Current Loss = 0.8928, Min Loss = 0.8934 with pool 338\n",
            "Iteration 26: Current Loss = 0.8924, Min Loss = 0.8928 with pool 337\n",
            "Iteration 27: Current Loss = 0.8917, Min Loss = 0.8924 with pool 308\n",
            "Iteration 28: Current Loss = 0.8914, Min Loss = 0.8917 with pool 304\n",
            "Iteration 29: Current Loss = 0.8907, Min Loss = 0.8914 with pool 275\n",
            "Iteration 30: Current Loss = 0.8903, Min Loss = 0.8907 with pool 246\n",
            "Iteration 31: Current Loss = 0.8896, Min Loss = 0.8903 with pool 245\n",
            "Iteration 32: Current Loss = 0.8895, Min Loss = 0.8896 with pool 216\n",
            "Iteration 33: Current Loss = 0.8885, Min Loss = 0.8895 with pool 214\n",
            "Iteration 34: Current Loss = 0.8882, Min Loss = 0.8885 with pool 213\n",
            "Iteration 35: Current Loss = 0.8881, Min Loss = 0.8882 with pool 184\n",
            "Iteration 36: Current Loss = 0.8875, Min Loss = 0.8881 with pool 183\n",
            "Iteration 37: Current Loss = 0.8868, Min Loss = 0.8875 with pool 182\n",
            "Iteration 38: Current Loss = 0.8867, Min Loss = 0.8868 with pool 181\n",
            "Iteration 39: Current Loss = 0.8866, Min Loss = 0.8867 with pool 152\n",
            "Iteration 40: Current Loss = 0.8868, Min Loss = 0.8866 with pool 123\n",
            "Iteration 41: Current Loss = 0.8869, Min Loss = 0.8866 with pool 94\n",
            "Iteration 42: Current Loss = 0.8869, Min Loss = 0.8866 with pool 65\n",
            "Iteration 43: Current Loss = 0.8869, Min Loss = 0.8866 with pool 36\n",
            "Iteration 43: Current Loss = 0.8869, Min Loss = 0.8866\n",
            "Active learning stopped after 42 iterations.\n",
            "Processing Fold 5/5...\n",
            "(720, 40)\n",
            "Iteration 1: Current Loss = 0.9699, Min Loss = inf with pool 691\n",
            "Iteration 2: Current Loss = 0.9645, Min Loss = 0.9699 with pool 662\n",
            "Iteration 3: Current Loss = 0.9572, Min Loss = 0.9645 with pool 633\n",
            "Iteration 4: Current Loss = 0.9211, Min Loss = 0.9572 with pool 604\n",
            "Iteration 5: Current Loss = 0.9201, Min Loss = 0.9211 with pool 601\n",
            "Iteration 6: Current Loss = 0.9069, Min Loss = 0.9201 with pool 572\n",
            "Iteration 7: Current Loss = 0.9010, Min Loss = 0.9069 with pool 571\n",
            "Iteration 8: Current Loss = 0.9007, Min Loss = 0.9010 with pool 542\n",
            "Iteration 9: Current Loss = 0.9004, Min Loss = 0.9007 with pool 513\n",
            "Iteration 10: Current Loss = 0.9003, Min Loss = 0.9004 with pool 484\n",
            "Iteration 11: Current Loss = 0.9001, Min Loss = 0.9003 with pool 483\n",
            "Iteration 12: Current Loss = 0.9001, Min Loss = 0.9001 with pool 454\n",
            "Iteration 13: Current Loss = 0.9002, Min Loss = 0.9001 with pool 425\n",
            "Iteration 14: Current Loss = 0.9002, Min Loss = 0.9001 with pool 396\n",
            "Iteration 15: Current Loss = 0.9005, Min Loss = 0.9001 with pool 395\n",
            "Iteration 16: Current Loss = 0.8995, Min Loss = 0.9001 with pool 394\n",
            "Iteration 17: Current Loss = 0.9000, Min Loss = 0.8995 with pool 391\n",
            "Iteration 18: Current Loss = 0.9002, Min Loss = 0.8995 with pool 390\n",
            "Iteration 19: Current Loss = 0.9003, Min Loss = 0.8995 with pool 389\n",
            "Iteration 20: Current Loss = 0.9018, Min Loss = 0.8995 with pool 387\n",
            "Iteration 20: Current Loss = 0.9018, Min Loss = 0.8995\n",
            "Active learning stopped after 19 iterations.\n",
            "Average Loss: 0.8813\n",
            "Best number of nodes: 198\n",
            "Best number of queries: 33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Student Performance"
      ],
      "metadata": {
        "id": "JlJlAuNLxtE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Format"
      ],
      "metadata": {
        "id": "XlcTSlV-Dr06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5y7uMAFxy4a",
        "outputId": "3acb699a-4d3c-4853-9d79-a5377cf278f5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo"
      ],
      "metadata": {
        "id": "vg0ZCJd-yY9o"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fetch dataset\n",
        "student = fetch_ucirepo(id=320)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = student.data.features\n",
        "y = student.data.targets\n",
        "\n",
        "student_data = pd.concat([X, y], axis=1)\n",
        "\n",
        "# metadata\n",
        "print(student.metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35NmEPZ9yZ5m",
        "outputId": "56de0085-9ae6-4d1a-9455-fdde1347b5d8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 320, 'name': 'Student Performance', 'repository_url': 'https://archive.ics.uci.edu/dataset/320/student+performance', 'data_url': 'https://archive.ics.uci.edu/static/public/320/data.csv', 'abstract': 'Predict student performance in secondary education (high school). ', 'area': 'Social Science', 'tasks': ['Classification', 'Regression'], 'characteristics': ['Multivariate'], 'num_instances': 649, 'num_features': 30, 'feature_types': ['Integer'], 'demographics': ['Sex', 'Age', 'Other', 'Education Level', 'Occupation'], 'target_col': ['G1', 'G2', 'G3'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2008, 'last_updated': 'Fri Jan 05 2024', 'dataset_doi': '10.24432/C5TG7T', 'creators': ['Paulo Cortez'], 'intro_paper': {'ID': 360, 'type': 'NATIVE', 'title': 'Using data mining to predict secondary school student performance', 'authors': 'P. Cortez, A. M. G. Silva', 'venue': 'Proceedings of 5th Annual Future Business Technology Conference', 'year': 2008, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/61d468d5254730bbecf822c6b60d7d6595d9889c', 'sha': None, 'corpus': '16621299', 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This data approach student achievement in secondary education of two Portuguese schools. The data attributes include student grades, demographic, social and school related features) and it was collected by using school reports and questionnaires. Two datasets are provided regarding the performance in two distinct subjects: Mathematics (mat) and Portuguese language (por). In [Cortez and Silva, 2008], the two datasets were modeled under binary/five-level classification and regression tasks. Important note: the target attribute G3 has a strong correlation with attributes G2 and G1. This occurs because G3 is the final year grade (issued at the 3rd period), while G1 and G2 correspond to the 1st and 2nd period grades. It is more difficult to predict G3 without G2 and G1, but such prediction is much more useful (see paper source for more details).', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"# Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:\\r\\n1 school - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\\r\\n2 sex - student's sex (binary: 'F' - female or 'M' - male)\\r\\n3 age - student's age (numeric: from 15 to 22)\\r\\n4 address - student's home address type (binary: 'U' - urban or 'R' - rural)\\r\\n5 famsize - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\\r\\n6 Pstatus - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\\r\\n7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2  5th to 9th grade, 3  secondary education or 4  higher education)\\r\\n8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2  5th to 9th grade, 3  secondary education or 4  higher education)\\r\\n9 Mjob - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\\r\\n10 Fjob - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\\r\\n11 reason - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\\r\\n12 guardian - student's guardian (nominal: 'mother', 'father' or 'other')\\r\\n13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\\r\\n14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\\r\\n15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)\\r\\n16 schoolsup - extra educational support (binary: yes or no)\\r\\n17 famsup - family educational support (binary: yes or no)\\r\\n18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\\r\\n19 activities - extra-curricular activities (binary: yes or no)\\r\\n20 nursery - attended nursery school (binary: yes or no)\\r\\n21 higher - wants to take higher education (binary: yes or no)\\r\\n22 internet - Internet access at home (binary: yes or no)\\r\\n23 romantic - with a romantic relationship (binary: yes or no)\\r\\n24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\\r\\n25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)\\r\\n26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)\\r\\n27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\\r\\n28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\\r\\n29 health - current health status (numeric: from 1 - very bad to 5 - very good)\\r\\n30 absences - number of school absences (numeric: from 0 to 93)\\r\\n\\r\\n# these grades are related with the course subject, Math or Portuguese:\\r\\n31 G1 - first period grade (numeric: from 0 to 20)\\r\\n31 G2 - second period grade (numeric: from 0 to 20)\\r\\n32 G3 - final grade (numeric: from 0 to 20, output target)\", 'citation': None}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# variable information\n",
        "print(student.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNxTkVRi1b8a",
        "outputId": "037318e4-9d4e-4185-e32a-6f1afceea7c3"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          name     role         type      demographic  \\\n",
            "0       school  Feature  Categorical             None   \n",
            "1          sex  Feature       Binary              Sex   \n",
            "2          age  Feature      Integer              Age   \n",
            "3      address  Feature  Categorical             None   \n",
            "4      famsize  Feature  Categorical            Other   \n",
            "5      Pstatus  Feature  Categorical            Other   \n",
            "6         Medu  Feature      Integer  Education Level   \n",
            "7         Fedu  Feature      Integer  Education Level   \n",
            "8         Mjob  Feature  Categorical       Occupation   \n",
            "9         Fjob  Feature  Categorical       Occupation   \n",
            "10      reason  Feature  Categorical             None   \n",
            "11    guardian  Feature  Categorical             None   \n",
            "12  traveltime  Feature      Integer             None   \n",
            "13   studytime  Feature      Integer             None   \n",
            "14    failures  Feature      Integer             None   \n",
            "15   schoolsup  Feature       Binary             None   \n",
            "16      famsup  Feature       Binary             None   \n",
            "17        paid  Feature       Binary             None   \n",
            "18  activities  Feature       Binary             None   \n",
            "19     nursery  Feature       Binary             None   \n",
            "20      higher  Feature       Binary             None   \n",
            "21    internet  Feature       Binary             None   \n",
            "22    romantic  Feature       Binary             None   \n",
            "23      famrel  Feature      Integer             None   \n",
            "24    freetime  Feature      Integer             None   \n",
            "25       goout  Feature      Integer             None   \n",
            "26        Dalc  Feature      Integer             None   \n",
            "27        Walc  Feature      Integer             None   \n",
            "28      health  Feature      Integer             None   \n",
            "29    absences  Feature      Integer             None   \n",
            "30          G1   Target  Categorical             None   \n",
            "31          G2   Target  Categorical             None   \n",
            "32          G3   Target      Integer             None   \n",
            "\n",
            "                                          description units missing_values  \n",
            "0   student's school (binary: 'GP' - Gabriel Perei...  None             no  \n",
            "1   student's sex (binary: 'F' - female or 'M' - m...  None             no  \n",
            "2              student's age (numeric: from 15 to 22)  None             no  \n",
            "3   student's home address type (binary: 'U' - urb...  None             no  \n",
            "4   family size (binary: 'LE3' - less or equal to ...  None             no  \n",
            "5   parent's cohabitation status (binary: 'T' - li...  None             no  \n",
            "6   mother's education (numeric: 0 - none,  1 - pr...  None             no  \n",
            "7   father's education (numeric: 0 - none,  1 - pr...  None             no  \n",
            "8   mother's job (nominal: 'teacher', 'health' car...  None             no  \n",
            "9   father's job (nominal: 'teacher', 'health' car...  None             no  \n",
            "10  reason to choose this school (nominal: close t...  None             no  \n",
            "11  student's guardian (nominal: 'mother', 'father...  None             no  \n",
            "12  home to school travel time (numeric: 1 - <15 m...  None             no  \n",
            "13  weekly study time (numeric: 1 - <2 hours, 2 - ...  None             no  \n",
            "14  number of past class failures (numeric: n if 1...  None             no  \n",
            "15      extra educational support (binary: yes or no)  None             no  \n",
            "16     family educational support (binary: yes or no)  None             no  \n",
            "17  extra paid classes within the course subject (...  None             no  \n",
            "18    extra-curricular activities (binary: yes or no)  None             no  \n",
            "19        attended nursery school (binary: yes or no)  None             no  \n",
            "20  wants to take higher education (binary: yes or...  None             no  \n",
            "21        Internet access at home (binary: yes or no)  None             no  \n",
            "22   with a romantic relationship (binary: yes or no)  None             no  \n",
            "23  quality of family relationships (numeric: from...  None             no  \n",
            "24  free time after school (numeric: from 1 - very...  None             no  \n",
            "25  going out with friends (numeric: from 1 - very...  None             no  \n",
            "26  workday alcohol consumption (numeric: from 1 -...  None             no  \n",
            "27  weekend alcohol consumption (numeric: from 1 -...  None             no  \n",
            "28  current health status (numeric: from 1 - very ...  None             no  \n",
            "29  number of school absences (numeric: from 0 to 93)  None             no  \n",
            "30         first period grade (numeric: from 0 to 20)  None             no  \n",
            "31        second period grade (numeric: from 0 to 20)  None             no  \n",
            "32  final grade (numeric: from 0 to 20, output tar...  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sum(student_data.duplicated()))\n",
        "print(student_data.shape)\n",
        "student_data.head().T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Ja8zq921eqM",
        "outputId": "33b97e45-830a-482c-8ea1-8093f1314af6"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(649, 33)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  0        1        2         3       4\n",
              "school           GP       GP       GP        GP      GP\n",
              "sex               F        F        F         F       F\n",
              "age              18       17       15        15      16\n",
              "address           U        U        U         U       U\n",
              "famsize         GT3      GT3      LE3       GT3     GT3\n",
              "Pstatus           A        T        T         T       T\n",
              "Medu              4        1        1         4       3\n",
              "Fedu              4        1        1         2       3\n",
              "Mjob        at_home  at_home  at_home    health   other\n",
              "Fjob        teacher    other    other  services   other\n",
              "reason       course   course    other      home    home\n",
              "guardian     mother   father   mother    mother  father\n",
              "traveltime        2        1        1         1       1\n",
              "studytime         2        2        2         3       2\n",
              "failures          0        0        0         0       0\n",
              "schoolsup       yes       no      yes        no      no\n",
              "famsup           no      yes       no       yes     yes\n",
              "paid             no       no       no        no      no\n",
              "activities       no       no       no       yes      no\n",
              "nursery         yes       no      yes       yes     yes\n",
              "higher          yes      yes      yes       yes     yes\n",
              "internet         no      yes      yes       yes      no\n",
              "romantic         no       no       no       yes      no\n",
              "famrel            4        5        4         3       4\n",
              "freetime          3        3        3         2       3\n",
              "goout             4        3        2         2       2\n",
              "Dalc              1        1        2         1       1\n",
              "Walc              1        1        3         1       2\n",
              "health            3        3        3         5       5\n",
              "absences          4        2        6         0       0\n",
              "G1                0        9       12        14      11\n",
              "G2               11       11       13        14      13\n",
              "G3               11       11       12        14      13"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-95f4a382-4d65-49e5-8557-559e37b50bc0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>school</th>\n",
              "      <td>GP</td>\n",
              "      <td>GP</td>\n",
              "      <td>GP</td>\n",
              "      <td>GP</td>\n",
              "      <td>GP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>18</td>\n",
              "      <td>17</td>\n",
              "      <td>15</td>\n",
              "      <td>15</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>address</th>\n",
              "      <td>U</td>\n",
              "      <td>U</td>\n",
              "      <td>U</td>\n",
              "      <td>U</td>\n",
              "      <td>U</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>famsize</th>\n",
              "      <td>GT3</td>\n",
              "      <td>GT3</td>\n",
              "      <td>LE3</td>\n",
              "      <td>GT3</td>\n",
              "      <td>GT3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Pstatus</th>\n",
              "      <td>A</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Medu</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fedu</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mjob</th>\n",
              "      <td>at_home</td>\n",
              "      <td>at_home</td>\n",
              "      <td>at_home</td>\n",
              "      <td>health</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fjob</th>\n",
              "      <td>teacher</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>services</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reason</th>\n",
              "      <td>course</td>\n",
              "      <td>course</td>\n",
              "      <td>other</td>\n",
              "      <td>home</td>\n",
              "      <td>home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>guardian</th>\n",
              "      <td>mother</td>\n",
              "      <td>father</td>\n",
              "      <td>mother</td>\n",
              "      <td>mother</td>\n",
              "      <td>father</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traveltime</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>studytime</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>failures</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>schoolsup</th>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>famsup</th>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>paid</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>activities</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nursery</th>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>higher</th>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>internet</th>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>romantic</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>famrel</th>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freetime</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>goout</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Dalc</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Walc</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>health</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>absences</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G1</th>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G2</th>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G3</th>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95f4a382-4d65-49e5-8557-559e37b50bc0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-95f4a382-4d65-49e5-8557-559e37b50bc0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-95f4a382-4d65-49e5-8557-559e37b50bc0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eaaa96ef-fe20-4eb1-87ff-778f036c4baa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eaaa96ef-fe20-4eb1-87ff-778f036c4baa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eaaa96ef-fe20-4eb1-87ff-778f036c4baa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "student_data"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigating data types of categorical\n",
        "\n",
        "print(student_data['school'].value_counts())\n",
        "print(student_data['sex'].value_counts())\n",
        "print(student_data['address'].value_counts())\n",
        "print(student_data['famsize'].value_counts())\n",
        "print(student_data['Pstatus'].value_counts())\n",
        "print(student_data['sex'].value_counts())\n",
        "print(student_data['Mjob'].value_counts())\n",
        "print(student_data['Fjob'].value_counts())\n",
        "print(student_data['reason'].value_counts())\n",
        "print(student_data['guardian'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGTIRZtB37Pg",
        "outputId": "9120a254-654b-4d14-ccfc-938e77de42a4"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "school\n",
            "GP    423\n",
            "MS    226\n",
            "Name: count, dtype: int64\n",
            "sex\n",
            "F    383\n",
            "M    266\n",
            "Name: count, dtype: int64\n",
            "address\n",
            "U    452\n",
            "R    197\n",
            "Name: count, dtype: int64\n",
            "famsize\n",
            "GT3    457\n",
            "LE3    192\n",
            "Name: count, dtype: int64\n",
            "Pstatus\n",
            "T    569\n",
            "A     80\n",
            "Name: count, dtype: int64\n",
            "sex\n",
            "F    383\n",
            "M    266\n",
            "Name: count, dtype: int64\n",
            "Mjob\n",
            "other       258\n",
            "services    136\n",
            "at_home     135\n",
            "teacher      72\n",
            "health       48\n",
            "Name: count, dtype: int64\n",
            "Fjob\n",
            "other       367\n",
            "services    181\n",
            "at_home      42\n",
            "teacher      36\n",
            "health       23\n",
            "Name: count, dtype: int64\n",
            "reason\n",
            "course        285\n",
            "home          149\n",
            "reputation    143\n",
            "other          72\n",
            "Name: count, dtype: int64\n",
            "guardian\n",
            "mother    455\n",
            "father    153\n",
            "other      41\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assume the data is loaded into the DataFrame student_data\n",
        "# Categorical columns to one-hot encode\n",
        "categorical_columns = ['sex', 'school', 'address', 'famsize', 'Pstatus', 'Mjob', 'Fjob', 'reason', 'guardian']\n",
        "\n",
        "# One-hot encoding the categorical variables\n",
        "student_data_encoded = pd.get_dummies(student_data, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# List of binary columns (yes/no variables)\n",
        "binary_columns = ['schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic']\n",
        "\n",
        "# Map 'yes' to 1 and 'no' to 0 in the binary columns\n",
        "for col in binary_columns:\n",
        "    student_data_encoded[col] = student_data_encoded[col].map({'yes': 1, 'no': 0})\n",
        "\n",
        "student_data_encoded = student_data_encoded.astype(int)\n",
        "\n",
        "# Check the transformed dataset\n",
        "print(student_data_encoded.head().T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZ_cMDLi3kqZ",
        "outputId": "87df78e1-ce68-4803-fac6-e9c07f7b3e00"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    0   1   2   3   4\n",
            "age                18  17  15  15  16\n",
            "Medu                4   1   1   4   3\n",
            "Fedu                4   1   1   2   3\n",
            "traveltime          2   1   1   1   1\n",
            "studytime           2   2   2   3   2\n",
            "failures            0   0   0   0   0\n",
            "schoolsup           1   0   1   0   0\n",
            "famsup              0   1   0   1   1\n",
            "paid                0   0   0   0   0\n",
            "activities          0   0   0   1   0\n",
            "nursery             1   0   1   1   1\n",
            "higher              1   1   1   1   1\n",
            "internet            0   1   1   1   0\n",
            "romantic            0   0   0   1   0\n",
            "famrel              4   5   4   3   4\n",
            "freetime            3   3   3   2   3\n",
            "goout               4   3   2   2   2\n",
            "Dalc                1   1   2   1   1\n",
            "Walc                1   1   3   1   2\n",
            "health              3   3   3   5   5\n",
            "absences            4   2   6   0   0\n",
            "G1                  0   9  12  14  11\n",
            "G2                 11  11  13  14  13\n",
            "G3                 11  11  12  14  13\n",
            "sex_M               0   0   0   0   0\n",
            "school_MS           0   0   0   0   0\n",
            "address_U           1   1   1   1   1\n",
            "famsize_LE3         0   0   1   0   0\n",
            "Pstatus_T           0   1   1   1   1\n",
            "Mjob_health         0   0   0   1   0\n",
            "Mjob_other          0   0   0   0   1\n",
            "Mjob_services       0   0   0   0   0\n",
            "Mjob_teacher        0   0   0   0   0\n",
            "Fjob_health         0   0   0   0   0\n",
            "Fjob_other          0   1   1   0   1\n",
            "Fjob_services       0   0   0   1   0\n",
            "Fjob_teacher        1   0   0   0   0\n",
            "reason_home         0   0   0   1   1\n",
            "reason_other        0   0   1   0   0\n",
            "reason_reputation   0   0   0   0   0\n",
            "guardian_mother     1   0   1   1   0\n",
            "guardian_other      0   0   0   0   0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(student_data_encoded.shape)\n",
        "student_X = student_data_encoded.drop(['G1', 'G2', 'G3'], axis=1)\n",
        "student_y = student_data_encoded['G1']"
      ],
      "metadata": {
        "id": "fajUISV17vN3",
        "outputId": "2a924e9a-08ce-4456-db6b-a7d5ac5648bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(649, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "T48DJ4h_YMih",
        "outputId": "ea648236-1a04-43bd-eb6b-6f49b3b987b7"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "G1\n",
              "10    95\n",
              "11    91\n",
              "12    82\n",
              "13    72\n",
              "14    71\n",
              "9     65\n",
              "8     42\n",
              "15    35\n",
              "7     33\n",
              "16    22\n",
              "17    16\n",
              "6      9\n",
              "18     7\n",
              "5      5\n",
              "4      2\n",
              "0      1\n",
              "19     1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G1</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_y = [max(0, y - 3) for y in student_y]"
      ],
      "metadata": {
        "id": "N3HXNZPMYt5c"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(student_y).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "gx0RL2-hZB37",
        "outputId": "b1dc6403-a2f1-4471-c77a-83516a77a291"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7     95\n",
              "8     91\n",
              "9     82\n",
              "10    72\n",
              "11    71\n",
              "6     65\n",
              "5     42\n",
              "12    35\n",
              "4     33\n",
              "13    22\n",
              "14    16\n",
              "3      9\n",
              "15     7\n",
              "2      5\n",
              "1      2\n",
              "0      1\n",
              "16     1\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_X = np.array(student_X)\n",
        "student_y = np.array(student_y)"
      ],
      "metadata": {
        "id": "S49wZ4DmYGJ2"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(student_X.shape)\n",
        "print(student_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QM1N8LbZT3I",
        "outputId": "9ff33742-ade9-449d-e78b-4e3e6d67162f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(649, 39)\n",
            "(649,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test"
      ],
      "metadata": {
        "id": "Sjb4YlPADu3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer\n",
        "from functools import partial\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 64, name='nodes'),    # Number of nodes in the hidden layer\n",
        "    Integer(5, 50, name='n_queries')   # Number of queries in active learning\n",
        "]\n",
        "\n",
        "def objective(params):\n",
        "    query_strategy = conflicting_evidence_strategy_clf\n",
        "    nodes, n_queries = params  # Unpack the hyperparameters (nodes, n_queries)\n",
        "    return main(query_strategy, X = student_X, y = student_y, task = \"multi_clf\", nodes=nodes, n_queries=n_queries, init_size = 0.1)\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")\n",
        "print(f\"Best number of queries: {result.x[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "AemFkBH_Cflx",
        "outputId": "2a3cb026-24d2-4c2a-ed95-60f4eeb55f68"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New training with nodes 52 and n_queries 13\n",
            "Processing Fold 1/5...\n",
            "Iteration 1: Current Loss = 1.6423, Min Loss = inf with pool 455\n",
            "Iteration 2: Current Loss = 1.5994, Min Loss = 1.6423 with pool 442\n",
            "Iteration 3: Current Loss = 1.5318, Min Loss = 1.5994 with pool 429\n",
            "Iteration 4: Current Loss = 1.4650, Min Loss = 1.5318 with pool 416\n",
            "Iteration 5: Current Loss = 1.4024, Min Loss = 1.4650 with pool 403\n",
            "Iteration 6: Current Loss = 1.3263, Min Loss = 1.4024 with pool 390\n",
            "Iteration 7: Current Loss = 1.2628, Min Loss = 1.3263 with pool 377\n",
            "Iteration 8: Current Loss = 1.0349, Min Loss = 1.2628 with pool 364\n",
            "Iteration 9: Current Loss = 1.0140, Min Loss = 1.0349 with pool 351\n",
            "Iteration 10: Current Loss = 1.0102, Min Loss = 1.0140 with pool 338\n",
            "Iteration 11: Current Loss = 1.0089, Min Loss = 1.0102 with pool 327\n",
            "Iteration 12: Current Loss = 1.0090, Min Loss = 1.0089 with pool 325\n",
            "Iteration 13: Current Loss = 1.0074, Min Loss = 1.0089 with pool 312\n",
            "Iteration 14: Current Loss = 1.0072, Min Loss = 1.0074 with pool 299\n",
            "Iteration 15: Current Loss = 1.0069, Min Loss = 1.0072 with pool 286\n",
            "Iteration 16: Current Loss = 1.0063, Min Loss = 1.0069 with pool 273\n",
            "Iteration 17: Current Loss = 1.0058, Min Loss = 1.0063 with pool 260\n",
            "Iteration 18: Current Loss = 1.0054, Min Loss = 1.0058 with pool 247\n",
            "Iteration 19: Current Loss = 1.0051, Min Loss = 1.0054 with pool 234\n",
            "Iteration 20: Current Loss = 1.0050, Min Loss = 1.0051 with pool 221\n",
            "Iteration 21: Current Loss = 1.0051, Min Loss = 1.0050 with pool 208\n",
            "Iteration 22: Current Loss = 1.0052, Min Loss = 1.0050 with pool 195\n",
            "Iteration 23: Current Loss = 1.0051, Min Loss = 1.0050 with pool 182\n",
            "Iteration 24: Current Loss = 1.0053, Min Loss = 1.0050 with pool 169\n",
            "Iteration 24: Current Loss = 1.0053, Min Loss = 1.0050\n",
            "Active learning stopped after 23 iterations with loss 1.0050.\n",
            "Processing Fold 2/5...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-9244308e00c9>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m result = gp_minimize(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# Objective function to minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# Hyperparameter space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-108-9244308e00c9>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mquery_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconflicting_evidence_strategy_clf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m  \u001b[0;31m# Unpack the hyperparameters (nodes, n_queries)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multi_clf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-398dce882751>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(query_strategy, X, y, task, nodes, n_queries, stability_threshold, n_folds, init_size, beta)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# Create the active learner with the provided query strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mlearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_active_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_strategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Run the active learning loop with custom stop set criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-ccf9ffff1f06>\u001b[0m in \u001b[0;36mcreate_active_learner\u001b[0;34m(X_train, y_train, keras_model, query_strategy)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Initialize the ActiveLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     learner = ActiveLearner(\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mX_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, query_strategy, X_training, y_training, bootstrap_init, on_transformed, **fit_kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_to_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodALinput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodALinput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36m_fit_to_known\u001b[0;34m(self, bootstrap, **fit_kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mn_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         self._fit(\n\u001b[0m\u001b[1;32m    771\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         self._fit_keras_model(\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;31m# Create an iterator that yields batches for one epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         epoch_iterator = TFEpochIterator(\n\u001b[0m\u001b[1;32m    283\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, distribute_strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribute_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             dataset = self._distribute_strategy.experimental_distribute_dataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m_get_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mget_tf_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/array_data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrab_one\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             dataset = dataset.map(\n\u001b[0m\u001b[1;32m    216\u001b[0m                 \u001b[0mgrab_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2309\u001b[0m     \u001b[0;31m# pylint: disable=g-import-not-at-top,protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2310\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmap_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2311\u001b[0;31m     return map_op._map_v2(\n\u001b[0m\u001b[1;32m   2312\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2313\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     38\u001b[0m         input_dataset, map_func, preserve_cardinality=True, name=name)\n\u001b[1;32m     39\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     return _ParallelMapDataset(\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1249\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m     \u001b[0;31m# Implements PolymorphicFunction.get_concrete_function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mconcrete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_concrete_function_garbage_collected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m     \u001b[0mconcrete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1219\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1220\u001b[0m         \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_uninitialized_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;31m# Note: wrapper_helper will apply autograph based on context.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/variable_utils.py\u001b[0m in \u001b[0;36mconvert_variables_to_tensors\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_resource_variable_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m   \"\"\"\n\u001b[0;32m--> 628\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    629\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1063\u001b[0m   \"\"\"\n\u001b[1;32m   1064\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m   \u001b[0mentries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m   return _tf_core_pack_sequence_as(\n\u001b[0m\u001b[1;32m   1104\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m     final_index, packed = _tf_core_packed_nest_with_indices(\n\u001b[0m\u001b[1;32m    904\u001b[0m         \u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_nested_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequence_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_packed_nest_with_indices\u001b[0;34m(structure, flat, index, is_nested_fn, sequence_fn)\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m   \u001b[0msequence_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msequence_fn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msequence_like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_tf_core_yield_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_nested_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m       new_index, child = _tf_core_packed_nest_with_indices(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_yield_value\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_tf_core_yield_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_tf_core_yield_sorted_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_yield_sorted_items\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    338\u001b[0m   \"\"\"\n\u001b[1;32m    339\u001b[0m   \u001b[0;31m# Ordered to check common structure types (list, tuple, dict) first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       \u001b[0;32myield\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer, Real\n",
        "from functools import partial\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=40, n_informative=30, n_redundant=10, n_classes=2, random_state=42)\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 64, name='nodes'),    # Number of nodes in the hidden layer\n",
        "    Real(0.3, 0.9, name='beta')   # Number of queries in active learning\n",
        "]\n",
        "\n",
        "def objective(params):\n",
        "    nodes, beta = params  # Unpack the hyperparameters (nodes, n_queries)\n",
        "    query_strategy = sensitivity_strategy\n",
        "    return main(query_strategy, X = student_X, y = student_y, task = \"multi_clf\", nodes=nodes, beta = beta)\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")\n",
        "print(f\"Best value for beta: {result.x[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "FTTNEUAqzSes",
        "outputId": "efb7b96f-1563-4135-bb96-cd1da7e7b470"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New training with nodes 52 and beta 0.4100608739196983\n",
            "Processing Fold 1/5...\n",
            "Iteration 1: Current Loss = 2.5997, Min Loss = inf with pool 273\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/modAL/models/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, X_pool, return_metrics, *query_args, **query_kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             query_result, query_metrics = self.query_strategy(\n\u001b[0m\u001b[1;32m    176\u001b[0m                 self, X_pool, *query_args, **query_kwargs)\n",
            "\u001b[0;32m<ipython-input-85-a17e8552a247>\u001b[0m in \u001b[0;36msensitivity_strategy\u001b[0;34m(learner, X_pool, task, beta, n_instances)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Step 2: For each pattern in the pool (X_pool)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mS_oz_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_sensitivity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Shape is input by output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-c17ba4ae5de0>\u001b[0m in \u001b[0;36mcompute_sensitivity_matrix\u001b[0;34m(X_pool, learner)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# Summation over hidden units j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0msummation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_hidden_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mV_input_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_hidden_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mS_p_oz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mo_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msummation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-c17ba4ae5de0>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# Summation over hidden units j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0msummation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_hidden_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mV_input_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_hidden_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mS_p_oz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mo_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msummation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-109-e687f5f101e9>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m result = gp_minimize(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# Objective function to minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# Hyperparameter space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-e687f5f101e9>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m  \u001b[0;31m# Unpack the hyperparameters (nodes, n_queries)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mquery_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensitivity_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multi_clf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-71-398dce882751>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(query_strategy, X, y, task, nodes, n_queries, stability_threshold, n_folds, init_size, beta)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;31m# Run the active learning loop with custom stop set criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_learning_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_stop_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstability_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstability_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Save the trained learner (model) for this fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-104-e84292a33df8>\u001b[0m in \u001b[0;36mactive_learning_loop\u001b[0;34m(learner, X_pool, y_pool, X_stop_set, y_stop, X_sample, y_sample, task, n_queries, stability_threshold, max_iterations, beta)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Need to query with the full dataset which is in sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mquery_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_instance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_instances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Manual of the teach function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/modAL/models/base.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, X_pool, return_metrics, *query_args, **query_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mquery_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m             query_result = self.query_strategy(\n\u001b[0m\u001b[1;32m    181\u001b[0m                 self, X_pool, *query_args, **query_kwargs)\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-85-a17e8552a247>\u001b[0m in \u001b[0;36msensitivity_strategy\u001b[0;34m(learner, X_pool, task, beta, n_instances)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Step 2: For each pattern in the pool (X_pool)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mS_oz_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_sensitivity_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Shape is input by output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-c17ba4ae5de0>\u001b[0m in \u001b[0;36mcompute_sensitivity_matrix\u001b[0;34m(X_pool, learner)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# input units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# Summation over hidden units j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0msummation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_hidden_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mV_input_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_hidden_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mS_p_oz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mo_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msummation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msensitivity_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_p_oz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-76-c17ba4ae5de0>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# input units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# Summation over hidden units j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0msummation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_hidden_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mV_input_hidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW_hidden_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mS_p_oz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mo_p\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msummation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0msensitivity_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_p_oz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer, Real\n",
        "from functools import partial\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 64, name='nodes'),    # Number of nodes in the hidden layer\n",
        "]\n",
        "\n",
        "def objective(nodes):\n",
        "    return train_passive_binary(X = student_X, y = student_y, task = \"multi\", nodes=nodes[0])\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drxh7pJ3hDTt",
        "outputId": "88c3e586-82f1-43c7-d53b-f14b9530ed6a"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.4520\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.5517\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.4468\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.4925\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.4833\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.5526\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.4880\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.4935\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.5477\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 2.4921\n",
            "Best number of nodes: 51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Health and Nutrition Survey"
      ],
      "metadata": {
        "id": "CDapVzfa01hG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "national_health_and_nutrition_health_survey_2013_2014_nhanes_age_prediction_subset = fetch_ucirepo(id=887)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = national_health_and_nutrition_health_survey_2013_2014_nhanes_age_prediction_subset.data.features\n",
        "y = national_health_and_nutrition_health_survey_2013_2014_nhanes_age_prediction_subset.data.targets\n",
        "\n",
        "# metadata\n",
        "print(national_health_and_nutrition_health_survey_2013_2014_nhanes_age_prediction_subset.metadata)\n",
        "\n",
        "# variable information\n",
        "print(national_health_and_nutrition_health_survey_2013_2014_nhanes_age_prediction_subset.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDS948Tzx2lS",
        "outputId": "66200ab3-b8e0-45dd-912b-d3fe2095248a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 887, 'name': 'National Health and Nutrition Health Survey 2013-2014 (NHANES) Age Prediction Subset', 'repository_url': 'https://archive.ics.uci.edu/dataset/887/national+health+and+nutrition+health+survey+2013-2014+(nhanes)+age+prediction+subset', 'data_url': 'https://archive.ics.uci.edu/static/public/887/data.csv', 'abstract': \"The National Health and Nutrition Examination Survey (NHANES), administered by the Centers for Disease Control and Prevention (CDC), collects extensive health and nutritional information from a diverse U.S. population. Though expansive, the dataset is often too broad for specific analytical purposes. In this sub-dataset, we narrow our focus to predicting respondents' age by extracting a subset of features from the larger NHANES dataset. These selected features include physiological measurements, lifestyle choices, and biochemical markers, which were hypothesized to have strong correlations with age.\", 'area': 'Health and Medicine', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 6287, 'num_features': 7, 'feature_types': ['Real', 'Categorical', 'Integer'], 'demographics': ['Age', 'Gender'], 'target_col': ['age_group'], 'index_col': ['SEQN'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2019, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5BS66', 'creators': ['NA NA'], 'intro_paper': {'ID': 304, 'type': 'NATIVE', 'title': 'A data-driven approach to predicting diabetes and cardiovascular disease with machine learning', 'authors': 'An Dinh, Stacey Miertschin, Amber Young, S. Mohanty', 'venue': 'BMC Medical Informatics and Decision Making', 'year': 2019, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/01af1548ff1f3661d8bb813e8c35ee219a79ca9f', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'The original full dataset can be found at:\\n\\nhttps://wwwn.cdc.gov/nchs/nhanes/search/DataPage.aspx?Component=Questionnaire&CycleBeginYear=2013', 'purpose': 'The NHANES dataset was created to assess the health and nutritional status of adults and children in the United States. \\n', 'funded_by': 'Centers for Disease Control and Prevention (CDC), specifically through its National Center for Health Statistics (NCHS)\\n', 'instances_represent': 'Survey respondents throughout the United States\\n\\nData was gathered through interviews, physical examinations, and laboratory tests.', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': 'For this subset respondents 65 years old and older were labeled  as senior and all individuals under 65 years old as non-senior.\\n', 'variable_info': None, 'citation': 'Please acknowledge the National Center for Health Statistics (NCHS) at the Centers for Disease Control and Prevention (CDC)'}}\n",
            "        name     role         type demographic  \\\n",
            "0       SEQN       ID   Continuous        None   \n",
            "1  age_group   Target  Categorical         Age   \n",
            "2   RIDAGEYR    Other   Continuous         Age   \n",
            "3   RIAGENDR  Feature   Continuous      Gender   \n",
            "4     PAQ605  Feature   Continuous        None   \n",
            "5     BMXBMI  Feature   Continuous        None   \n",
            "6     LBXGLU  Feature   Continuous        None   \n",
            "7     DIQ010  Feature   Continuous        None   \n",
            "8     LBXGLT  Feature   Continuous        None   \n",
            "9      LBXIN  Feature   Continuous        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0                         Respondent Sequence Number  None             no  \n",
            "1         Respondent's Age Group (senior/non-senior)  None             no  \n",
            "2                                   Respondent's Age  None             no  \n",
            "3                                Respondent's Gender  None             no  \n",
            "4  If the respondent engages in moderate or vigor...  None             no  \n",
            "5                       Respondent's Body Mass Index  None             no  \n",
            "6           Respondent's Blood Glucose after fasting  None             no  \n",
            "7                      If the Respondent is diabetic  None             no  \n",
            "8                                 Respondent's Oral   None             no  \n",
            "9                  Respondent's Blood Insulin Levels  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "X = np.array(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaQTKDCBXjt_",
        "outputId": "74e12cec-5fe7-4f4e-ec5d-02dec56ce684"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer\n",
        "from functools import partial\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 50, name='nodes'),    # Number of nodes in the hidden layer\n",
        "    Integer(10, 30, name='n_queries')   # Number of queries in active learning\n",
        "]\n",
        "\n",
        "def objective(params):\n",
        "    query_strategy = conflicting_evidence_strategy_clf\n",
        "    nodes, n_queries = params  # Unpack the hyperparameters (nodes, n_queries)\n",
        "    return main(query_strategy, X = X, y = y, task = \"bin_clf\", nodes=nodes, n_queries=n_queries, init_size = 0.1)\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")\n",
        "print(f\"Best number of queries: {result.x[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "PdBpA4J2YIrF",
        "outputId": "4524e82e-b251-4772-aadf-1f57dace8548"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New training with nodes 41 and n_queries 14\n",
            "Processing Fold 1/5...\n",
            "(1822, 7)\n",
            "(1822,)\n",
            "(456, 7)\n",
            "(456,)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a7c553b00788>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m result = gp_minimize(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# Objective function to minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# Hyperparameter space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-a7c553b00788>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mquery_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconflicting_evidence_strategy_clf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m  \u001b[0;31m# Unpack the hyperparameters (nodes, n_queries)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bin_clf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-7983d544faeb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(query_strategy, X, y, task, nodes, n_queries, stability_threshold, n_folds, init_size, beta)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;31m# Run the active learning loop with custom stop set criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactive_learning_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_stop_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_queries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_queries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstability_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstability_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# Save the trained learner (model) for this fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-e84292a33df8>\u001b[0m in \u001b[0;36mactive_learning_loop\u001b[0;34m(learner, X_pool, y_pool, X_stop_set, y_stop, X_sample, y_sample, task, n_queries, stability_threshold, max_iterations, beta)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m# Teach the model using the queried instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_pool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pool\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Remove queried instances from the pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36mteach\u001b[0;34m(self, X, y, bootstrap, only_new, **fit_kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0monly_new\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_training_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_to_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbootstrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             check_X_y(X, y, accept_sparse=True, ensure_2d=False, allow_nd=True, multi_output=True, dtype=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/modAL/models/learners.py\u001b[0m in \u001b[0;36m_fit_to_known\u001b[0;34m(self, bootstrap, **fit_kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mn_instances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m         self._fit(\n\u001b[0m\u001b[1;32m    771\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_model_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m         self._fit_keras_model(\n\u001b[0m\u001b[1;32m    939\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py\u001b[0m in \u001b[0;36m_fit_keras_model\u001b[0;34m(self, X, y, sample_weight, warm_start, epochs, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m                 \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m             \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwarm_start\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    341\u001b[0m                         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     )\n\u001b[0;32m--> 343\u001b[0;31m                 val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m    344\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                 \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36menumerate_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    647\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m             \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    650\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 for step in range(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer, Real\n",
        "from functools import partial\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 64, name='nodes'),    # Number of nodes in the hidden layer\n",
        "    Real(0.3, 0.9, name='beta')   # Number of queries in active learning\n",
        "]\n",
        "\n",
        "def objective(params):\n",
        "    nodes, beta = params  # Unpack the hyperparameters (nodes, n_queries)\n",
        "    query_strategy = sensitivity_strategy\n",
        "    return main(query_strategy, X = student_X, y = student_y, task = \"multi_clf\", nodes=nodes, beta = beta)\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")\n",
        "print(f\"Best value for beta: {result.x[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "collapsed": true,
        "id": "-pdHlCXc1YeG",
        "outputId": "635fd3fe-16e7-46f0-eed6-bf63342abcdf"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "main() got an unexpected keyword argument 'X'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-38169efb15d7>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m result = gp_minimize(\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;31m# Objective function to minimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m          \u001b[0;31m# Hyperparameter space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    279\u001b[0m         )\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     return base_minimize(\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size, space_constraint)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-135-38169efb15d7>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m  \u001b[0;31m# Unpack the hyperparameters (nodes, n_queries)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mquery_strategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensitivity_strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Run Bayesian optimization with Gaussian process minimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: main() got an unexpected keyword argument 'X'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "wCJXojuCWLD-"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer, Real\n",
        "from functools import partial\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 64, name='nodes'),    # Number of nodes in the hidden layer\n",
        "]\n",
        "\n",
        "def objective(nodes):\n",
        "    return train_passive_binary(X = X, y = y, task = \"binary\", nodes=nodes[0])\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVEETgYRRgIS",
        "outputId": "2e392bd4-45d2-4ba2-c734-170ce97ccdbf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.2653\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.3104\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.2726\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.2926\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.2957\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.3745\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.2947\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.3116\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.3317\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.2965\n",
            "Best number of nodes: 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Phishing"
      ],
      "metadata": {
        "id": "E4sfWc1E08FW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "phishing_websites = fetch_ucirepo(id=327)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = phishing_websites.data.features\n",
        "y = phishing_websites.data.targets\n",
        "\n",
        "# metadata\n",
        "print(phishing_websites.metadata)\n",
        "\n",
        "# variable information\n",
        "print(phishing_websites.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdmrX1wT9KXA",
        "outputId": "e18355ff-270c-4b21-80da-356e532f14b5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 327, 'name': 'Phishing Websites', 'repository_url': 'https://archive.ics.uci.edu/dataset/327/phishing+websites', 'data_url': 'https://archive.ics.uci.edu/static/public/327/data.csv', 'abstract': 'This dataset collected mainly from: PhishTank archive, MillerSmiles archive, Googles searching operators.', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 11055, 'num_features': 30, 'feature_types': ['Integer'], 'demographics': [], 'target_col': ['result'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2012, 'last_updated': 'Tue Mar 05 2024', 'dataset_doi': '10.24432/C51W2X', 'creators': ['Rami Mohammad', 'Lee McCluskey'], 'intro_paper': {'ID': 396, 'type': 'NATIVE', 'title': 'An assessment of features related to phishing websites using an automated technique', 'authors': 'R. Mohammad, F. Thabtah, L. Mccluskey', 'venue': 'International Conference for Internet Technology and Secured Transactions', 'year': 2012, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/An-assessment-of-features-related-to-phishing-using-Mohammad-Thabtah/0c0ff58063f4e078714ea74f112bc709ba9fed06', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'One of the challenges faced by our research was the unavailability of reliable training datasets. In fact this challenge faces any researcher in the field. However, although plenty of articles about predicting phishing websites have been disseminated these days, no reliable training dataset has been published publically, may be because there is no agreement in literature on the definitive features that characterize phishing webpages, hence it is difficult to shape a dataset that covers all possible features. \\r\\nIn this dataset, we shed light on the important features that have proved to be sound and effective in predicting phishing websites. In addition, we propose some new features.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'For Further information about the features see the features file in the data folder.', 'citation': None}}\n",
            "                          name     role     type demographic description  \\\n",
            "0            having_ip_address  Feature  Integer        None        None   \n",
            "1                   url_length  Feature  Integer        None        None   \n",
            "2           shortining_service  Feature  Integer        None        None   \n",
            "3             having_at_symbol  Feature  Integer        None        None   \n",
            "4     double_slash_redirecting  Feature  Integer        None        None   \n",
            "5                prefix_suffix  Feature  Integer        None        None   \n",
            "6            having_sub_domain  Feature  Integer        None        None   \n",
            "7               sslfinal_state  Feature  Integer        None        None   \n",
            "8   domain_registration_length  Feature  Integer        None        None   \n",
            "9                      favicon  Feature  Integer        None        None   \n",
            "10                        port  Feature  Integer        None        None   \n",
            "11                 https_token  Feature  Integer        None        None   \n",
            "12                 request_url  Feature  Integer        None        None   \n",
            "13               url_of_anchor  Feature  Integer        None        None   \n",
            "14               links_in_tags  Feature  Integer        None        None   \n",
            "15                         sfh  Feature  Integer        None        None   \n",
            "16         submitting_to_email  Feature  Integer        None        None   \n",
            "17                abnormal_url  Feature  Integer        None        None   \n",
            "18                    redirect  Feature  Integer        None        None   \n",
            "19                on_mouseover  Feature  Integer        None        None   \n",
            "20                  rightclick  Feature  Integer        None        None   \n",
            "21                 popupwindow  Feature  Integer        None        None   \n",
            "22                      iframe  Feature  Integer        None        None   \n",
            "23               age_of_domain  Feature  Integer        None        None   \n",
            "24                   dnsrecord  Feature  Integer        None        None   \n",
            "25                 web_traffic  Feature  Integer        None        None   \n",
            "26                   page_rank  Feature  Integer        None        None   \n",
            "27                google_index  Feature  Integer        None        None   \n",
            "28      links_pointing_to_page  Feature  Integer        None        None   \n",
            "29          statistical_report  Feature  Integer        None        None   \n",
            "30                      result   Target  Integer        None        None   \n",
            "\n",
            "   units missing_values  \n",
            "0   None             no  \n",
            "1   None             no  \n",
            "2   None             no  \n",
            "3   None             no  \n",
            "4   None             no  \n",
            "5   None             no  \n",
            "6   None             no  \n",
            "7   None             no  \n",
            "8   None             no  \n",
            "9   None             no  \n",
            "10  None             no  \n",
            "11  None             no  \n",
            "12  None             no  \n",
            "13  None             no  \n",
            "14  None             no  \n",
            "15  None             no  \n",
            "16  None             no  \n",
            "17  None             no  \n",
            "18  None             no  \n",
            "19  None             no  \n",
            "20  None             no  \n",
            "21  None             no  \n",
            "22  None             no  \n",
            "23  None             no  \n",
            "24  None             no  \n",
            "25  None             no  \n",
            "26  None             no  \n",
            "27  None             no  \n",
            "28  None             no  \n",
            "29  None             no  \n",
            "30  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X)\n",
        "y = (np.array(y) + 1) / 2"
      ],
      "metadata": {
        "id": "fW5xbf0W9_-f"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer\n",
        "from functools import partial\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 264, name='nodes'),    # Number of nodes in the hidden layer\n",
        "    Integer(10, 500, name='n_queries')   # Number of queries in active learning\n",
        "]\n",
        "\n",
        "def objective(params):\n",
        "    query_strategy = conflicting_evidence_strategy_clf\n",
        "    nodes, n_queries = params  # Unpack the hyperparameters (nodes, n_queries)\n",
        "    return main(query_strategy, X = X, y = y, task = \"multi_clf\", nodes=nodes, n_queries=n_queries, init_size = 0.1)\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")\n",
        "print(f\"Best number of queries: {result.x[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v82o5PxomuRm",
        "outputId": "eef85d01-1ceb-4d82-cae4-eafc1154af76"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "New training with nodes 211 and n_queries 100\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1835, Min Loss = 0.1835 with pool 7148\n",
            "Iteration 21: Current Loss = 0.1687, Min Loss = 0.1687 with pool 6976\n",
            "Iteration 31: Current Loss = 0.1500, Min Loss = 0.1500 with pool 6827\n",
            "Iteration 41: Current Loss = 0.1428, Min Loss = 0.1428 with pool 6495\n",
            "Iteration 51: Current Loss = 0.1339, Min Loss = 0.1339 with pool 6051\n",
            "Iteration 61: Current Loss = 0.1236, Min Loss = 0.1236 with pool 5525\n",
            "Iteration 71: Current Loss = 0.1081, Min Loss = 0.1081 with pool 4624\n",
            "Iteration 81: Current Loss = 0.0982, Min Loss = 0.0982 with pool 3624\n",
            "Iteration 91: Current Loss = 0.0888, Min Loss = 0.0888 with pool 2624\n",
            "Iteration 96: Current Loss = 0.0876, Min Loss = 0.0859\n",
            "Active learning stopped after 95 iterations with loss 0.0859.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1795, Min Loss = 0.1795 with pool 7174\n",
            "Iteration 21: Current Loss = 0.1683, Min Loss = 0.1683 with pool 6985\n",
            "Iteration 31: Current Loss = 0.1602, Min Loss = 0.1602 with pool 6944\n",
            "Iteration 41: Current Loss = 0.1464, Min Loss = 0.1464 with pool 6608\n",
            "Iteration 51: Current Loss = 0.1290, Min Loss = 0.1290 with pool 5998\n",
            "Iteration 61: Current Loss = 0.1191, Min Loss = 0.1191 with pool 5088\n",
            "Iteration 71: Current Loss = 0.0954, Min Loss = 0.0954 with pool 4286\n",
            "Iteration 81: Current Loss = 0.0842, Min Loss = 0.0842 with pool 3385\n",
            "Iteration 85: Current Loss = 0.0844, Min Loss = 0.0815\n",
            "Active learning stopped after 84 iterations with loss 0.0815.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1748, Min Loss = 0.1748 with pool 7097\n",
            "Iteration 21: Current Loss = 0.1559, Min Loss = 0.1559 with pool 6918\n",
            "Iteration 31: Current Loss = 0.1443, Min Loss = 0.1443 with pool 6827\n",
            "Iteration 41: Current Loss = 0.1362, Min Loss = 0.1362 with pool 6768\n",
            "Iteration 51: Current Loss = 0.1309, Min Loss = 0.1309 with pool 6710\n",
            "Iteration 61: Current Loss = 0.1159, Min Loss = 0.1159 with pool 6200\n",
            "Iteration 71: Current Loss = 0.1054, Min Loss = 0.1054 with pool 5397\n",
            "Iteration 81: Current Loss = 0.0930, Min Loss = 0.0930 with pool 4496\n",
            "Iteration 91: Current Loss = 0.0811, Min Loss = 0.0811 with pool 3496\n",
            "Iteration 92: Current Loss = 0.0811, Min Loss = 0.0811\n",
            "Active learning stopped after 91 iterations with loss 0.0811.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1758, Min Loss = 0.1758 with pool 7249\n",
            "Iteration 21: Current Loss = 0.1580, Min Loss = 0.1580 with pool 7204\n",
            "Iteration 31: Current Loss = 0.1477, Min Loss = 0.1477 with pool 6971\n",
            "Iteration 41: Current Loss = 0.1366, Min Loss = 0.1366 with pool 6731\n",
            "Iteration 51: Current Loss = 0.1225, Min Loss = 0.1225 with pool 6124\n",
            "Iteration 61: Current Loss = 0.1092, Min Loss = 0.1092 with pool 5612\n",
            "Iteration 71: Current Loss = 0.0916, Min Loss = 0.0916 with pool 4709\n",
            "Iteration 81: Current Loss = 0.0772, Min Loss = 0.0772 with pool 3709\n",
            "Iteration 84: Current Loss = 0.0787, Min Loss = 0.0772\n",
            "Active learning stopped after 83 iterations with loss 0.0772.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1642, Min Loss = 0.1642 with pool 7207\n",
            "Iteration 21: Current Loss = 0.1455, Min Loss = 0.1455 with pool 6867\n",
            "Iteration 31: Current Loss = 0.1303, Min Loss = 0.1303 with pool 6157\n",
            "Iteration 41: Current Loss = 0.1156, Min Loss = 0.1156 with pool 5447\n",
            "Iteration 51: Current Loss = 0.0932, Min Loss = 0.0932 with pool 4447\n",
            "Iteration 61: Current Loss = 0.0865, Min Loss = 0.0865 with pool 3546\n",
            "Iteration 63: Current Loss = 0.0913, Min Loss = 0.0865\n",
            "Active learning stopped after 62 iterations with loss 0.0865.\n",
            "Average Loss: 0.0825\n",
            "\n",
            "New training with nodes 207 and n_queries 302\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1746, Min Loss = 0.1746 with pool 7031\n",
            "Iteration 21: Current Loss = 0.1601, Min Loss = 0.1601 with pool 6958\n",
            "Iteration 31: Current Loss = 0.1443, Min Loss = 0.1443 with pool 6590\n",
            "Iteration 41: Current Loss = 0.1106, Min Loss = 0.1106 with pool 4165\n",
            "Iteration 51: Current Loss = 0.0899, Min Loss = 0.0899 with pool 1145\n",
            "Iteration 53: Current Loss = 0.0909, Min Loss = 0.0899\n",
            "Active learning stopped after 52 iterations with loss 0.0899.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1703, Min Loss = 0.1703 with pool 6650\n",
            "Iteration 21: Current Loss = 0.1124, Min Loss = 0.1124 with pool 4231\n",
            "Iteration 31: Current Loss = 0.0818, Min Loss = 0.0818 with pool 1211\n",
            "Active learning stopped after 34 iterations with loss 0.0774.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1633, Min Loss = 0.1633 with pool 6689\n",
            "Iteration 21: Current Loss = 0.1219, Min Loss = 0.1219 with pool 4568\n",
            "Iteration 31: Current Loss = 0.0848, Min Loss = 0.0848 with pool 1548\n",
            "Active learning stopped after 35 iterations with loss 0.0817.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1732, Min Loss = 0.1732 with pool 7040\n",
            "Iteration 21: Current Loss = 0.1103, Min Loss = 0.1103 with pool 4320\n",
            "Iteration 31: Current Loss = 0.0803, Min Loss = 0.0803 with pool 1300\n",
            "Active learning stopped after 34 iterations with loss 0.0781.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1622, Min Loss = 0.1622 with pool 7062\n",
            "Iteration 21: Current Loss = 0.1451, Min Loss = 0.1451 with pool 7008\n",
            "Iteration 31: Current Loss = 0.1149, Min Loss = 0.1149 with pool 4883\n",
            "Iteration 41: Current Loss = 0.0767, Min Loss = 0.0767 with pool 1863\n",
            "Iteration 44: Current Loss = 0.0783, Min Loss = 0.0767\n",
            "Active learning stopped after 43 iterations with loss 0.0767.\n",
            "Average Loss: 0.0807\n",
            "\n",
            "New training with nodes 120 and n_queries 59\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1951, Min Loss = 0.1951 with pool 7370\n",
            "Iteration 21: Current Loss = 0.1727, Min Loss = 0.1727 with pool 7046\n",
            "Iteration 31: Current Loss = 0.1590, Min Loss = 0.1590 with pool 6976\n",
            "Iteration 41: Current Loss = 0.1536, Min Loss = 0.1536 with pool 6823\n",
            "Iteration 51: Current Loss = 0.1473, Min Loss = 0.1473 with pool 6573\n",
            "Iteration 61: Current Loss = 0.1396, Min Loss = 0.1396 with pool 6206\n",
            "Iteration 71: Current Loss = 0.1313, Min Loss = 0.1313 with pool 5899\n",
            "Iteration 81: Current Loss = 0.1250, Min Loss = 0.1250 with pool 5367\n",
            "Iteration 91: Current Loss = 0.1110, Min Loss = 0.1110 with pool 4891\n",
            "Active learning stopped after 100 iterations with loss 0.1000.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1930, Min Loss = 0.1930 with pool 7370\n",
            "Iteration 21: Current Loss = 0.1685, Min Loss = 0.1685 with pool 7095\n",
            "Iteration 31: Current Loss = 0.1575, Min Loss = 0.1575 with pool 6958\n",
            "Iteration 41: Current Loss = 0.1471, Min Loss = 0.1471 with pool 6537\n",
            "Iteration 51: Current Loss = 0.1391, Min Loss = 0.1391 with pool 6120\n",
            "Iteration 61: Current Loss = 0.1286, Min Loss = 0.1286 with pool 5587\n",
            "Iteration 71: Current Loss = 0.1126, Min Loss = 0.1126 with pool 5112\n",
            "Iteration 81: Current Loss = 0.1021, Min Loss = 0.1021 with pool 4580\n",
            "Iteration 91: Current Loss = 0.0903, Min Loss = 0.0903 with pool 3990\n",
            "Iteration 100: Current Loss = 0.0851, Min Loss = 0.0845\n",
            "Active learning stopped after 99 iterations with loss 0.0845.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1934, Min Loss = 0.1934 with pool 7370\n",
            "Iteration 21: Current Loss = 0.1662, Min Loss = 0.1662 with pool 7146\n",
            "Iteration 31: Current Loss = 0.1598, Min Loss = 0.1598 with pool 7003\n",
            "Iteration 41: Current Loss = 0.1477, Min Loss = 0.1477 with pool 6792\n",
            "Iteration 51: Current Loss = 0.1394, Min Loss = 0.1394 with pool 6484\n",
            "Iteration 61: Current Loss = 0.1266, Min Loss = 0.1266 with pool 5894\n",
            "Iteration 71: Current Loss = 0.1199, Min Loss = 0.1199 with pool 5419\n",
            "Iteration 81: Current Loss = 0.1093, Min Loss = 0.1093 with pool 4886\n",
            "Iteration 91: Current Loss = 0.1033, Min Loss = 0.1033 with pool 4354\n",
            "Active learning stopped after 100 iterations with loss 0.1008.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1857, Min Loss = 0.1857 with pool 7370\n",
            "Iteration 21: Current Loss = 0.1596, Min Loss = 0.1596 with pool 7062\n",
            "Iteration 31: Current Loss = 0.1469, Min Loss = 0.1469 with pool 6906\n",
            "Iteration 41: Current Loss = 0.1437, Min Loss = 0.1437 with pool 6822\n",
            "Iteration 51: Current Loss = 0.1337, Min Loss = 0.1337 with pool 6457\n",
            "Iteration 61: Current Loss = 0.1231, Min Loss = 0.1231 with pool 6036\n",
            "Iteration 71: Current Loss = 0.1133, Min Loss = 0.1133 with pool 5446\n",
            "Iteration 81: Current Loss = 0.1036, Min Loss = 0.1036 with pool 4856\n",
            "Iteration 91: Current Loss = 0.0869, Min Loss = 0.0869 with pool 4266\n",
            "Iteration 95: Current Loss = 0.0867, Min Loss = 0.0852\n",
            "Active learning stopped after 94 iterations with loss 0.0852.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1798, Min Loss = 0.1798 with pool 7370\n",
            "Iteration 21: Current Loss = 0.1595, Min Loss = 0.1595 with pool 7019\n",
            "Iteration 31: Current Loss = 0.1473, Min Loss = 0.1473 with pool 6918\n",
            "Iteration 41: Current Loss = 0.1370, Min Loss = 0.1370 with pool 6612\n",
            "Iteration 51: Current Loss = 0.1295, Min Loss = 0.1295 with pool 6253\n",
            "Iteration 61: Current Loss = 0.1225, Min Loss = 0.1225 with pool 5777\n",
            "Iteration 71: Current Loss = 0.1100, Min Loss = 0.1100 with pool 5187\n",
            "Iteration 81: Current Loss = 0.0993, Min Loss = 0.0993 with pool 4654\n",
            "Iteration 89: Current Loss = 0.0960, Min Loss = 0.0958\n",
            "Active learning stopped after 88 iterations with loss 0.0958.\n",
            "Average Loss: 0.0932\n",
            "\n",
            "New training with nodes 124 and n_queries 174\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1865, Min Loss = 0.1865 with pool 7058\n",
            "Iteration 21: Current Loss = 0.1712, Min Loss = 0.1712 with pool 6848\n",
            "Iteration 31: Current Loss = 0.1499, Min Loss = 0.1499 with pool 5795\n",
            "Iteration 41: Current Loss = 0.1130, Min Loss = 0.1130 with pool 4398\n",
            "Iteration 51: Current Loss = 0.0927, Min Loss = 0.0927 with pool 2658\n",
            "Iteration 60: Current Loss = 0.0917, Min Loss = 0.0910\n",
            "Active learning stopped after 59 iterations with loss 0.0910.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1834, Min Loss = 0.1834 with pool 7034\n",
            "Iteration 21: Current Loss = 0.1640, Min Loss = 0.1640 with pool 6814\n",
            "Iteration 31: Current Loss = 0.1435, Min Loss = 0.1435 with pool 5764\n",
            "Iteration 41: Current Loss = 0.1073, Min Loss = 0.1073 with pool 4711\n",
            "Iteration 51: Current Loss = 0.0852, Min Loss = 0.0852 with pool 3317\n",
            "Iteration 60: Current Loss = 0.0780, Min Loss = 0.0762\n",
            "Active learning stopped after 59 iterations with loss 0.0762.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1801, Min Loss = 0.1801 with pool 7046\n",
            "Iteration 21: Current Loss = 0.1568, Min Loss = 0.1568 with pool 6643\n",
            "Iteration 31: Current Loss = 0.1351, Min Loss = 0.1351 with pool 5245\n",
            "Iteration 41: Current Loss = 0.0989, Min Loss = 0.0989 with pool 3674\n",
            "Iteration 51: Current Loss = 0.0810, Min Loss = 0.0810 with pool 1934\n",
            "Iteration 54: Current Loss = 0.0829, Min Loss = 0.0810\n",
            "Active learning stopped after 53 iterations with loss 0.0810.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1787, Min Loss = 0.1787 with pool 7027\n",
            "Iteration 21: Current Loss = 0.1514, Min Loss = 0.1514 with pool 6309\n",
            "Iteration 31: Current Loss = 0.1321, Min Loss = 0.1321 with pool 4915\n",
            "Iteration 41: Current Loss = 0.0853, Min Loss = 0.0853 with pool 3175\n",
            "Iteration 51: Current Loss = 0.0785, Min Loss = 0.0785 with pool 1608\n",
            "Iteration 56: Current Loss = 0.0794, Min Loss = 0.0779\n",
            "Active learning stopped after 55 iterations with loss 0.0779.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1729, Min Loss = 0.1729 with pool 7053\n",
            "Iteration 21: Current Loss = 0.1553, Min Loss = 0.1553 with pool 6935\n",
            "Iteration 31: Current Loss = 0.1387, Min Loss = 0.1387 with pool 6044\n",
            "Iteration 41: Current Loss = 0.1114, Min Loss = 0.1114 with pool 4818\n",
            "Iteration 51: Current Loss = 0.0867, Min Loss = 0.0867 with pool 3251\n",
            "Iteration 61: Current Loss = 0.0810, Min Loss = 0.0810 with pool 1511\n",
            "Iteration 62: Current Loss = 0.0850, Min Loss = 0.0810\n",
            "Active learning stopped after 61 iterations with loss 0.0810.\n",
            "Average Loss: 0.0814\n",
            "\n",
            "New training with nodes 42 and n_queries 329\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1952, Min Loss = 0.1952 with pool 6733\n",
            "Iteration 21: Current Loss = 0.1742, Min Loss = 0.1742 with pool 6361\n",
            "Iteration 31: Current Loss = 0.1327, Min Loss = 0.1327 with pool 3722\n",
            "Iteration 41: Current Loss = 0.1006, Min Loss = 0.1006 with pool 432\n",
            "Active learning stopped after 41 iterations with loss 0.1003.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2038, Min Loss = 0.2038 with pool 6854\n",
            "Iteration 21: Current Loss = 0.1449, Min Loss = 0.1449 with pool 4541\n",
            "Iteration 31: Current Loss = 0.0947, Min Loss = 0.0947 with pool 1251\n",
            "Active learning stopped after 33 iterations with loss 0.0895.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1897, Min Loss = 0.1897 with pool 6596\n",
            "Iteration 21: Current Loss = 0.1260, Min Loss = 0.1260 with pool 3958\n",
            "Iteration 31: Current Loss = 0.1023, Min Loss = 0.1023 with pool 668\n",
            "Active learning stopped after 32 iterations with loss 0.0980.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2044, Min Loss = 0.2044 with pool 6537\n",
            "Iteration 21: Current Loss = 0.1691, Min Loss = 0.1691 with pool 5529\n",
            "Iteration 31: Current Loss = 0.0954, Min Loss = 0.0954 with pool 2239\n",
            "Active learning stopped after 36 iterations with loss 0.0842.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1972, Min Loss = 0.1972 with pool 6784\n",
            "Iteration 21: Current Loss = 0.1722, Min Loss = 0.1722 with pool 6395\n",
            "Iteration 31: Current Loss = 0.1116, Min Loss = 0.1116 with pool 3433\n",
            "Active learning stopped after 40 iterations with loss 0.0906.\n",
            "Average Loss: 0.0925\n",
            "\n",
            "New training with nodes 20 and n_queries 364\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2294, Min Loss = 0.2294 with pool 6682\n",
            "Iteration 21: Current Loss = 0.1921, Min Loss = 0.1921 with pool 6595\n",
            "Iteration 31: Current Loss = 0.1760, Min Loss = 0.1760 with pool 6188\n",
            "Iteration 41: Current Loss = 0.1281, Min Loss = 0.1281 with pool 2911\n",
            "Active learning stopped after 47 iterations with loss 0.1101.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.3878, Min Loss = 0.3878 with pool 7557\n",
            "Iteration 21: Current Loss = 0.2066, Min Loss = 0.2066 with pool 6829\n",
            "Iteration 31: Current Loss = 0.1873, Min Loss = 0.1873 with pool 6421\n",
            "Iteration 41: Current Loss = 0.1339, Min Loss = 0.1339 with pool 3507\n",
            "Active learning stopped after 49 iterations with loss 0.1145.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2292, Min Loss = 0.2292 with pool 6693\n",
            "Iteration 21: Current Loss = 0.1893, Min Loss = 0.1893 with pool 6610\n",
            "Iteration 31: Current Loss = 0.1742, Min Loss = 0.1742 with pool 6589\n",
            "Iteration 41: Current Loss = 0.1263, Min Loss = 0.1263 with pool 3311\n",
            "Active learning stopped after 49 iterations with loss 0.1044.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2138, Min Loss = 0.2138 with pool 6539\n",
            "Iteration 21: Current Loss = 0.1845, Min Loss = 0.1845 with pool 6428\n",
            "Iteration 31: Current Loss = 0.1509, Min Loss = 0.1509 with pool 4951\n",
            "Iteration 41: Current Loss = 0.1078, Min Loss = 0.1078 with pool 2037\n",
            "Active learning stopped after 45 iterations with loss 0.0926.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2029, Min Loss = 0.2029 with pool 6536\n",
            "Iteration 21: Current Loss = 0.1741, Min Loss = 0.1741 with pool 6471\n",
            "Iteration 31: Current Loss = 0.1247, Min Loss = 0.1247 with pool 3194\n",
            "Active learning stopped after 39 iterations with loss 0.1055.\n",
            "Average Loss: 0.1054\n",
            "\n",
            "New training with nodes 248 and n_queries 10\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2139, Min Loss = 0.2139 with pool 7860\n",
            "Iteration 21: Current Loss = 0.2042, Min Loss = 0.2042 with pool 7760\n",
            "Iteration 30: Current Loss = 0.1969, Min Loss = 0.1951\n",
            "Active learning stopped after 29 iterations with loss 0.1951.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1988, Min Loss = 0.1988 with pool 7860\n",
            "Iteration 21: Current Loss = 0.1914, Min Loss = 0.1914 with pool 7760\n",
            "Iteration 31: Current Loss = 0.1807, Min Loss = 0.1807 with pool 7660\n",
            "Iteration 33: Current Loss = 0.1855, Min Loss = 0.1807\n",
            "Active learning stopped after 32 iterations with loss 0.1807.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2145, Min Loss = 0.2145 with pool 7860\n",
            "Iteration 21: Current Loss = 0.2098, Min Loss = 0.2098 with pool 7760\n",
            "Iteration 22: Current Loss = 0.2125, Min Loss = 0.2098\n",
            "Active learning stopped after 21 iterations with loss 0.2098.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2072, Min Loss = 0.2072 with pool 7860\n",
            "Iteration 21: Current Loss = 0.1998, Min Loss = 0.1998 with pool 7760\n",
            "Iteration 31: Current Loss = 0.1822, Min Loss = 0.1822 with pool 7660\n",
            "Iteration 41: Current Loss = 0.1725, Min Loss = 0.1725 with pool 7560\n",
            "Iteration 46: Current Loss = 0.1726, Min Loss = 0.1673\n",
            "Active learning stopped after 45 iterations with loss 0.1673.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1845, Min Loss = 0.1845 with pool 7860\n",
            "Iteration 19: Current Loss = 0.1807, Min Loss = 0.1787\n",
            "Active learning stopped after 18 iterations with loss 0.1787.\n",
            "Average Loss: 0.1863\n",
            "\n",
            "New training with nodes 262 and n_queries 313\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1734, Min Loss = 0.1734 with pool 7079\n",
            "Iteration 21: Current Loss = 0.1482, Min Loss = 0.1482 with pool 5491\n",
            "Iteration 31: Current Loss = 0.0931, Min Loss = 0.0931 with pool 2361\n",
            "Iteration 33: Current Loss = 0.0959, Min Loss = 0.0931\n",
            "Active learning stopped after 32 iterations with loss 0.0931.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1646, Min Loss = 0.1646 with pool 6677\n",
            "Iteration 21: Current Loss = 0.1308, Min Loss = 0.1308 with pool 4785\n",
            "Iteration 31: Current Loss = 0.0808, Min Loss = 0.0808 with pool 1655\n",
            "Active learning stopped after 35 iterations with loss 0.0771.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1661, Min Loss = 0.1661 with pool 6993\n",
            "Iteration 21: Current Loss = 0.1422, Min Loss = 0.1422 with pool 6005\n",
            "Iteration 31: Current Loss = 0.0930, Min Loss = 0.0930 with pool 4113\n",
            "Iteration 41: Current Loss = 0.0792, Min Loss = 0.0792 with pool 983\n",
            "Active learning stopped after 43 iterations with loss 0.0770.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1614, Min Loss = 0.1614 with pool 6816\n",
            "Iteration 21: Current Loss = 0.1431, Min Loss = 0.1431 with pool 6125\n",
            "Iteration 31: Current Loss = 0.0919, Min Loss = 0.0919 with pool 4236\n",
            "Iteration 41: Current Loss = 0.0751, Min Loss = 0.0751 with pool 1106\n",
            "Iteration 43: Current Loss = 0.0768, Min Loss = 0.0751\n",
            "Active learning stopped after 42 iterations with loss 0.0751.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1533, Min Loss = 0.1533 with pool 7024\n",
            "Iteration 21: Current Loss = 0.1432, Min Loss = 0.1432 with pool 6905\n",
            "Iteration 31: Current Loss = 0.1369, Min Loss = 0.1369 with pool 6826\n",
            "Iteration 38: Current Loss = 0.1375, Min Loss = 0.1344\n",
            "Active learning stopped after 37 iterations with loss 0.1344.\n",
            "Average Loss: 0.0913\n",
            "\n",
            "New training with nodes 163 and n_queries 13\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1998, Min Loss = 0.1998 with pool 7830\n",
            "Iteration 21: Current Loss = 0.1852, Min Loss = 0.1852 with pool 7700\n",
            "Iteration 31: Current Loss = 0.1703, Min Loss = 0.1703 with pool 7570\n",
            "Iteration 41: Current Loss = 0.1628, Min Loss = 0.1628 with pool 7440\n",
            "Iteration 51: Current Loss = 0.1572, Min Loss = 0.1572 with pool 7310\n",
            "Iteration 61: Current Loss = 0.1477, Min Loss = 0.1477 with pool 7193\n",
            "Iteration 70: Current Loss = 0.1465, Min Loss = 0.1453\n",
            "Active learning stopped after 69 iterations with loss 0.1453.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2176, Min Loss = 0.2176 with pool 7830\n",
            "Iteration 21: Current Loss = 0.2016, Min Loss = 0.2016 with pool 7700\n",
            "Iteration 31: Current Loss = 0.1887, Min Loss = 0.1887 with pool 7570\n",
            "Iteration 41: Current Loss = 0.1804, Min Loss = 0.1804 with pool 7440\n",
            "Iteration 51: Current Loss = 0.1742, Min Loss = 0.1742 with pool 7311\n",
            "Iteration 61: Current Loss = 0.1612, Min Loss = 0.1612 with pool 7224\n",
            "Iteration 63: Current Loss = 0.1629, Min Loss = 0.1612\n",
            "Active learning stopped after 62 iterations with loss 0.1612.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2018, Min Loss = 0.2018 with pool 7830\n",
            "Iteration 21: Current Loss = 0.1914, Min Loss = 0.1914 with pool 7700\n",
            "Iteration 31: Current Loss = 0.1757, Min Loss = 0.1757 with pool 7570\n",
            "Iteration 35: Current Loss = 0.1775, Min Loss = 0.1754\n",
            "Active learning stopped after 34 iterations with loss 0.1754.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1999, Min Loss = 0.1999 with pool 7830\n",
            "Iteration 21: Current Loss = 0.1814, Min Loss = 0.1814 with pool 7700\n",
            "Iteration 31: Current Loss = 0.1706, Min Loss = 0.1706 with pool 7570\n",
            "Iteration 41: Current Loss = 0.1641, Min Loss = 0.1641 with pool 7440\n",
            "Iteration 51: Current Loss = 0.1562, Min Loss = 0.1562 with pool 7340\n",
            "Iteration 61: Current Loss = 0.1519, Min Loss = 0.1519 with pool 7281\n",
            "Iteration 69: Current Loss = 0.1489, Min Loss = 0.1489\n",
            "Active learning stopped after 68 iterations with loss 0.1489.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.1928, Min Loss = 0.1928 with pool 7830\n",
            "Iteration 21: Current Loss = 0.1757, Min Loss = 0.1757 with pool 7700\n",
            "Iteration 31: Current Loss = 0.1640, Min Loss = 0.1640 with pool 7570\n",
            "Iteration 41: Current Loss = 0.1598, Min Loss = 0.1598 with pool 7440\n",
            "Iteration 41: Current Loss = 0.1610, Min Loss = 0.1598\n",
            "Active learning stopped after 40 iterations with loss 0.1598.\n",
            "Average Loss: 0.1581\n",
            "\n",
            "New training with nodes 11 and n_queries 267\n",
            "Processing Fold 1/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2418, Min Loss = 0.2418 with pool 6486\n",
            "Iteration 21: Current Loss = 0.1987, Min Loss = 0.1987 with pool 6385\n",
            "Iteration 31: Current Loss = 0.1637, Min Loss = 0.1637 with pool 5030\n",
            "Iteration 41: Current Loss = 0.1330, Min Loss = 0.1330 with pool 2360\n",
            "Active learning stopped after 48 iterations with loss 0.1270.\n",
            "Processing Fold 2/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.3979, Min Loss = 0.3979 with pool 5649\n",
            "Iteration 21: Current Loss = 0.3857, Min Loss = 0.3857 with pool 2979\n",
            "Iteration 31: Current Loss = 0.3571, Min Loss = 0.3571 with pool 574\n",
            "Active learning stopped after 32 iterations with loss 0.3548.\n",
            "Processing Fold 3/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2302, Min Loss = 0.2302 with pool 6739\n",
            "Iteration 21: Current Loss = 0.2061, Min Loss = 0.2061 with pool 6411\n",
            "Iteration 31: Current Loss = 0.1569, Min Loss = 0.1569 with pool 4532\n",
            "Iteration 41: Current Loss = 0.1347, Min Loss = 0.1347 with pool 1862\n",
            "Active learning stopped after 46 iterations with loss 0.1281.\n",
            "Processing Fold 4/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2275, Min Loss = 0.2275 with pool 6378\n",
            "Iteration 21: Current Loss = 0.1927, Min Loss = 0.1927 with pool 6298\n",
            "Iteration 31: Current Loss = 0.1777, Min Loss = 0.1777 with pool 5476\n",
            "Iteration 41: Current Loss = 0.1279, Min Loss = 0.1279 with pool 3072\n",
            "Iteration 51: Current Loss = 0.1064, Min Loss = 0.1064 with pool 402\n",
            "Active learning stopped after 51 iterations with loss 0.1060.\n",
            "Processing Fold 5/5...\n",
            "(7960, 30)\n",
            "Iteration 1: Current Loss = inf, Min Loss = inf with pool 7960\n",
            "Iteration 11: Current Loss = 0.2311, Min Loss = 0.2311 with pool 6745\n",
            "Iteration 21: Current Loss = 0.1905, Min Loss = 0.1905 with pool 6548\n",
            "Iteration 31: Current Loss = 0.1449, Min Loss = 0.1449 with pool 4403\n",
            "Iteration 41: Current Loss = 0.1240, Min Loss = 0.1240 with pool 1733\n",
            "Active learning stopped after 46 iterations with loss 0.1192.\n",
            "Average Loss: 0.1670\n",
            "Best number of nodes: 207\n",
            "Best number of queries: 302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic Binary Classification\n",
        "from skopt import gp_minimize\n",
        "from skopt.space import Integer, Real\n",
        "from functools import partial\n",
        "\n",
        "# Define the search space for Bayesian optimization (nodes and n_queries)\n",
        "search_space = [\n",
        "    Integer(5, 64, name='nodes'),    # Number of nodes in the hidden layer\n",
        "]\n",
        "\n",
        "def objective(nodes):\n",
        "    return train_passive_binary(X = X, y = y, task = \"multi\", nodes=nodes[0])\n",
        "\n",
        "# Run Bayesian optimization with Gaussian process minimization\n",
        "result = gp_minimize(\n",
        "    objective,             # Objective function to minimize\n",
        "    search_space,          # Hyperparameter space\n",
        "    n_calls=10,            # Number of iterations to run\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Print the best hyperparameters found\n",
        "print(f\"Best number of nodes: {result.x[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1oYyyflaK7s",
        "outputId": "41633ee9-2cb7-4ca6-a08f-a3b0e1601248"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1338\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1470\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1340\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1355\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1381\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1492\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1366\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1413\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1461\n",
            "Getting here?\n",
            "Processing Fold 1/5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Fold 2/5...\n",
            "Processing Fold 3/5...\n",
            "Processing Fold 4/5...\n",
            "Processing Fold 5/5...\n",
            "Average Loss across 5 folds: 0.1319\n",
            "Best number of nodes: 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mushroom: Missing"
      ],
      "metadata": {
        "id": "wH4vWH3W0-TG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "secondary_mushroom = fetch_ucirepo(id=848)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = secondary_mushroom.data.features\n",
        "y = secondary_mushroom.data.targets\n",
        "\n",
        "# metadata\n",
        "print(secondary_mushroom.metadata)\n",
        "\n",
        "# variable information\n",
        "print(secondary_mushroom.variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGpbgha2zrYv",
        "outputId": "c8d85eb1-b0b7-4b89-f627-503a49933f91"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 848, 'name': 'Secondary Mushroom', 'repository_url': 'https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/848/data.csv', 'abstract': 'Dataset of simulated mushrooms for binary classification into edible and poisonous.', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 61068, 'num_features': 20, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 2021, 'last_updated': 'Wed Apr 10 2024', 'dataset_doi': '10.24432/C5FP5Q', 'creators': ['Dennis Wagner', 'D. Heider', 'Georges Hattab'], 'intro_paper': {'ID': 259, 'type': 'NATIVE', 'title': 'Mushroom data creation, curation, and simulation to support classification tasks', 'authors': 'Dennis Wagner, D. Heider, Georges Hattab', 'venue': 'Scientific Reports', 'year': 2021, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/336be248b6f1c5d77c3c93e89f2e19e7344b0250', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'The given information is about the Secondary Mushroom Dataset, the Primary Mushroom Dataset used for the simulation and the respective metadata can be found in the zip.\\n\\nThis dataset includes 61069 hypothetical mushrooms with caps based on 173 species (353 mushrooms\\nper species). Each mushroom is identified as definitely edible, definitely poisonous, or of\\nunknown edibility and not recommended (the latter class was combined with the poisonous class).\\n\\nThe related Python project contains a Python module secondary_data_generation.py\\nused to generate this data based on primary_data_edited.csv also found in the repository.\\nBoth nominal and metrical variables are a result of randomization.\\nThe simulated and ordered by species version is found in secondary_data_generated.csv.\\nThe randomly shuffled version is found in secondary_data_shuffled.csv.', 'purpose': 'Inspired by the Mushroom Data Set of J. Schlimmer: url:https://archive.ics.uci.edu/ml/datasets/Mushroom.', 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'One binary class divided in edible=e and poisonous=p (with the latter one also containing mushrooms of unknown edibility).\\nTwenty remaining variables (n: nominal, m: metrical)\\n1. cap-diameter (m): float number in cm\\n2. cap-shape (n): bell=b, conical=c, convex=x, flat=f,\\nsunken=s, spherical=p, others=o\\n3. cap-surface (n): fibrous=i, grooves=g, scaly=y, smooth=s,\\nshiny=h, leathery=l, silky=k, sticky=t,\\nwrinkled=w, fleshy=e\\n4. cap-color (n): brown=n, buff=b, gray=g, green=r, pink=p,\\npurple=u, red=e, white=w, yellow=y, blue=l,\\norange=o, black=k\\n5. does-bruise-bleed (n): bruises-or-bleeding=t,no=f\\n6. gill-attachment (n): adnate=a, adnexed=x, decurrent=d, free=e,\\nsinuate=s, pores=p, none=f, unknown=?\\n7. gill-spacing (n): close=c, distant=d, none=f\\n8. gill-color (n): see cap-color + none=f\\n9. stem-height (m): float number in cm\\n10. stem-width (m): float number in mm\\n11. stem-root (n): bulbous=b, swollen=s, club=c, cup=u, equal=e,\\nrhizomorphs=z, rooted=r\\n12. stem-surface (n): see cap-surface + none=f\\n13. stem-color (n): see cap-color + none=f\\n14. veil-type (n): partial=p, universal=u\\n15. veil-color (n): see cap-color + none=f\\n16. has-ring (n): ring=t, none=f\\n17. ring-type (n): cobwebby=c, evanescent=e, flaring=r, grooved=g,\\nlarge=l, pendant=p, sheathing=s, zone=z, scaly=y, movable=m, none=f, unknown=?\\n18. spore-print-color (n): see cap color\\n19. habitat (n): grasses=g, leaves=l, meadows=m, paths=p, heaths=h,\\nurban=u, waste=w, woods=d\\n20. season (n): spring=s, summer=u, autumn=a, winter=w', 'citation': None}}\n",
            "                    name     role         type demographic description units  \\\n",
            "0                  class   Target  Categorical        None        None  None   \n",
            "1           cap-diameter  Feature   Continuous        None        None  None   \n",
            "2              cap-shape  Feature  Categorical        None        None  None   \n",
            "3            cap-surface  Feature  Categorical        None        None  None   \n",
            "4              cap-color  Feature  Categorical        None        None  None   \n",
            "5   does-bruise-or-bleed  Feature  Categorical        None        None  None   \n",
            "6        gill-attachment  Feature  Categorical        None        None  None   \n",
            "7           gill-spacing  Feature  Categorical        None        None  None   \n",
            "8             gill-color  Feature  Categorical        None        None  None   \n",
            "9            stem-height  Feature   Continuous        None        None  None   \n",
            "10            stem-width  Feature   Continuous        None        None  None   \n",
            "11             stem-root  Feature  Categorical        None        None  None   \n",
            "12          stem-surface  Feature  Categorical        None        None  None   \n",
            "13            stem-color  Feature  Categorical        None        None  None   \n",
            "14             veil-type  Feature  Categorical        None        None  None   \n",
            "15            veil-color  Feature  Categorical        None        None  None   \n",
            "16              has-ring  Feature  Categorical        None        None  None   \n",
            "17             ring-type  Feature  Categorical        None        None  None   \n",
            "18     spore-print-color  Feature  Categorical        None        None  None   \n",
            "19               habitat  Feature  Categorical        None        None  None   \n",
            "20                season  Feature  Categorical        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3             yes  \n",
            "4              no  \n",
            "5              no  \n",
            "6             yes  \n",
            "7             yes  \n",
            "8              no  \n",
            "9              no  \n",
            "10             no  \n",
            "11            yes  \n",
            "12            yes  \n",
            "13             no  \n",
            "14            yes  \n",
            "15            yes  \n",
            "16             no  \n",
            "17            yes  \n",
            "18            yes  \n",
            "19             no  \n",
            "20             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "8gY0_WI1nsZc",
        "outputId": "fb6f1d7d-323d-418d-dd21-b334380f3e7f"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "class\n",
              "p        33888\n",
              "e        27181\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>p</th>\n",
              "      <td>33888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>e</th>\n",
              "      <td>27181</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Parkinsons: Regression"
      ],
      "metadata": {
        "id": "S98tkr_g1B1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "parkinsons_telemonitoring = fetch_ucirepo(id=189)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = parkinsons_telemonitoring.data.features\n",
        "y = parkinsons_telemonitoring.data.targets\n",
        "\n",
        "# metadata\n",
        "print(parkinsons_telemonitoring.metadata)\n",
        "\n",
        "# variable information\n",
        "print(parkinsons_telemonitoring.variables)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHbSX-VTz-K7",
        "outputId": "0b834ff5-728d-4da8-9f91-ed67154e96d0"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 189, 'name': 'Parkinsons Telemonitoring', 'repository_url': 'https://archive.ics.uci.edu/dataset/189/parkinsons+telemonitoring', 'data_url': 'https://archive.ics.uci.edu/static/public/189/data.csv', 'abstract': \"Oxford Parkinson's Disease Telemonitoring Dataset\", 'area': 'Health and Medicine', 'tasks': ['Regression'], 'characteristics': ['Tabular'], 'num_instances': 5875, 'num_features': 19, 'feature_types': ['Integer', 'Real'], 'demographics': ['Age', 'Sex'], 'target_col': ['motor_UPDRS', 'total_UPDRS'], 'index_col': ['subject#'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2009, 'last_updated': 'Fri Nov 03 2023', 'dataset_doi': '10.24432/C5ZS3N', 'creators': ['Athanasios Tsanas', 'Max Little'], 'intro_paper': {'ID': 229, 'type': 'NATIVE', 'title': \"Accurate Telemonitoring of Parkinson's Disease Progression by Noninvasive Speech Tests\", 'authors': 'A. Tsanas, Max A. Little, P. McSharry, L. Ramig', 'venue': 'IEEE Transactions on Biomedical Engineering', 'year': 2010, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/1fdf33b6d8b1bdb38866ba824c1dcaecdfb6bdd6', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': '19932995', 'pmcid': None}, 'additional_info': {'summary': \"This dataset is composed of a range of biomedical voice measurements from 42 people with early-stage Parkinson's disease recruited to a six-month trial of a telemonitoring device for remote symptom progression monitoring. The recordings were automatically captured in the patient's homes.\\r\\n\\r\\nColumns in the table contain subject number, subject age, subject gender, time interval from baseline recruitment date, motor UPDRS, total UPDRS, and 16 biomedical voice measures. Each row corresponds to one of 5,875 voice recording from these individuals. The main aim of the data is to predict the motor and total UPDRS scores ('motor_UPDRS' and 'total_UPDRS') from the 16 voice measures.\\r\\n\\r\\nThe data is in ASCII CSV format. The rows of the CSV file contain an instance corresponding to one voice recording. There are around 200 recordings per patient, the subject number of the patient is identified in the first column. For further information or to pass on comments, please contact Athanasios Tsanas (tsanasthanasis@gmail.com) or Max Little (littlem@physics.ox.ac.uk).\\r\\n\\r\\nFurther details are contained in the following reference -- if you use this dataset, please cite:\\r\\nAthanasios Tsanas, Max A. Little, Patrick E. McSharry, Lorraine O. Ramig (2009),\\r\\n'Accurate telemonitoring of Parkinsons disease progression by non-invasive speech tests',\\r\\nIEEE Transactions on Biomedical Engineering (to appear).\\r\\n\\r\\nFurther details about the biomedical voice measures can be found in:\\r\\nMax A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2009), \\r\\n'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', \\r\\nIEEE Transactions on Biomedical Engineering, 56(4):1015-1022\\r\\n\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': \"subject# - Integer that uniquely identifies each subject\\r\\nage - Subject age\\r\\nsex - Subject gender '0' - male, '1' - female\\r\\ntest_time - Time since recruitment into the trial. The integer part is the number of days since recruitment. \\r\\nmotor_UPDRS - Clinician's motor UPDRS score, linearly interpolated\\r\\ntotal_UPDRS - Clinician's total UPDRS score, linearly interpolated\\r\\nJitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP - Several measures of variation in fundamental frequency\\r\\nShimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA - Several measures of variation in amplitude\\r\\nNHR,HNR - Two measures of ratio of noise to tonal components in the voice\\r\\nRPDE - A nonlinear dynamical complexity measure\\r\\nDFA - Signal fractal scaling exponent\\r\\nPPE - A nonlinear measure of fundamental frequency variation \\r\\n\", 'citation': None}}\n",
            "             name     role        type demographic  \\\n",
            "0        subject#       ID     Integer        None   \n",
            "1             age  Feature     Integer         Age   \n",
            "2       test_time  Feature  Continuous        None   \n",
            "3       Jitter(%)  Feature  Continuous        None   \n",
            "4     Jitter(Abs)  Feature  Continuous        None   \n",
            "5      Jitter:RAP  Feature  Continuous        None   \n",
            "6     Jitter:PPQ5  Feature  Continuous        None   \n",
            "7      Jitter:DDP  Feature  Continuous        None   \n",
            "8         Shimmer  Feature  Continuous        None   \n",
            "9     Shimmer(dB)  Feature  Continuous        None   \n",
            "10   Shimmer:APQ3  Feature  Continuous        None   \n",
            "11   Shimmer:APQ5  Feature  Continuous        None   \n",
            "12  Shimmer:APQ11  Feature  Continuous        None   \n",
            "13    Shimmer:DDA  Feature  Continuous        None   \n",
            "14            NHR  Feature  Continuous        None   \n",
            "15            HNR  Feature  Continuous        None   \n",
            "16           RPDE  Feature  Continuous        None   \n",
            "17            DFA  Feature  Continuous        None   \n",
            "18            PPE  Feature  Continuous        None   \n",
            "19    motor_UPDRS   Target  Continuous        None   \n",
            "20    total_UPDRS   Target  Continuous        None   \n",
            "21            sex  Feature      Binary         Sex   \n",
            "\n",
            "                                          description units missing_values  \n",
            "0       Integer that uniquely identifies each subject  None             no  \n",
            "1                                         Subject age  None             no  \n",
            "2   Time since recruitment into the trial. The int...  None             no  \n",
            "3   Several measures of variation in fundamental f...  None             no  \n",
            "4   Several measures of variation in fundamental f...  None             no  \n",
            "5   Several measures of variation in fundamental f...  None             no  \n",
            "6   Several measures of variation in fundamental f...  None             no  \n",
            "7   Several measures of variation in fundamental f...  None             no  \n",
            "8          Several measures of variation in amplitude  None             no  \n",
            "9          Several measures of variation in amplitude  None             no  \n",
            "10         Several measures of variation in amplitude  None             no  \n",
            "11         Several measures of variation in amplitude  None             no  \n",
            "12         Several measures of variation in amplitude  None             no  \n",
            "13         Several measures of variation in amplitude  None             no  \n",
            "14  Two measures of ratio of noise to tonal compon...  None             no  \n",
            "15  Two measures of ratio of noise to tonal compon...  None             no  \n",
            "16           A nonlinear dynamical complexity measure  None             no  \n",
            "17                    Signal fractal scaling exponent  None             no  \n",
            "18  A nonlinear measure of fundamental frequency v...  None             no  \n",
            "19  Clinician's motor UPDRS score, linearly interp...  None             no  \n",
            "20  Clinician's total UPDRS score, linearly interp...  None             no  \n",
            "21               Subject sex '0' - male, '1' - female  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Thermography: Regression"
      ],
      "metadata": {
        "id": "TUeJjyYA1D_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "infrared_thermography_temperature = fetch_ucirepo(id=925)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = infrared_thermography_temperature.data.features\n",
        "y = infrared_thermography_temperature.data.targets\n",
        "\n",
        "# metadata\n",
        "print(infrared_thermography_temperature.metadata)\n",
        "\n",
        "# variable information\n",
        "print(infrared_thermography_temperature.variables)"
      ],
      "metadata": {
        "id": "IoujnBl00Ply",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df4468ea-3ed5-49c2-c684-ce586d4da009"
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 925, 'name': 'Infrared Thermography Temperature', 'repository_url': 'https://archive.ics.uci.edu/dataset/925/infrared+thermography+temperature+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/925/data.csv', 'abstract': 'The Infrared Thermography Temperature Dataset contains temperatures read from various locations of inferred images about patients, with the addition of oral temperatures measured for each individual. The 33 features consist of gender, age, ethnicity, ambiant temperature, humidity, distance, and other temperature readings from the thermal images. The dataset is intended to be used in a regression task to predict the oral temperature using the environment information as well as the thermal image readings. ', 'area': 'Health and Medicine', 'tasks': ['Regression'], 'characteristics': ['Tabular'], 'num_instances': 1020, 'num_features': 33, 'feature_types': ['Real', 'Categorical'], 'demographics': ['Gender', 'Age', 'Ethnicity'], 'target_col': ['aveOralF', 'aveOralM'], 'index_col': ['SubjectID'], 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2021, 'last_updated': 'Tue Dec 12 2023', 'dataset_doi': '10.13026/9ay4-2c37', 'creators': ['Quanzeng Wang', 'Yangling Zhou', 'Pejman Ghassemi', 'David McBride', 'J. Casamento', 'T. Pfefer', 'Quanzeng Wang', 'Yangling Zhou', 'Pejman Ghassemi', 'David McBride', 'J. Casamento', 'T. Pfefer'], 'intro_paper': {'ID': 343, 'type': 'NATIVE', 'title': 'Infrared Thermography for Measuring Elevated Body Temperature: Clinical Accuracy, Calibration, and Evaluation', 'authors': 'Quanzeng Wang, Yangling Zhou, Pejman Ghassemi, David McBride, J. Casamento, T. Pfefer', 'venue': 'Italian National Conference on Sensors', 'year': 2021, 'journal': None, 'DOI': None, 'URL': 'https://www.semanticscholar.org/paper/443b9932d295ca3a014e7d874b4bd77a33a276bd', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': None, 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '- gender\\n- age\\n- ethnicity\\n- ambiant temperature\\n- humidity\\n- distance\\n- temperature readings from the thermal images', 'citation': None}, 'external_url': 'https://physionet.org/content/face-oral-temp-data/1.0.0/'}\n",
            "           name     role         type demographic  \\\n",
            "0     SubjectID       ID  Categorical        None   \n",
            "1      aveOralF   Target   Continuous        None   \n",
            "2      aveOralM   Target   Continuous        None   \n",
            "3        Gender  Feature  Categorical      Gender   \n",
            "4           Age  Feature  Categorical         Age   \n",
            "5     Ethnicity  Feature  Categorical   Ethnicity   \n",
            "6         T_atm  Feature   Continuous        None   \n",
            "7      Humidity  Feature   Continuous        None   \n",
            "8      Distance  Feature   Continuous        None   \n",
            "9     T_offset1  Feature   Continuous        None   \n",
            "10    Max1R13_1  Feature   Continuous        None   \n",
            "11    Max1L13_1  Feature   Continuous        None   \n",
            "12  aveAllR13_1  Feature   Continuous        None   \n",
            "13  aveAllL13_1  Feature   Continuous        None   \n",
            "14        T_RC1  Feature   Continuous        None   \n",
            "15    T_RC_Dry1  Feature   Continuous        None   \n",
            "16    T_RC_Wet1  Feature   Continuous        None   \n",
            "17    T_RC_Max1  Feature   Continuous        None   \n",
            "18        T_LC1  Feature   Continuous        None   \n",
            "19    T_LC_Dry1  Feature   Continuous        None   \n",
            "20    T_LC_Wet1  Feature   Continuous        None   \n",
            "21    T_LC_Max1  Feature   Continuous        None   \n",
            "22         RCC1  Feature   Continuous        None   \n",
            "23         LCC1  Feature   Continuous        None   \n",
            "24   canthiMax1  Feature   Continuous        None   \n",
            "25  canthi4Max1  Feature   Continuous        None   \n",
            "26      T_FHCC1  Feature   Continuous        None   \n",
            "27      T_FHRC1  Feature   Continuous        None   \n",
            "28      T_FHLC1  Feature   Continuous        None   \n",
            "29      T_FHBC1  Feature   Continuous        None   \n",
            "30      T_FHTC1  Feature   Continuous        None   \n",
            "31    T_FH_Max1  Feature   Continuous        None   \n",
            "32   T_FHC_Max1  Feature   Continuous        None   \n",
            "33       T_Max1  Feature   Continuous        None   \n",
            "34        T_OR1  Feature   Continuous        None   \n",
            "35    T_OR_Max1  Feature   Continuous        None   \n",
            "\n",
            "                                          description units missing_values  \n",
            "0                                          Subject ID  None             no  \n",
            "1              Oral temperature measured in fast mode  None             no  \n",
            "2           Oral temperature measured in monitor mode  None             no  \n",
            "3                                      Male or Female  None             no  \n",
            "4                          Age ranges in categories\\n  None             no  \n",
            "5   American Indian or Alaska Native, Asian, Black...  None             no  \n",
            "6                                 Ambiant temperature  None             no  \n",
            "7                                   Relative humidity  None             no  \n",
            "8       Distance between the subjects and the IRTs.  None             no  \n",
            "9   Temperature difference between the set and mea...  None             no  \n",
            "10  Max value of a circle with diameter of 13 pixe...  None             no  \n",
            "11  Max value of a circle with diameter of 13 pixe...  None             no  \n",
            "12  Average value of a circle with diameter of 13 ...  None             no  \n",
            "13  Average value of a circle with diameter of 13 ...  None             no  \n",
            "14  Average temperature of the highest four pixels...  None             no  \n",
            "15  Average temperature of the highest four pixels...  None             no  \n",
            "16  Average temperature of the highest four pixels...  None             no  \n",
            "17  Max value of a square of 24x24 pixels around t...  None             no  \n",
            "18  Average temperature of the highest four pixels...  None             no  \n",
            "19  Average temperature of the highest four pixels...  None             no  \n",
            "20  Average temperature of the highest four pixels...  None             no  \n",
            "21  Max value of a circle with diameter of 13 pixe...  None             no  \n",
            "22  Average value of a square of 3x3 pixels center...  None             no  \n",
            "23  Average value of a square of 3x3 pixels center...  None             no  \n",
            "24              Max value in the extended canthi area  None             no  \n",
            "25  Average temperature of the highest four pixels...  None             no  \n",
            "26  Average value in the center point of forehead,...  None             no  \n",
            "27  Average value in the right point of the forehe...  None             no  \n",
            "28  Average value in the left point of the forehea...  None             no  \n",
            "29  Average value in the bottom point of the foreh...  None             no  \n",
            "30  Average value in the top point of the forehead...  None             no  \n",
            "31  Maximum temperature within the extended forehe...  None             no  \n",
            "32  Max value in the center point of forehead, a s...  None             no  \n",
            "33  Maximum temperature within the whole face region.  None             no  \n",
            "34  Average temperature of the highest four pixels...  None             no  \n",
            "35       Maximum temperature within the mouth region.  None             no  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "BgY3cS_aoFq3",
        "outputId": "20950a26-3a0b-4d6c-ddb1-f12cec8809c9"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      aveOralF  aveOralM\n",
              "0        36.85     36.59\n",
              "1        37.00     37.19\n",
              "2        37.20     37.34\n",
              "3        36.85     37.09\n",
              "4        36.80     37.04\n",
              "...        ...       ...\n",
              "1015     36.95     36.99\n",
              "1016     37.25     37.19\n",
              "1017     37.35     37.59\n",
              "1018     37.15     37.29\n",
              "1019     37.05     37.19\n",
              "\n",
              "[1020 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fee949f-2baa-4b34-abf9-5fe7f526d878\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aveOralF</th>\n",
              "      <th>aveOralM</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>36.85</td>\n",
              "      <td>36.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37.00</td>\n",
              "      <td>37.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37.20</td>\n",
              "      <td>37.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36.85</td>\n",
              "      <td>37.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36.80</td>\n",
              "      <td>37.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1015</th>\n",
              "      <td>36.95</td>\n",
              "      <td>36.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1016</th>\n",
              "      <td>37.25</td>\n",
              "      <td>37.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1017</th>\n",
              "      <td>37.35</td>\n",
              "      <td>37.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1018</th>\n",
              "      <td>37.15</td>\n",
              "      <td>37.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1019</th>\n",
              "      <td>37.05</td>\n",
              "      <td>37.19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1020 rows  2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fee949f-2baa-4b34-abf9-5fe7f526d878')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0fee949f-2baa-4b34-abf9-5fe7f526d878 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0fee949f-2baa-4b34-abf9-5fe7f526d878');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c6db42ff-3e92-438a-9520-0694adaf273a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6db42ff-3e92-438a-9520-0694adaf273a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c6db42ff-3e92-438a-9520-0694adaf273a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_03262f24-34f1-4606-8102-2b98f80be2e4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('y')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_03262f24-34f1-4606-8102-2b98f80be2e4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('y');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "y",
              "summary": "{\n  \"name\": \"y\",\n  \"rows\": 1020,\n  \"fields\": [\n    {\n      \"column\": \"aveOralF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3864033248934766,\n        \"min\": 35.75,\n        \"max\": 39.6,\n        \"num_unique_values\": 53,\n        \"samples\": [\n          37.65,\n          39.2,\n          38.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aveOralM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5095022787133393,\n        \"min\": 35.54,\n        \"max\": 40.34,\n        \"num_unique_values\": 70,\n        \"samples\": [\n          36.39,\n          36.59,\n          37.59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Testing Functions"
      ],
      "metadata": {
        "id": "B-Lh-XosxpI6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import make_regression\n",
        "import evidential_deep_learning as edl\n",
        "\n",
        "def main():\n",
        "    # Create synthetic regression data\n",
        "    x_train, y_train = generate_regression_data(1000)\n",
        "    x_test, y_test = generate_regression_data(1000, train=False)\n",
        "\n",
        "    # Define the model with evidential output for regression\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(x_train.shape[1],)),\n",
        "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "        edl.layers.DenseNormalGamma(1),\n",
        "    ])\n",
        "\n",
        "    # Define custom loss function with evidential regularization\n",
        "    def EvidentialRegressionLoss(true, pred):\n",
        "        return edl.losses.EvidentialRegression(true, pred, coeff=1e-2)\n",
        "\n",
        "    # Early stopping callback\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "\n",
        "    # Compile and train the model with early stopping\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(5e-4), loss=EvidentialRegressionLoss)\n",
        "    model.fit(x_train, y_train, batch_size=100, epochs=500, validation_data=(x_test, y_test),\n",
        "              callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Predict on the test data\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "    return y_pred\n",
        "\n",
        "def generate_regression_data(n_samples, train=True):\n",
        "    # Use sklearn's make_regression to generate synthetic regression data\n",
        "    X, y = make_regression(n_samples=n_samples, n_features=20, noise=0.1)\n",
        "    X = X.astype(np.float32)\n",
        "    y = y.astype(np.float32)\n",
        "\n",
        "    if not train:\n",
        "        # Add noise to test data\n",
        "        y += np.random.normal(0, 3, size=y.shape).astype(np.float32)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "y_pred = main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBzLz9CUOmyH",
        "outputId": "b3a2b0b3-8436-42be-c07c-be5624042915"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m32/32\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#[mu, v, alpha, beta]\n",
        "print(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylnogi-NPaJC",
        "outputId": "28c110bf-5ef0-4853-83a1-b8e626cb56af"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.03724585e+01  3.93922150e-04  1.00000048e+00  1.53312235e+01]\n",
            " [-6.35994244e+00  1.31807267e-03  1.00012648e+00  1.02595873e+01]\n",
            " [-7.93386745e+00  2.97468854e-04  1.00002491e+00  1.08337526e+01]\n",
            " ...\n",
            " [-7.16663361e+00  7.59767310e-04  1.00004590e+00  1.07342796e+01]\n",
            " [-6.83244658e+00  8.13805789e-04  1.00013018e+00  1.03489933e+01]\n",
            " [-7.27296925e+00  1.01219758e-03  1.00010216e+00  9.53599644e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import fastshap\n",
        "import time\n",
        "\n",
        "def conflicting_evidence_strategy_reg(learner, X_pool, task = \"reg\", n_instances=10, max = True):\n",
        "    regressor = learner.estimator.model_\n",
        "    preds = regressor.predict(X_pool, verbose = 0)\n",
        "\n",
        "    # Just using alpha because measure of uncertainty of variance which is where problems are\n",
        "    alpha = np.array(preds[:, 2])\n",
        "    sorted_indices = np.argsort(alpha)[:n_instances]\n",
        "\n",
        "    print(f\"Indices is {sorted_indices}\")\n",
        "\n",
        "    # Return the indices and the corresponding instances\n",
        "    return sorted_indices, X_pool[sorted_indices]"
      ],
      "metadata": {
        "id": "4yLakefulOQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}